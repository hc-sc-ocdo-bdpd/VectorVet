{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö VectorVet Demo Notebook  \n",
    "  \n",
    "This notebook demonstrates embedding generation, loading embeddings, computing metrics, and summarizing results using the custom `VectorVet` toolkit. \n",
    "\n",
    "---    \n",
    "## üîß Setup and Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries  \n",
    "import sys  \n",
    "from pathlib import Path  \n",
    "  \n",
    "# Data Science Libraries  \n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from tqdm.auto import tqdm  \n",
    "  \n",
    "# Text Processing  \n",
    "from sklearn.datasets import fetch_20newsgroups  \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  \n",
    "  \n",
    "# Embedding Generation  \n",
    "from llama_cpp import Llama  \n",
    "  \n",
    "# Custom VectorVet Modules  \n",
    "PROJECT_ROOT = Path.cwd().parent  \n",
    "sys.path.append(str(PROJECT_ROOT))  \n",
    "  \n",
    "from vectorvet.core.loader import load_multiple_embeddings  \n",
    "from vectorvet.core.metrics import run_all_metrics  \n",
    "from vectorvet.core.summarizer import summarize_to_dataframe  \n",
    "from vectorvet.core.utils import timer  \n",
    "  \n",
    "# Display Configuration  \n",
    "pd.set_option(\"display.max_columns\", None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "  \n",
    "## üóÉÔ∏è Load and Chunk the Dataset  \n",
    "  \n",
    "We'll use the well-known 20 Newsgroups dataset for this demo. We'll chunk the texts into manageable pieces.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba6871f90e24a4f9b41fe21789c4880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunking texts:   0%|          | 0/11014 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total chunks created: 21975\n"
     ]
    }
   ],
   "source": [
    "# Fetch the 20 Newsgroups dataset  \n",
    "news = fetch_20newsgroups(subset=\"train\", remove=(\"headers\", \"footers\", \"quotes\"))  \n",
    "texts = [t for t in news.data if t.strip()]  \n",
    "  \n",
    "# Initialize a text splitter  \n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=50)  \n",
    "  \n",
    "# Chunk the dataset  \n",
    "chunked_data = []  \n",
    "for idx, text in enumerate(tqdm(texts, desc=\"Chunking texts\")):  \n",
    "    chunks = splitter.split_text(text)  \n",
    "    for chunk_idx, chunk in enumerate(chunks):  \n",
    "        chunked_data.append({  \n",
    "            \"original_index\": idx,  \n",
    "            \"chunk_index\": chunk_idx,  \n",
    "            \"chunk\": chunk  \n",
    "        })  \n",
    "  \n",
    "# Create DataFrame of chunks  \n",
    "chunked_df = pd.DataFrame(chunked_data)  \n",
    "chunk_texts = chunked_df[\"chunk\"].tolist()  \n",
    "  \n",
    "print(f\"‚úÖ Total chunks created: {len(chunk_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_texts = chunk_texts[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "  \n",
    "## üìå Generate Embeddings for Each Model  \n",
    "  \n",
    "We'll generate embeddings using various LLM models and save them for further analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Embedding with Phi-3-mini-4k-instruct-q4 ‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA RTX A3000 12GB Laptop GPU, compute capability 8.6, VMM: yes\n",
      "llama_model_load_from_file_impl: using device CUDA0 (NVIDIA RTX A3000 12GB Laptop GPU) - 11230 MiB free\n",
      "llama_model_loader: loaded meta data with 24 key-value pairs and 195 tensors from /workspaces/VectorVet/models/Phi-3-mini-4k-instruct-q4.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi3\n",
      "llama_model_loader: - kv   2:                        phi3.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                      phi3.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   4:                   phi3.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   5:                           phi3.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  phi3.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:               phi3.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   8:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   9:                  phi3.rope.dimension_count u32              = 96\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32064]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32064]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 32000\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:   81 tensors\n",
      "llama_model_loader: - type q5_K:   32 tensors\n",
      "llama_model_loader: - type q6_K:   17 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 2.23 GiB (5.01 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control-looking token:  32007 '<|end|>' was not control-type; this is probably a bug in the model. its type will be overridden\n",
      "load: control-looking token:  32000 '<|endoftext|>' was not control-type; this is probably a bug in the model. its type will be overridden\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special tokens cache size = 67\n",
      "load: token to piece cache size = 0.1690 MB\n",
      "print_info: arch             = phi3\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 4096\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 32\n",
      "print_info: n_rot            = 96\n",
      "print_info: n_swa            = 2047\n",
      "print_info: n_embd_head_k    = 96\n",
      "print_info: n_embd_head_v    = 96\n",
      "print_info: n_gqa            = 1\n",
      "print_info: n_embd_k_gqa     = 3072\n",
      "print_info: n_embd_v_gqa     = 3072\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 4096\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.82 B\n",
      "print_info: general.name     = Phi3\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32064\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 32000 '<|endoftext|>'\n",
      "print_info: EOT token        = 32007 '<|end|>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: PAD token        = 32000 '<|endoftext|>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 32000 '<|endoftext|>'\n",
      "print_info: EOG token        = 32007 '<|end|>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CUDA0\n",
      "load_tensors: layer   1 assigned to device CUDA0\n",
      "load_tensors: layer   2 assigned to device CUDA0\n",
      "load_tensors: layer   3 assigned to device CUDA0\n",
      "load_tensors: layer   4 assigned to device CUDA0\n",
      "load_tensors: layer   5 assigned to device CUDA0\n",
      "load_tensors: layer   6 assigned to device CUDA0\n",
      "load_tensors: layer   7 assigned to device CUDA0\n",
      "load_tensors: layer   8 assigned to device CUDA0\n",
      "load_tensors: layer   9 assigned to device CUDA0\n",
      "load_tensors: layer  10 assigned to device CUDA0\n",
      "load_tensors: layer  11 assigned to device CUDA0\n",
      "load_tensors: layer  12 assigned to device CUDA0\n",
      "load_tensors: layer  13 assigned to device CUDA0\n",
      "load_tensors: layer  14 assigned to device CUDA0\n",
      "load_tensors: layer  15 assigned to device CUDA0\n",
      "load_tensors: layer  16 assigned to device CUDA0\n",
      "load_tensors: layer  17 assigned to device CUDA0\n",
      "load_tensors: layer  18 assigned to device CUDA0\n",
      "load_tensors: layer  19 assigned to device CUDA0\n",
      "load_tensors: layer  20 assigned to device CUDA0\n",
      "load_tensors: layer  21 assigned to device CUDA0\n",
      "load_tensors: layer  22 assigned to device CUDA0\n",
      "load_tensors: layer  23 assigned to device CUDA0\n",
      "load_tensors: layer  24 assigned to device CUDA0\n",
      "load_tensors: layer  25 assigned to device CUDA0\n",
      "load_tensors: layer  26 assigned to device CUDA0\n",
      "load_tensors: layer  27 assigned to device CUDA0\n",
      "load_tensors: layer  28 assigned to device CUDA0\n",
      "load_tensors: layer  29 assigned to device CUDA0\n",
      "load_tensors: layer  30 assigned to device CUDA0\n",
      "load_tensors: layer  31 assigned to device CUDA0\n",
      "load_tensors: layer  32 assigned to device CUDA0\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 0 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors: offloading 32 repeating layers to GPU\n",
      "load_tensors: offloading output layer to GPU\n",
      "load_tensors: offloaded 33/33 layers to GPU\n",
      "load_tensors:        CUDA0 model buffer size =  2228.82 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =    52.84 MiB\n",
      "............................................................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 512\n",
      "llama_init_from_model: n_ctx_per_seq = 512\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 10000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (512) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 3072, n_embd_v_gqa = 3072\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   192.00 MiB\n",
      "llama_init_from_model: KV self size  =  192.00 MiB, K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
      "llama_init_from_model:  CUDA_Host  output buffer size =     0.01 MiB\n",
      "llama_init_from_model:      CUDA0 compute buffer size =    83.00 MiB\n",
      "llama_init_from_model:  CUDA_Host compute buffer size =     7.01 MiB\n",
      "llama_init_from_model: graph nodes  = 1286\n",
      "llama_init_from_model: graph splits = 2\n",
      "CUDA : ARCHS = 520 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\\n' + message['content'] + '<|end|>' + '\\n' + '<|assistant|>' + '\\n'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\\n'}}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '32000', 'tokenizer.ggml.eos_token_id': '32000', 'tokenizer.ggml.bos_token_id': '1', 'general.architecture': 'phi3', 'phi3.context_length': '4096', 'phi3.attention.head_count_kv': '32', 'general.name': 'Phi3', 'tokenizer.ggml.pre': 'default', 'phi3.embedding_length': '3072', 'tokenizer.ggml.unknown_token_id': '0', 'phi3.feed_forward_length': '8192', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.block_count': '32', 'phi3.attention.head_count': '32', 'phi3.rope.dimension_count': '96', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\n",
      "' + message['content'] + '<|end|>' + '\n",
      "' + '<|assistant|>' + '\n",
      "'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\n",
      "'}}{% endif %}{% endfor %}\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <s>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d30c00cc9149729840b35838ebccf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding (Phi-3-mini-4k-instruct-q4):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =    2422.42 ms /   136 tokens (   17.81 ms per token,    56.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2429.73 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     104.45 ms /   134 tokens (    0.78 ms per token,  1282.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     111.73 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     130.44 ms /   216 tokens (    0.60 ms per token,  1655.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.52 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     156.17 ms /   276 tokens (    0.57 ms per token,  1767.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.23 ms /   277 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.40 ms /    28 tokens (    3.16 ms per token,   316.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.24 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.91 ms /   126 tokens (    0.71 ms per token,  1401.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.45 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.12 ms /   116 tokens (    0.75 ms per token,  1331.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.03 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.69 ms /   124 tokens (    0.71 ms per token,  1414.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.61 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      69.06 ms /    17 tokens (    4.06 ms per token,   246.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.69 ms /    18 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     179.46 ms /   368 tokens (    0.49 ms per token,  2050.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     197.44 ms /   369 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     111.96 ms /   182 tokens (    0.62 ms per token,  1625.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     120.19 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.09 ms /    57 tokens (    1.32 ms per token,   759.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.67 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     152.07 ms /   270 tokens (    0.56 ms per token,  1775.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.90 ms /   271 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     124.85 ms /   234 tokens (    0.53 ms per token,  1874.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.88 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     120.48 ms /   219 tokens (    0.55 ms per token,  1817.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.87 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     123.96 ms /   227 tokens (    0.55 ms per token,  1831.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.04 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.14 ms /   245 tokens (    0.52 ms per token,  1927.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.58 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =    6623.18 ms /     2 tokens ( 3311.59 ms per token,     0.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    6624.38 ms /     3 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     112.09 ms /   179 tokens (    0.63 ms per token,  1596.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     120.10 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.18 ms /   283 tokens (    0.55 ms per token,  1823.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     168.13 ms /   284 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     112.06 ms /   180 tokens (    0.62 ms per token,  1606.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.65 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.05 ms /   119 tokens (    0.73 ms per token,  1366.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.77 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     157.39 ms /   290 tokens (    0.54 ms per token,  1842.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.55 ms /   291 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      71.76 ms /    35 tokens (    2.05 ms per token,   487.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.91 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     209.90 ms /   433 tokens (    0.48 ms per token,  2062.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     229.53 ms /   434 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      84.18 ms /    90 tokens (    0.94 ms per token,  1069.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.76 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     103.57 ms /   145 tokens (    0.71 ms per token,  1399.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.85 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     121.33 ms /   216 tokens (    0.56 ms per token,  1780.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.47 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     117.66 ms /   202 tokens (    0.58 ms per token,  1716.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.45 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     168.44 ms /   332 tokens (    0.51 ms per token,  1971.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     183.28 ms /   333 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     166.45 ms /   323 tokens (    0.52 ms per token,  1940.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     180.36 ms /   324 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     165.55 ms /   321 tokens (    0.52 ms per token,  1938.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.06 ms /   322 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     154.63 ms /   280 tokens (    0.55 ms per token,  1810.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.97 ms /   281 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     159.35 ms /   297 tokens (    0.54 ms per token,  1863.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     172.96 ms /   298 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     171.96 ms /   349 tokens (    0.49 ms per token,  2029.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     186.61 ms /   350 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     163.31 ms /   314 tokens (    0.52 ms per token,  1922.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     176.48 ms /   315 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     159.47 ms /   297 tokens (    0.54 ms per token,  1862.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     171.63 ms /   298 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     160.37 ms /   300 tokens (    0.53 ms per token,  1870.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     173.08 ms /   301 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     114.60 ms /   190 tokens (    0.60 ms per token,  1657.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.72 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     106.43 ms /   152 tokens (    0.70 ms per token,  1428.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     112.32 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     159.20 ms /   293 tokens (    0.54 ms per token,  1840.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     171.42 ms /   294 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.52 ms /    57 tokens (    1.32 ms per token,   754.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.19 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     105.72 ms /   154 tokens (    0.69 ms per token,  1456.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     111.55 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     129.02 ms /   249 tokens (    0.52 ms per token,  1929.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     139.69 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.50 ms /    63 tokens (    1.21 ms per token,   823.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.41 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.10 ms /    56 tokens (    1.34 ms per token,   745.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.63 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      86.26 ms /   101 tokens (    0.85 ms per token,  1170.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.19 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     123.28 ms /   226 tokens (    0.55 ms per token,  1833.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.38 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     130.61 ms /   256 tokens (    0.51 ms per token,  1960.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.67 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      69.62 ms /    22 tokens (    3.16 ms per token,   316.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.54 ms /    23 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     151.77 ms /   266 tokens (    0.57 ms per token,  1752.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.07 ms /   267 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     124.23 ms /   230 tokens (    0.54 ms per token,  1851.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.86 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.62 ms /   126 tokens (    0.70 ms per token,  1421.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.72 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     118.98 ms /   207 tokens (    0.57 ms per token,  1739.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.73 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     149.80 ms /   257 tokens (    0.58 ms per token,  1715.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.52 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      83.95 ms /    90 tokens (    0.93 ms per token,  1072.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.40 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.28 ms /    40 tokens (    1.81 ms per token,   553.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.54 ms /    41 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     151.63 ms /   265 tokens (    0.57 ms per token,  1747.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.27 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      81.86 ms /    77 tokens (    1.06 ms per token,   940.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.24 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.47 ms /    41 tokens (    1.77 ms per token,   565.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.63 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.36 ms /   111 tokens (    0.80 ms per token,  1256.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.22 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.84 ms /   213 tokens (    0.56 ms per token,  1777.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.32 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.12 ms /   204 tokens (    0.58 ms per token,  1712.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.28 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     113.88 ms /   192 tokens (    0.59 ms per token,  1685.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.12 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     122.61 ms /   219 tokens (    0.56 ms per token,  1786.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.19 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     101.78 ms /   135 tokens (    0.75 ms per token,  1326.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     106.58 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.13 ms /   280 tokens (    0.55 ms per token,  1804.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.56 ms /   281 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     114.23 ms /   190 tokens (    0.60 ms per token,  1663.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.39 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     130.07 ms /   254 tokens (    0.51 ms per token,  1952.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.85 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     126.43 ms /   236 tokens (    0.54 ms per token,  1866.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.22 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     151.47 ms /   263 tokens (    0.58 ms per token,  1736.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.87 ms /   264 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.68 ms /    67 tokens (    1.20 ms per token,   830.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.89 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      24.06 ms /     4 tokens (    6.02 ms per token,   166.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      25.05 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      79.81 ms /    66 tokens (    1.21 ms per token,   826.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.66 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      69.50 ms /    20 tokens (    3.47 ms per token,   287.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.95 ms /    21 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     160.83 ms /   303 tokens (    0.53 ms per token,  1883.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     174.57 ms /   304 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     118.41 ms /   203 tokens (    0.58 ms per token,  1714.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.18 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     129.89 ms /   255 tokens (    0.51 ms per token,  1963.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.31 ms /   256 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      83.94 ms /    88 tokens (    0.95 ms per token,  1048.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.72 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.86 ms /    62 tokens (    1.24 ms per token,   806.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.45 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      71.90 ms /    31 tokens (    2.32 ms per token,   431.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.78 ms /    32 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     107.85 ms /   162 tokens (    0.67 ms per token,  1502.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     113.40 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      77.16 ms /    64 tokens (    1.21 ms per token,   829.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.04 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.42 ms /   120 tokens (    0.73 ms per token,  1372.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.89 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     150.21 ms /   257 tokens (    0.58 ms per token,  1710.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.27 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     129.60 ms /   253 tokens (    0.51 ms per token,  1952.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.01 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.52 ms /    67 tokens (    1.20 ms per token,   832.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.52 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     103.04 ms /   136 tokens (    0.76 ms per token,  1319.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.81 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.78 ms /   280 tokens (    0.56 ms per token,  1797.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     167.50 ms /   281 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.86 ms /   282 tokens (    0.55 ms per token,  1809.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     167.80 ms /   283 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     126.20 ms /   238 tokens (    0.53 ms per token,  1885.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.58 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     121.03 ms /   217 tokens (    0.56 ms per token,  1792.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     129.71 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     154.11 ms /   273 tokens (    0.56 ms per token,  1771.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.96 ms /   274 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.87 ms /   108 tokens (    0.83 ms per token,  1201.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.90 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     108.01 ms /   160 tokens (    0.68 ms per token,  1481.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     113.77 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      71.67 ms /    33 tokens (    2.17 ms per token,   460.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.72 ms /    34 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      85.11 ms /    96 tokens (    0.89 ms per token,  1127.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.87 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.88 ms /   206 tokens (    0.58 ms per token,  1718.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.42 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     151.22 ms /   260 tokens (    0.58 ms per token,  1719.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.11 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      85.60 ms /    97 tokens (    0.88 ms per token,  1133.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.55 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     130.21 ms /   251 tokens (    0.52 ms per token,  1927.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.27 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     170.38 ms /   336 tokens (    0.51 ms per token,  1972.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     185.73 ms /   337 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     224.91 ms /   485 tokens (    0.46 ms per token,  2156.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     246.03 ms /   486 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     128.70 ms /   248 tokens (    0.52 ms per token,  1927.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.82 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     151.08 ms /   261 tokens (    0.58 ms per token,  1727.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.77 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     113.53 ms /   185 tokens (    0.61 ms per token,  1629.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.91 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     159.87 ms /   290 tokens (    0.55 ms per token,  1814.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     171.43 ms /   291 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     165.48 ms /   319 tokens (    0.52 ms per token,  1927.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     178.11 ms /   320 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     124.69 ms /   231 tokens (    0.54 ms per token,  1852.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     132.45 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     112.99 ms /   180 tokens (    0.63 ms per token,  1593.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.75 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     101.64 ms /   134 tokens (    0.76 ms per token,  1318.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     106.53 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.71 ms /    35 tokens (    2.08 ms per token,   481.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.00 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     151.95 ms /   261 tokens (    0.58 ms per token,  1717.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.59 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      81.36 ms /    71 tokens (    1.15 ms per token,   872.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.58 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.96 ms /    58 tokens (    1.31 ms per token,   763.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.48 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      86.82 ms /   105 tokens (    0.83 ms per token,  1209.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.56 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     110.01 ms /   170 tokens (    0.65 ms per token,  1545.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.86 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     152.98 ms /   265 tokens (    0.58 ms per token,  1732.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.56 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.27 ms /   107 tokens (    0.82 ms per token,  1212.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.18 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     114.40 ms /   192 tokens (    0.60 ms per token,  1678.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.53 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.23 ms /   203 tokens (    0.59 ms per token,  1702.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.37 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     120.57 ms /   209 tokens (    0.58 ms per token,  1733.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.99 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     165.32 ms /   317 tokens (    0.52 ms per token,  1917.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     177.19 ms /   318 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     118.39 ms /   202 tokens (    0.59 ms per token,  1706.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     124.65 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     121.95 ms /   218 tokens (    0.56 ms per token,  1787.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     129.47 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      74.34 ms /    46 tokens (    1.62 ms per token,   618.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.03 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     162.40 ms /   307 tokens (    0.53 ms per token,  1890.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     174.76 ms /   308 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     151.77 ms /   259 tokens (    0.59 ms per token,  1706.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.46 ms /   260 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     114.44 ms /   186 tokens (    0.62 ms per token,  1625.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     120.74 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     153.17 ms /   264 tokens (    0.58 ms per token,  1723.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.14 ms /   265 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     120.54 ms /   210 tokens (    0.57 ms per token,  1742.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.97 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     130.54 ms /   252 tokens (    0.52 ms per token,  1930.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.79 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     102.96 ms /   140 tokens (    0.74 ms per token,  1359.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.68 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     103.98 ms /   136 tokens (    0.76 ms per token,  1307.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.44 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.01 ms /   203 tokens (    0.59 ms per token,  1705.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.28 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     130.84 ms /   254 tokens (    0.52 ms per token,  1941.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.38 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     125.82 ms /   233 tokens (    0.54 ms per token,  1851.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.48 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     171.72 ms /   342 tokens (    0.50 ms per token,  1991.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     185.66 ms /   343 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.57 ms /    61 tokens (    1.26 ms per token,   796.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.52 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     158.44 ms /   287 tokens (    0.55 ms per token,  1811.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     169.25 ms /   288 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.51 ms /   240 tokens (    0.53 ms per token,  1882.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.61 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     153.88 ms /   268 tokens (    0.57 ms per token,  1741.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.19 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     150.88 ms /   258 tokens (    0.58 ms per token,  1710.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.10 ms /   259 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     118.79 ms /   201 tokens (    0.59 ms per token,  1692.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.57 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     129.57 ms /   247 tokens (    0.52 ms per token,  1906.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     137.96 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     126.90 ms /   238 tokens (    0.53 ms per token,  1875.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.70 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     101.67 ms /   133 tokens (    0.76 ms per token,  1308.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     106.44 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     106.90 ms /   154 tokens (    0.69 ms per token,  1440.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     112.14 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     153.88 ms /   265 tokens (    0.58 ms per token,  1722.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.74 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.94 ms /    59 tokens (    1.29 ms per token,   776.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.61 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     159.33 ms /   290 tokens (    0.55 ms per token,  1820.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.32 ms /   291 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.42 ms /   102 tokens (    0.86 ms per token,  1166.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.16 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     152.05 ms /   257 tokens (    0.59 ms per token,  1690.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.01 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     123.20 ms /   222 tokens (    0.55 ms per token,  1802.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.05 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     103.73 ms /   142 tokens (    0.73 ms per token,  1368.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.51 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.35 ms /    67 tokens (    1.20 ms per token,   833.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.15 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     160.02 ms /   293 tokens (    0.55 ms per token,  1831.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     171.35 ms /   294 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.06 ms /    33 tokens (    2.21 ms per token,   451.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.09 ms /    34 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     122.94 ms /   222 tokens (    0.55 ms per token,  1805.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.45 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     123.41 ms /   224 tokens (    0.55 ms per token,  1815.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.85 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     113.46 ms /   180 tokens (    0.63 ms per token,  1586.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.50 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.39 ms /   124 tokens (    0.71 ms per token,  1402.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.66 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     115.18 ms /   191 tokens (    0.60 ms per token,  1658.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     122.42 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     130.38 ms /   253 tokens (    0.52 ms per token,  1940.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.34 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.17 ms /   205 tokens (    0.58 ms per token,  1720.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.65 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.92 ms /   240 tokens (    0.53 ms per token,  1876.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     137.04 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     159.53 ms /   290 tokens (    0.55 ms per token,  1817.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.55 ms /   291 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     120.59 ms /   212 tokens (    0.57 ms per token,  1758.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.62 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     111.59 ms /   175 tokens (    0.64 ms per token,  1568.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.42 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     109.50 ms /   166 tokens (    0.66 ms per token,  1516.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.21 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      82.93 ms /    84 tokens (    0.99 ms per token,  1012.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.30 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.03 ms /   237 tokens (    0.54 ms per token,  1865.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.08 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     101.09 ms /   130 tokens (    0.78 ms per token,  1286.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.83 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     130.19 ms /   253 tokens (    0.51 ms per token,  1943.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     139.54 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     110.53 ms /   171 tokens (    0.65 ms per token,  1547.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.99 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      81.26 ms /    69 tokens (    1.18 ms per token,   849.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.21 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.95 ms /    47 tokens (    1.57 ms per token,   635.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.18 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     111.94 ms /   176 tokens (    0.64 ms per token,  1572.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.77 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     125.05 ms /   227 tokens (    0.55 ms per token,  1815.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.16 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      83.56 ms /    84 tokens (    0.99 ms per token,  1005.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.01 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      90.41 ms /   128 tokens (    0.71 ms per token,  1415.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.88 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.75 ms /   125 tokens (    0.71 ms per token,  1408.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.27 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     165.40 ms /   309 tokens (    0.54 ms per token,  1868.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     177.76 ms /   310 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     113.01 ms /   182 tokens (    0.62 ms per token,  1610.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.01 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      81.92 ms /    76 tokens (    1.08 ms per token,   927.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.39 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.18 ms /    60 tokens (    1.27 ms per token,   787.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.75 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      82.58 ms /    81 tokens (    1.02 ms per token,   980.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.66 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     129.71 ms /   249 tokens (    0.52 ms per token,  1919.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.79 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.04 ms /   235 tokens (    0.54 ms per token,  1849.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.52 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     106.29 ms /   150 tokens (    0.71 ms per token,  1411.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     111.24 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      90.55 ms /   127 tokens (    0.71 ms per token,  1402.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.99 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.17 ms /   117 tokens (    0.75 ms per token,  1342.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.12 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.54 ms /   119 tokens (    0.74 ms per token,  1359.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.87 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     169.27 ms /   326 tokens (    0.52 ms per token,  1925.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.46 ms /   327 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.92 ms /   125 tokens (    0.71 ms per token,  1405.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.25 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     114.14 ms /   185 tokens (    0.62 ms per token,  1620.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     120.07 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     125.26 ms /   230 tokens (    0.54 ms per token,  1836.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     132.88 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     156.44 ms /   272 tokens (    0.58 ms per token,  1738.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.44 ms /   273 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      79.54 ms /    15 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.28 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.12 ms /   203 tokens (    0.59 ms per token,  1704.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.82 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     125.28 ms /   226 tokens (    0.55 ms per token,  1803.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.17 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     118.79 ms /   199 tokens (    0.60 ms per token,  1675.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.22 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     108.75 ms /   161 tokens (    0.68 ms per token,  1480.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     114.47 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      83.24 ms /    83 tokens (    1.00 ms per token,   997.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.41 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.15 ms /   202 tokens (    0.59 ms per token,  1695.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.81 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.01 ms /    43 tokens (    1.70 ms per token,   588.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.31 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     101.64 ms /   133 tokens (    0.76 ms per token,  1308.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.91 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      82.53 ms /    79 tokens (    1.04 ms per token,   957.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.93 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     118.52 ms /   199 tokens (    0.60 ms per token,  1678.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.25 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     105.17 ms /   147 tokens (    0.72 ms per token,  1397.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     110.25 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.42 ms /    63 tokens (    1.21 ms per token,   824.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.35 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      84.36 ms /    84 tokens (    1.00 ms per token,   995.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.58 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     104.04 ms /   143 tokens (    0.73 ms per token,  1374.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.72 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.43 ms /    33 tokens (    2.19 ms per token,   455.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.35 ms /    34 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.54 ms /   113 tokens (    0.79 ms per token,  1261.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.59 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.48 ms /   124 tokens (    0.71 ms per token,  1401.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.62 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      74.08 ms /    48 tokens (    1.54 ms per token,   647.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.65 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.31 ms /   272 tokens (    0.57 ms per token,  1751.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.70 ms /   273 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     152.41 ms /   258 tokens (    0.59 ms per token,  1692.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.26 ms /   259 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     117.29 ms /   196 tokens (    0.60 ms per token,  1671.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     123.59 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     154.97 ms /   267 tokens (    0.58 ms per token,  1722.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.32 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      83.98 ms /    86 tokens (    0.98 ms per token,  1024.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.46 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     159.99 ms /   292 tokens (    0.55 ms per token,  1825.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.51 ms /   293 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     105.09 ms /   148 tokens (    0.71 ms per token,  1408.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     110.45 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.84 ms /    53 tokens (    1.43 ms per token,   698.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.45 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      69.83 ms /    17 tokens (    4.11 ms per token,   243.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.28 ms /    18 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     111.61 ms /   174 tokens (    0.64 ms per token,  1559.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.87 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     129.20 ms /   245 tokens (    0.53 ms per token,  1896.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.10 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     109.36 ms /   166 tokens (    0.66 ms per token,  1517.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.04 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.27 ms /    41 tokens (    1.84 ms per token,   544.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.63 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     124.63 ms /   227 tokens (    0.55 ms per token,  1821.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.10 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.97 ms /   122 tokens (    0.72 ms per token,  1386.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.53 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     112.30 ms /   173 tokens (    0.65 ms per token,  1540.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.37 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      84.47 ms /    87 tokens (    0.97 ms per token,  1030.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.46 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     104.24 ms /   141 tokens (    0.74 ms per token,  1352.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.45 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      82.05 ms /    70 tokens (    1.17 ms per token,   853.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.07 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     159.70 ms /   287 tokens (    0.56 ms per token,  1797.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.55 ms /   288 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     159.45 ms /   287 tokens (    0.56 ms per token,  1799.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.00 ms /   288 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     160.64 ms /   293 tokens (    0.55 ms per token,  1823.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     171.24 ms /   294 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.79 ms /    51 tokens (    1.45 ms per token,   691.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.28 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.94 ms /   241 tokens (    0.53 ms per token,  1883.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.78 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.94 ms /    67 tokens (    1.21 ms per token,   827.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.32 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      67.07 ms /     9 tokens (    7.45 ms per token,   134.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.30 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     126.55 ms /   234 tokens (    0.54 ms per token,  1849.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     134.26 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.98 ms /    45 tokens (    1.62 ms per token,   616.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.30 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     112.97 ms /   177 tokens (    0.64 ms per token,  1566.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.92 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     111.04 ms /   171 tokens (    0.65 ms per token,  1540.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     116.90 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     178.29 ms /   360 tokens (    0.50 ms per token,  2019.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     192.91 ms /   361 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.94 ms /   123 tokens (    0.72 ms per token,  1382.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.15 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     233.28 ms /   512 tokens (    0.46 ms per token,  2194.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.61 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     230.92 ms /   512 tokens (    0.45 ms per token,  2217.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.04 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.03 ms /   512 tokens (    0.45 ms per token,  2216.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.04 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.13 ms /   512 tokens (    0.45 ms per token,  2215.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.84 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.14 ms /   512 tokens (    0.45 ms per token,  2215.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.47 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.70 ms /   512 tokens (    0.45 ms per token,  2209.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.80 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.47 ms /   512 tokens (    0.45 ms per token,  2211.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.18 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.56 ms /   512 tokens (    0.45 ms per token,  2211.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.84 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     173.76 ms /   343 tokens (    0.51 ms per token,  1974.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     185.31 ms /   344 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.07 ms /   120 tokens (    0.73 ms per token,  1362.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.18 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      67.65 ms /    11 tokens (    6.15 ms per token,   162.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.26 ms /    12 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     152.59 ms /   259 tokens (    0.59 ms per token,  1697.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.60 ms /   260 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.19 ms /   512 tokens (    0.45 ms per token,  2214.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.22 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.46 ms /   512 tokens (    0.45 ms per token,  2212.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.38 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.40 ms /   512 tokens (    0.45 ms per token,  2212.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.41 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.16 ms /   512 tokens (    0.45 ms per token,  2214.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.44 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.53 ms /   512 tokens (    0.45 ms per token,  2211.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.50 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.41 ms /   512 tokens (    0.45 ms per token,  2212.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.04 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.36 ms /   512 tokens (    0.45 ms per token,  2213.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.98 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.40 ms /   512 tokens (    0.45 ms per token,  2212.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.63 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.36 ms /   512 tokens (    0.45 ms per token,  2212.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.12 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.81 ms /   512 tokens (    0.45 ms per token,  2208.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.57 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.57 ms /   512 tokens (    0.45 ms per token,  2211.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.13 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     230.99 ms /   512 tokens (    0.45 ms per token,  2216.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.00 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     230.95 ms /   512 tokens (    0.45 ms per token,  2216.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.90 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.12 ms /   512 tokens (    0.45 ms per token,  2215.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.66 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     230.48 ms /   512 tokens (    0.45 ms per token,  2221.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     248.66 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.79 ms /   512 tokens (    0.45 ms per token,  2208.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.54 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.68 ms /   512 tokens (    0.45 ms per token,  2209.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.48 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.41 ms /   512 tokens (    0.45 ms per token,  2212.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.04 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.29 ms /   512 tokens (    0.45 ms per token,  2213.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.43 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.63 ms /   512 tokens (    0.45 ms per token,  2210.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.08 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.96 ms /   512 tokens (    0.45 ms per token,  2207.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.10 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.13 ms /   512 tokens (    0.45 ms per token,  2215.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.25 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.62 ms /   512 tokens (    0.45 ms per token,  2210.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.27 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.20 ms /   512 tokens (    0.45 ms per token,  2214.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.49 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.71 ms /   512 tokens (    0.45 ms per token,  2209.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     254.46 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.73 ms /   512 tokens (    0.45 ms per token,  2209.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.23 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.56 ms /   512 tokens (    0.45 ms per token,  2211.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.33 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.36 ms /   512 tokens (    0.45 ms per token,  2212.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.84 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.38 ms /   512 tokens (    0.45 ms per token,  2203.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.69 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.32 ms /   512 tokens (    0.45 ms per token,  2213.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.83 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.31 ms /   512 tokens (    0.45 ms per token,  2203.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.78 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.69 ms /   512 tokens (    0.45 ms per token,  2209.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.38 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.70 ms /   512 tokens (    0.45 ms per token,  2209.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.72 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.48 ms /   512 tokens (    0.45 ms per token,  2211.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.80 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.26 ms /   512 tokens (    0.45 ms per token,  2204.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.18 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.06 ms /   512 tokens (    0.45 ms per token,  2206.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.85 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.30 ms /   512 tokens (    0.45 ms per token,  2204.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.90 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.20 ms /   512 tokens (    0.45 ms per token,  2205.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.58 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.49 ms /   512 tokens (    0.45 ms per token,  2211.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.61 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.09 ms /   512 tokens (    0.45 ms per token,  2206.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.45 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.22 ms /   512 tokens (    0.45 ms per token,  2204.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.24 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.45 ms /   512 tokens (    0.45 ms per token,  2212.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.77 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.93 ms /   512 tokens (    0.45 ms per token,  2207.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.87 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.81 ms /   512 tokens (    0.45 ms per token,  2208.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.56 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.29 ms /   512 tokens (    0.45 ms per token,  2204.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.44 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.87 ms /   512 tokens (    0.45 ms per token,  2208.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.56 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.58 ms /   512 tokens (    0.45 ms per token,  2201.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.51 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     233.10 ms /   512 tokens (    0.46 ms per token,  2196.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.45 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.04 ms /   512 tokens (    0.45 ms per token,  2206.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.64 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.42 ms /   512 tokens (    0.45 ms per token,  2212.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.95 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.01 ms /   512 tokens (    0.45 ms per token,  2206.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.31 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.58 ms /   512 tokens (    0.45 ms per token,  2210.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.64 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.28 ms /   512 tokens (    0.45 ms per token,  2204.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.92 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.28 ms /   512 tokens (    0.45 ms per token,  2204.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.08 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     231.83 ms /   512 tokens (    0.45 ms per token,  2208.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.20 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.05 ms /   512 tokens (    0.45 ms per token,  2206.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     254.02 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.43 ms /   512 tokens (    0.45 ms per token,  2202.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.46 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.36 ms /   512 tokens (    0.45 ms per token,  2203.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.16 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     232.12 ms /   512 tokens (    0.45 ms per token,  2205.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.86 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     219.32 ms /   459 tokens (    0.48 ms per token,  2092.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     236.86 ms /   460 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     124.11 ms /   221 tokens (    0.56 ms per token,  1780.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.46 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     128.21 ms /   238 tokens (    0.54 ms per token,  1856.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.97 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.20 ms /   199 tokens (    0.60 ms per token,  1669.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.73 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      77.21 ms /    63 tokens (    1.23 ms per token,   815.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.17 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     164.62 ms /   304 tokens (    0.54 ms per token,  1846.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     175.20 ms /   305 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     121.39 ms /   209 tokens (    0.58 ms per token,  1721.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.08 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.58 ms /   199 tokens (    0.60 ms per token,  1664.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.78 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      82.13 ms /    78 tokens (    1.05 ms per token,   949.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.29 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.71 ms /    36 tokens (    2.02 ms per token,   495.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.74 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      84.50 ms /    87 tokens (    0.97 ms per token,  1029.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.10 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.38 ms /   109 tokens (    0.81 ms per token,  1233.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.26 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     129.89 ms /   240 tokens (    0.54 ms per token,  1847.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     137.76 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      77.85 ms /    59 tokens (    1.32 ms per token,   757.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.71 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     173.90 ms /   340 tokens (    0.51 ms per token,  1955.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     186.30 ms /   341 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     128.54 ms /   239 tokens (    0.54 ms per token,  1859.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.29 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     158.36 ms /   277 tokens (    0.57 ms per token,  1749.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     167.85 ms /   278 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     121.45 ms /   208 tokens (    0.58 ms per token,  1712.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.66 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     132.25 ms /   251 tokens (    0.53 ms per token,  1897.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.51 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     111.15 ms /   170 tokens (    0.65 ms per token,  1529.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     116.56 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     158.70 ms /   278 tokens (    0.57 ms per token,  1751.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     168.13 ms /   279 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     233.09 ms /   512 tokens (    0.46 ms per token,  2196.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.48 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     158.99 ms /   281 tokens (    0.57 ms per token,  1767.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     168.02 ms /   282 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     157.99 ms /   278 tokens (    0.57 ms per token,  1759.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     167.17 ms /   279 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      74.37 ms /    39 tokens (    1.91 ms per token,   524.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.91 ms /    40 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      83.93 ms /    85 tokens (    0.99 ms per token,  1012.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.37 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.13 ms /   263 tokens (    0.59 ms per token,  1695.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.41 ms /   264 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     128.53 ms /   238 tokens (    0.54 ms per token,  1851.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.99 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      83.74 ms /    87 tokens (    0.96 ms per token,  1038.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.50 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     101.59 ms /   129 tokens (    0.79 ms per token,  1269.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     106.07 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     104.46 ms /   141 tokens (    0.74 ms per token,  1349.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.88 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     108.16 ms /   154 tokens (    0.70 ms per token,  1423.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     113.95 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      84.99 ms /    85 tokens (    1.00 ms per token,  1000.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.19 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      83.92 ms /    87 tokens (    0.96 ms per token,  1036.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.22 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.16 ms /   199 tokens (    0.60 ms per token,  1670.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.33 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     122.55 ms /   209 tokens (    0.59 ms per token,  1705.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     129.19 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     102.61 ms /   134 tokens (    0.77 ms per token,  1305.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.27 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      71.96 ms /    27 tokens (    2.67 ms per token,   375.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.21 ms /    28 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.54 ms /   123 tokens (    0.72 ms per token,  1389.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.87 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      69.96 ms /    21 tokens (    3.33 ms per token,   300.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.62 ms /    22 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     124.20 ms /   221 tokens (    0.56 ms per token,  1779.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.74 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      74.76 ms /    40 tokens (    1.87 ms per token,   535.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.00 ms /    41 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.55 ms /    47 tokens (    1.56 ms per token,   638.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.87 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      82.71 ms /    77 tokens (    1.07 ms per token,   930.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.75 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     166.26 ms /   307 tokens (    0.54 ms per token,  1846.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     177.91 ms /   308 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      83.74 ms /    86 tokens (    0.97 ms per token,  1027.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.02 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      70.59 ms /    25 tokens (    2.82 ms per token,   354.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.36 ms /    26 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      81.61 ms /    73 tokens (    1.12 ms per token,   894.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.66 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      71.16 ms /    30 tokens (    2.37 ms per token,   421.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.05 ms /    31 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      85.27 ms /    93 tokens (    0.92 ms per token,  1090.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.66 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      67.75 ms /    15 tokens (    4.52 ms per token,   221.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.17 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     115.20 ms /   178 tokens (    0.65 ms per token,  1545.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.51 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.83 ms /   199 tokens (    0.60 ms per token,  1660.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.39 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      85.84 ms /    94 tokens (    0.91 ms per token,  1095.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.55 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.45 ms /    67 tokens (    1.20 ms per token,   832.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.28 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     132.88 ms /   254 tokens (    0.52 ms per token,  1911.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.84 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.17 ms /   120 tokens (    0.74 ms per token,  1345.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.64 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     166.49 ms /   306 tokens (    0.54 ms per token,  1837.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     178.14 ms /   307 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     128.14 ms /   236 tokens (    0.54 ms per token,  1841.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.19 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     116.50 ms /   186 tokens (    0.63 ms per token,  1596.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     123.81 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     123.73 ms /   217 tokens (    0.57 ms per token,  1753.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.94 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      81.62 ms /    72 tokens (    1.13 ms per token,   882.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.88 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.44 ms /    35 tokens (    2.07 ms per token,   483.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.58 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.63 ms /   262 tokens (    0.59 ms per token,  1683.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.78 ms /   263 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.05 ms /    45 tokens (    1.62 ms per token,   616.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.41 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     110.10 ms /   163 tokens (    0.68 ms per token,  1480.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.77 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.71 ms /   263 tokens (    0.59 ms per token,  1689.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     165.72 ms /   264 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      69.31 ms /    19 tokens (    3.65 ms per token,   274.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.98 ms /    20 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     103.81 ms /   140 tokens (    0.74 ms per token,  1348.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.61 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.21 ms /    54 tokens (    1.39 ms per token,   718.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.89 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      81.47 ms /    69 tokens (    1.18 ms per token,   846.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.24 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.98 ms /   123 tokens (    0.72 ms per token,  1382.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.41 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     167.49 ms /   308 tokens (    0.54 ms per token,  1838.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     179.83 ms /   309 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.86 ms /   109 tokens (    0.82 ms per token,  1226.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.09 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      82.79 ms /    68 tokens (    1.22 ms per token,   821.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.32 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.90 ms /    63 tokens (    1.22 ms per token,   819.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.65 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     111.92 ms /   171 tokens (    0.65 ms per token,  1527.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.82 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      90.03 ms /   113 tokens (    0.80 ms per token,  1255.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.35 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.15 ms /    50 tokens (    1.50 ms per token,   665.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.81 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     176.62 ms /   350 tokens (    0.50 ms per token,  1981.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     190.44 ms /   351 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     130.18 ms /   244 tokens (    0.53 ms per token,  1874.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.50 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     130.61 ms /   244 tokens (    0.54 ms per token,  1868.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.72 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     114.93 ms /   184 tokens (    0.62 ms per token,  1601.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.19 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.48 ms /   116 tokens (    0.75 ms per token,  1326.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.12 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.95 ms /    46 tokens (    1.61 ms per token,   622.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.41 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.40 ms /    37 tokens (    1.96 ms per token,   511.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.38 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      85.76 ms /    94 tokens (    0.91 ms per token,  1096.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.29 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      82.09 ms /    76 tokens (    1.08 ms per token,   925.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.14 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     160.25 ms /   281 tokens (    0.57 ms per token,  1753.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.23 ms /   282 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     159.41 ms /   280 tokens (    0.57 ms per token,  1756.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     169.46 ms /   281 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     162.77 ms /   291 tokens (    0.56 ms per token,  1787.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     173.06 ms /   292 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.09 ms /   261 tokens (    0.59 ms per token,  1682.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.98 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     111.11 ms /   167 tokens (    0.67 ms per token,  1503.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.39 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     113.08 ms /   175 tokens (    0.65 ms per token,  1547.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.85 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     122.80 ms /   185 tokens (    0.66 ms per token,  1506.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     129.05 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.95 ms /    53 tokens (    1.45 ms per token,   688.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.54 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     114.31 ms /   153 tokens (    0.75 ms per token,  1338.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.61 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     168.08 ms /   267 tokens (    0.63 ms per token,  1588.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     178.74 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     131.27 ms /   231 tokens (    0.57 ms per token,  1759.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.76 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     121.89 ms /   194 tokens (    0.63 ms per token,  1591.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.49 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     107.15 ms /   145 tokens (    0.74 ms per token,  1353.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     112.17 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     116.27 ms /   183 tokens (    0.64 ms per token,  1573.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     123.00 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      74.27 ms /    45 tokens (    1.65 ms per token,   605.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.66 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     125.78 ms /   219 tokens (    0.57 ms per token,  1741.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.23 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     157.03 ms /   267 tokens (    0.59 ms per token,  1700.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.44 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.76 ms /    61 tokens (    1.24 ms per token,   805.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.51 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.89 ms /   233 tokens (    0.55 ms per token,  1821.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.82 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      90.37 ms /   111 tokens (    0.81 ms per token,  1228.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.39 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.51 ms /   102 tokens (    0.87 ms per token,  1152.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.52 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     125.99 ms /   216 tokens (    0.58 ms per token,  1714.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.01 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.10 ms /   227 tokens (    0.56 ms per token,  1785.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     134.87 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     125.92 ms /   223 tokens (    0.56 ms per token,  1770.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.00 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     170.13 ms /   314 tokens (    0.54 ms per token,  1845.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     180.95 ms /   315 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.32 ms /    49 tokens (    1.54 ms per token,   650.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.30 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.70 ms /   100 tokens (    0.89 ms per token,  1127.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.77 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.21 ms /    97 tokens (    0.92 ms per token,  1087.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.00 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     168.32 ms /   294 tokens (    0.57 ms per token,  1746.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     179.18 ms /   295 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.03 ms /    43 tokens (    1.70 ms per token,   588.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.37 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     105.63 ms /   135 tokens (    0.78 ms per token,  1278.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     110.66 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      71.41 ms /    26 tokens (    2.75 ms per token,   364.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.34 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     168.58 ms /   285 tokens (    0.59 ms per token,  1690.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     179.91 ms /   286 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.91 ms /   114 tokens (    0.78 ms per token,  1282.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.46 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     112.47 ms /   161 tokens (    0.70 ms per token,  1431.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.89 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      69.99 ms /    12 tokens (    5.83 ms per token,   171.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.66 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      69.08 ms /    11 tokens (    6.28 ms per token,   159.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.62 ms /    12 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      85.98 ms /    85 tokens (    1.01 ms per token,   988.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.28 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     131.38 ms /   226 tokens (    0.58 ms per token,  1720.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.96 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     117.40 ms /   182 tokens (    0.65 ms per token,  1550.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     124.16 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     176.09 ms /   311 tokens (    0.57 ms per token,  1766.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     187.90 ms /   312 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     105.96 ms /   139 tokens (    0.76 ms per token,  1311.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     110.86 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     115.17 ms /   171 tokens (    0.67 ms per token,  1484.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.12 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     108.13 ms /   144 tokens (    0.75 ms per token,  1331.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     113.11 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.00 ms /   212 tokens (    0.60 ms per token,  1669.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.26 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     128.81 ms /   219 tokens (    0.59 ms per token,  1700.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.47 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     111.43 ms /   156 tokens (    0.71 ms per token,  1399.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.25 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     112.80 ms /   163 tokens (    0.69 ms per token,  1445.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.19 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     135.83 ms /   246 tokens (    0.55 ms per token,  1811.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.00 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.28 ms /   114 tokens (    0.78 ms per token,  1276.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.76 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     110.58 ms /   145 tokens (    0.76 ms per token,  1311.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     116.86 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.32 ms /    51 tokens (    1.50 ms per token,   668.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.96 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     120.97 ms /   185 tokens (    0.65 ms per token,  1529.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.34 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      77.68 ms /    58 tokens (    1.34 ms per token,   746.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.54 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.93 ms /    58 tokens (    1.33 ms per token,   753.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.51 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     108.07 ms /   136 tokens (    0.79 ms per token,  1258.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     113.36 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.83 ms /    48 tokens (    1.60 ms per token,   624.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.48 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      34.31 ms /     6 tokens (    5.72 ms per token,   174.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.47 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      92.53 ms /   106 tokens (    0.87 ms per token,  1145.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.33 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.63 ms /   198 tokens (    0.64 ms per token,  1551.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     134.24 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      83.74 ms /    72 tokens (    1.16 ms per token,   859.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.79 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.50 ms /    46 tokens (    1.64 ms per token,   609.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.69 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     110.07 ms /   141 tokens (    0.78 ms per token,  1281.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.05 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     121.14 ms /   186 tokens (    0.65 ms per token,  1535.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.14 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.62 ms /    96 tokens (    0.92 ms per token,  1083.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.66 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     132.14 ms /   217 tokens (    0.61 ms per token,  1642.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     139.40 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     132.58 ms /   222 tokens (    0.60 ms per token,  1674.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.03 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.69 ms /    96 tokens (    0.92 ms per token,  1082.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.85 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     168.74 ms /   263 tokens (    0.64 ms per token,  1558.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     177.71 ms /   264 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     106.13 ms /   131 tokens (    0.81 ms per token,  1234.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     111.35 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.96 ms /   213 tokens (    0.60 ms per token,  1664.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     134.90 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      84.12 ms /    75 tokens (    1.12 ms per token,   891.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.48 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     106.50 ms /   131 tokens (    0.81 ms per token,  1230.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     110.95 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     168.07 ms /   262 tokens (    0.64 ms per token,  1558.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     178.19 ms /   263 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     185.87 ms /   321 tokens (    0.58 ms per token,  1727.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     197.65 ms /   322 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      83.97 ms /    72 tokens (    1.17 ms per token,   857.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.13 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      91.18 ms /    97 tokens (    0.94 ms per token,  1063.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.91 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     128.07 ms /   193 tokens (    0.66 ms per token,  1507.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     134.58 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.15 ms /    94 tokens (    0.94 ms per token,  1066.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.95 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.43 ms /    30 tokens (    2.51 ms per token,   397.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.31 ms /    31 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.79 ms /    56 tokens (    1.37 ms per token,   729.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.48 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     224.11 ms /   385 tokens (    0.58 ms per token,  1717.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     238.68 ms /   386 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     173.03 ms /   276 tokens (    0.63 ms per token,  1595.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     182.28 ms /   277 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      93.57 ms /   108 tokens (    0.87 ms per token,  1154.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.85 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     171.59 ms /   263 tokens (    0.65 ms per token,  1532.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.05 ms /   264 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.23 ms /    27 tokens (    2.71 ms per token,   368.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.21 ms /    28 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     122.52 ms /   188 tokens (    0.65 ms per token,  1534.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.67 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     107.29 ms /   133 tokens (    0.81 ms per token,  1239.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     111.86 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     176.28 ms /   292 tokens (    0.60 ms per token,  1656.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     186.67 ms /   293 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      91.17 ms /   119 tokens (    0.77 ms per token,  1305.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      95.72 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     118.64 ms /   170 tokens (    0.70 ms per token,  1432.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     124.56 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     132.91 ms /   216 tokens (    0.62 ms per token,  1625.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.13 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      69.64 ms /    14 tokens (    4.97 ms per token,   201.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.08 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     128.69 ms /   195 tokens (    0.66 ms per token,  1515.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.04 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      77.30 ms /    55 tokens (    1.41 ms per token,   711.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.06 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     182.34 ms /   301 tokens (    0.61 ms per token,  1650.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     193.66 ms /   302 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     187.15 ms /   324 tokens (    0.58 ms per token,  1731.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.59 ms /   325 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     111.22 ms /   140 tokens (    0.79 ms per token,  1258.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     116.06 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.91 ms /    48 tokens (    1.60 ms per token,   624.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.67 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.47 ms /    35 tokens (    2.10 ms per token,   476.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.49 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.99 ms /    89 tokens (    0.99 ms per token,  1011.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.44 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.84 ms /    55 tokens (    1.40 ms per token,   715.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.52 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     137.53 ms /   230 tokens (    0.60 ms per token,  1672.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.63 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     117.27 ms /   171 tokens (    0.69 ms per token,  1458.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     122.97 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.15 ms /    51 tokens (    1.49 ms per token,   669.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.19 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.97 ms /    57 tokens (    1.35 ms per token,   740.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.54 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     119.72 ms /   184 tokens (    0.65 ms per token,  1536.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.61 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.87 ms /    56 tokens (    1.37 ms per token,   728.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.48 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     118.97 ms /   182 tokens (    0.65 ms per token,  1529.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.26 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     134.57 ms /   221 tokens (    0.61 ms per token,  1642.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.15 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      86.05 ms /    81 tokens (    1.06 ms per token,   941.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.40 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.09 ms /    76 tokens (    1.15 ms per token,   872.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.59 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      78.05 ms /    58 tokens (    1.35 ms per token,   743.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.67 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      92.64 ms /   122 tokens (    0.76 ms per token,  1316.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.14 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      91.54 ms /    92 tokens (    0.99 ms per token,  1005.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      95.00 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     112.30 ms /   144 tokens (    0.78 ms per token,  1282.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.40 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      28.38 ms /     4 tokens (    7.09 ms per token,   140.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.67 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      77.50 ms /    43 tokens (    1.80 ms per token,   554.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.71 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     120.60 ms /   169 tokens (    0.71 ms per token,  1401.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.60 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     141.14 ms /   238 tokens (    0.59 ms per token,  1686.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.12 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     114.15 ms /   148 tokens (    0.77 ms per token,  1296.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.36 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     133.35 ms /   210 tokens (    0.64 ms per token,  1574.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.25 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.25 ms /    49 tokens (    1.56 ms per token,   642.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.91 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.64 ms /    88 tokens (    1.02 ms per token,   981.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.15 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      93.95 ms /   127 tokens (    0.74 ms per token,  1351.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.59 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     177.78 ms /   282 tokens (    0.63 ms per token,  1586.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     187.87 ms /   283 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     109.25 ms /   130 tokens (    0.84 ms per token,  1189.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     114.11 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     142.75 ms /   238 tokens (    0.60 ms per token,  1667.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.14 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.66 ms /    85 tokens (    1.03 ms per token,   969.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.33 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      78.64 ms /    58 tokens (    1.36 ms per token,   737.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.35 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     117.29 ms /   156 tokens (    0.75 ms per token,  1330.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     122.74 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.97 ms /    88 tokens (    1.02 ms per token,   978.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.52 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.10 ms /    22 tokens (    3.32 ms per token,   300.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.09 ms /    23 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      93.33 ms /   103 tokens (    0.91 ms per token,  1103.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.37 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     176.84 ms /   269 tokens (    0.66 ms per token,  1521.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     186.80 ms /   270 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.30 ms /    41 tokens (    1.84 ms per token,   544.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.71 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     142.07 ms /   241 tokens (    0.59 ms per token,  1696.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.73 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     181.93 ms /   295 tokens (    0.62 ms per token,  1621.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     192.86 ms /   296 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     118.18 ms /   166 tokens (    0.71 ms per token,  1404.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     123.71 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     134.35 ms /   210 tokens (    0.64 ms per token,  1563.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.21 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      91.94 ms /   100 tokens (    0.92 ms per token,  1087.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      95.78 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     175.44 ms /   260 tokens (    0.67 ms per token,  1482.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     183.88 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      43.02 ms /     8 tokens (    5.38 ms per token,   185.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.69 ms /     9 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      96.02 ms /   121 tokens (    0.79 ms per token,  1260.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.31 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     175.23 ms /   260 tokens (    0.67 ms per token,  1483.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     184.03 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      85.22 ms /    71 tokens (    1.20 ms per token,   833.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.25 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.70 ms /    85 tokens (    1.06 ms per token,   947.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.03 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      79.64 ms /    61 tokens (    1.31 ms per token,   765.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.34 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      90.76 ms /    91 tokens (    1.00 ms per token,  1002.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.61 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.29 ms /    26 tokens (    2.82 ms per token,   354.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.25 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     115.29 ms /   148 tokens (    0.78 ms per token,  1283.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     120.58 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      70.10 ms /    12 tokens (    5.84 ms per token,   171.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.65 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      78.86 ms /    62 tokens (    1.27 ms per token,   786.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.61 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     123.18 ms /   178 tokens (    0.69 ms per token,  1444.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     129.40 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      93.17 ms /   120 tokens (    0.78 ms per token,  1287.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.57 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      90.26 ms /    91 tokens (    0.99 ms per token,  1008.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.79 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      70.33 ms /     9 tokens (    7.81 ms per token,   127.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.90 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      77.18 ms /    46 tokens (    1.68 ms per token,   596.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.43 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     114.71 ms /   148 tokens (    0.78 ms per token,  1290.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.86 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     115.20 ms /   163 tokens (    0.71 ms per token,  1414.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     120.89 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.92 ms /    92 tokens (    0.97 ms per token,  1034.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.55 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     173.48 ms /   261 tokens (    0.66 ms per token,  1504.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     183.58 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.51 ms /    86 tokens (    1.03 ms per token,   971.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.03 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.83 ms /    91 tokens (    0.99 ms per token,  1012.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.88 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.25 ms /    90 tokens (    0.99 ms per token,  1008.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.97 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     174.98 ms /   268 tokens (    0.65 ms per token,  1531.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     184.82 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     174.97 ms /   267 tokens (    0.66 ms per token,  1526.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     184.18 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     125.20 ms /   191 tokens (    0.66 ms per token,  1525.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.75 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      95.29 ms /   110 tokens (    0.87 ms per token,  1154.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.40 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     175.39 ms /   257 tokens (    0.68 ms per token,  1465.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     184.69 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     193.07 ms /   338 tokens (    0.57 ms per token,  1750.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.98 ms /   339 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      84.54 ms /    68 tokens (    1.24 ms per token,   804.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.74 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.80 ms /    27 tokens (    2.70 ms per token,   370.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.57 ms /    28 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     143.87 ms /   246 tokens (    0.58 ms per token,  1709.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.46 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     113.02 ms /   150 tokens (    0.75 ms per token,  1327.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.66 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     123.55 ms /   188 tokens (    0.66 ms per token,  1521.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.60 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     113.44 ms /   152 tokens (    0.75 ms per token,  1339.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.68 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.42 ms /    34 tokens (    2.16 ms per token,   463.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.39 ms /    35 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.09 ms /    82 tokens (    1.06 ms per token,   941.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.80 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.63 ms /    25 tokens (    2.91 ms per token,   344.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.64 ms /    26 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      85.92 ms /    72 tokens (    1.19 ms per token,   837.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.02 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.91 ms /    27 tokens (    2.74 ms per token,   365.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.85 ms /    28 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.44 ms /    57 tokens (    1.41 ms per token,   708.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.03 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     136.09 ms /   204 tokens (    0.67 ms per token,  1499.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.94 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      91.03 ms /    96 tokens (    0.95 ms per token,  1054.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      95.14 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      92.50 ms /    96 tokens (    0.96 ms per token,  1037.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.32 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     112.86 ms /   136 tokens (    0.83 ms per token,  1204.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.01 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     121.78 ms /   173 tokens (    0.70 ms per token,  1420.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.80 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     123.29 ms /   180 tokens (    0.68 ms per token,  1459.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     129.96 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      69.69 ms /    13 tokens (    5.36 ms per token,   186.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.22 ms /    14 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     145.64 ms /   256 tokens (    0.57 ms per token,  1757.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     154.56 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      84.00 ms /    67 tokens (    1.25 ms per token,   797.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.58 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      29.94 ms /     4 tokens (    7.49 ms per token,   133.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.02 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.25 ms /    81 tokens (    1.10 ms per token,   907.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.52 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     196.03 ms /   343 tokens (    0.57 ms per token,  1749.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     210.67 ms /   344 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     109.38 ms /   142 tokens (    0.77 ms per token,  1298.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     114.89 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      74.77 ms /    39 tokens (    1.92 ms per token,   521.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.23 ms /    40 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      93.29 ms /   111 tokens (    0.84 ms per token,  1189.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.51 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      91.81 ms /    97 tokens (    0.95 ms per token,  1056.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.03 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     115.64 ms /   146 tokens (    0.79 ms per token,  1262.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.19 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     112.50 ms /   132 tokens (    0.85 ms per token,  1173.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.19 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      93.65 ms /   105 tokens (    0.89 ms per token,  1121.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.68 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      78.94 ms /    56 tokens (    1.41 ms per token,   709.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.36 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      97.07 ms /   111 tokens (    0.87 ms per token,  1143.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.78 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      70.61 ms /    11 tokens (    6.42 ms per token,   155.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.12 ms /    12 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      94.06 ms /   116 tokens (    0.81 ms per token,  1233.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.41 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      90.03 ms /    86 tokens (    1.05 ms per token,   955.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.84 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     117.70 ms /   157 tokens (    0.75 ms per token,  1333.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     123.33 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     178.71 ms /   280 tokens (    0.64 ms per token,  1566.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     189.54 ms /   281 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     115.72 ms /   148 tokens (    0.78 ms per token,  1279.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.87 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      93.64 ms /   115 tokens (    0.81 ms per token,  1228.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.89 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     141.58 ms /   224 tokens (    0.63 ms per token,  1582.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.23 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     136.08 ms /   217 tokens (    0.63 ms per token,  1594.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.27 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      77.61 ms /    45 tokens (    1.72 ms per token,   579.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.34 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.21 ms /    14 tokens (    5.16 ms per token,   193.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.64 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     187.24 ms /   297 tokens (    0.63 ms per token,  1586.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.28 ms /   298 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     112.61 ms /   140 tokens (    0.80 ms per token,  1243.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.64 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     146.31 ms /   246 tokens (    0.59 ms per token,  1681.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.35 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     180.01 ms /   288 tokens (    0.63 ms per token,  1599.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     190.57 ms /   289 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      92.12 ms /   103 tokens (    0.89 ms per token,  1118.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.55 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     140.72 ms /   249 tokens (    0.57 ms per token,  1769.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.13 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     176.88 ms /   273 tokens (    0.65 ms per token,  1543.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     186.19 ms /   274 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     145.38 ms /   248 tokens (    0.59 ms per token,  1705.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.72 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     113.65 ms /   137 tokens (    0.83 ms per token,  1205.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.78 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     182.52 ms /   281 tokens (    0.65 ms per token,  1539.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     192.17 ms /   282 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     175.97 ms /   272 tokens (    0.65 ms per token,  1545.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     185.56 ms /   273 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      92.88 ms /   116 tokens (    0.80 ms per token,  1248.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.91 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     123.15 ms /   183 tokens (    0.67 ms per token,  1485.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     129.34 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     178.32 ms /   267 tokens (    0.67 ms per token,  1497.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.84 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     110.14 ms /   131 tokens (    0.84 ms per token,  1189.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     114.88 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     115.30 ms /   142 tokens (    0.81 ms per token,  1231.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     120.48 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.93 ms /    17 tokens (    4.35 ms per token,   229.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.65 ms /    18 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.57 ms /    32 tokens (    2.39 ms per token,   417.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.63 ms /    33 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     208.79 ms /   383 tokens (    0.55 ms per token,  1834.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.50 ms /   384 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     248.72 ms /   481 tokens (    0.52 ms per token,  1933.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     268.40 ms /   482 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     196.02 ms /   352 tokens (    0.56 ms per token,  1795.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     210.31 ms /   353 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.95 ms /    78 tokens (    1.13 ms per token,   886.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.73 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     137.91 ms /   213 tokens (    0.65 ms per token,  1544.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.06 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      95.43 ms /    98 tokens (    0.97 ms per token,  1026.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.47 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     181.54 ms /   280 tokens (    0.65 ms per token,  1542.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.09 ms /   281 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.60 ms /    79 tokens (    1.12 ms per token,   891.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.09 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     115.51 ms /   145 tokens (    0.80 ms per token,  1255.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.09 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.67 ms /    72 tokens (    1.23 ms per token,   812.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.63 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     114.58 ms /   139 tokens (    0.82 ms per token,  1213.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.44 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     122.53 ms /   172 tokens (    0.71 ms per token,  1403.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.35 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     134.34 ms /   212 tokens (    0.63 ms per token,  1578.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.33 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     184.78 ms /   298 tokens (    0.62 ms per token,  1612.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     195.36 ms /   299 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     145.06 ms /   252 tokens (    0.58 ms per token,  1737.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.98 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      78.86 ms /    52 tokens (    1.52 ms per token,   659.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.44 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      74.65 ms /    24 tokens (    3.11 ms per token,   321.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.29 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     121.03 ms /   164 tokens (    0.74 ms per token,  1355.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.76 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     141.81 ms /   232 tokens (    0.61 ms per token,  1636.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.20 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     179.50 ms /   269 tokens (    0.67 ms per token,  1498.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     189.11 ms /   270 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      83.11 ms /    66 tokens (    1.26 ms per token,   794.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.18 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     186.30 ms /   339 tokens (    0.55 ms per token,  1819.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.14 ms /   340 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.52 ms /    41 tokens (    1.87 ms per token,   535.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.78 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     182.63 ms /   290 tokens (    0.63 ms per token,  1587.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.84 ms /   291 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     184.69 ms /   292 tokens (    0.63 ms per token,  1581.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     195.08 ms /   293 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     113.40 ms /   132 tokens (    0.86 ms per token,  1164.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.25 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     137.12 ms /   209 tokens (    0.66 ms per token,  1524.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     144.38 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     120.85 ms /   169 tokens (    0.72 ms per token,  1398.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.59 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     179.04 ms /   272 tokens (    0.66 ms per token,  1519.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.93 ms /   273 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     183.49 ms /   293 tokens (    0.63 ms per token,  1596.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     195.46 ms /   294 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     182.17 ms /   294 tokens (    0.62 ms per token,  1613.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     193.36 ms /   295 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.75 ms /    84 tokens (    1.06 ms per token,   946.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.31 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      95.44 ms /   105 tokens (    0.91 ms per token,  1100.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.80 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      74.46 ms /    20 tokens (    3.72 ms per token,   268.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.30 ms /    21 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.46 ms /    69 tokens (    1.27 ms per token,   788.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.05 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     136.02 ms /   204 tokens (    0.67 ms per token,  1499.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.13 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      94.43 ms /   119 tokens (    0.79 ms per token,  1260.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.63 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     113.82 ms /   132 tokens (    0.86 ms per token,  1159.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.12 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.34 ms /    14 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.40 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     134.53 ms /   198 tokens (    0.68 ms per token,  1471.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.42 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      95.86 ms /   109 tokens (    0.88 ms per token,  1137.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.13 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      97.33 ms /   127 tokens (    0.77 ms per token,  1304.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.05 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.01 ms /    19 tokens (    3.84 ms per token,   260.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.15 ms /    20 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      87.94 ms /    71 tokens (    1.24 ms per token,   807.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.08 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      79.52 ms /    50 tokens (    1.59 ms per token,   628.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.14 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      78.83 ms /    49 tokens (    1.61 ms per token,   621.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.15 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      92.43 ms /    90 tokens (    1.03 ms per token,   973.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.13 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      93.20 ms /    96 tokens (    0.97 ms per token,  1030.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.96 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      81.99 ms /    62 tokens (    1.32 ms per token,   756.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.94 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      78.00 ms /    40 tokens (    1.95 ms per token,   512.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.12 ms /    41 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.03 ms /    28 tokens (    2.68 ms per token,   373.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.05 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      91.14 ms /    86 tokens (    1.06 ms per token,   943.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.96 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     144.93 ms /   242 tokens (    0.60 ms per token,  1669.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.42 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     133.80 ms /   203 tokens (    0.66 ms per token,  1517.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.63 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     116.08 ms /   152 tokens (    0.76 ms per token,  1309.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.41 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     118.68 ms /   156 tokens (    0.76 ms per token,  1314.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     123.87 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     116.79 ms /   148 tokens (    0.79 ms per token,  1267.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.92 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     147.38 ms /   254 tokens (    0.58 ms per token,  1723.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.60 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      77.16 ms /    42 tokens (    1.84 ms per token,   544.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.52 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     116.32 ms /   147 tokens (    0.79 ms per token,  1263.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.80 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     182.49 ms /   285 tokens (    0.64 ms per token,  1561.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     192.48 ms /   286 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      79.70 ms /    59 tokens (    1.35 ms per token,   740.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.60 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      91.84 ms /    91 tokens (    1.01 ms per token,   990.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      95.40 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      95.40 ms /   117 tokens (    0.82 ms per token,  1226.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.29 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.79 ms /    78 tokens (    1.15 ms per token,   868.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.19 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      96.37 ms /   110 tokens (    0.88 ms per token,  1141.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.55 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      95.83 ms /   106 tokens (    0.90 ms per token,  1106.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.20 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     126.21 ms /   186 tokens (    0.68 ms per token,  1473.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     132.55 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.46 ms /    37 tokens (    2.07 ms per token,   483.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.79 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     113.13 ms /   134 tokens (    0.84 ms per token,  1184.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.85 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      96.89 ms /   111 tokens (    0.87 ms per token,  1145.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.07 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     145.51 ms /   242 tokens (    0.60 ms per token,  1663.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     154.83 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     141.00 ms /   225 tokens (    0.63 ms per token,  1595.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.24 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      90.87 ms /    83 tokens (    1.09 ms per token,   913.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.36 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      34.87 ms /     5 tokens (    6.97 ms per token,   143.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.44 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     116.63 ms /   144 tokens (    0.81 ms per token,  1234.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     122.01 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      88.10 ms /    69 tokens (    1.28 ms per token,   783.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.40 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      93.94 ms /   114 tokens (    0.82 ms per token,  1213.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.46 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     143.39 ms /   236 tokens (    0.61 ms per token,  1645.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.95 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      95.13 ms /   104 tokens (    0.91 ms per token,  1093.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.53 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     179.37 ms /   268 tokens (    0.67 ms per token,  1494.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     190.70 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.23 ms /    35 tokens (    2.15 ms per token,   465.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.25 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     136.34 ms /   209 tokens (    0.65 ms per token,  1532.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     144.34 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     175.20 ms /   258 tokens (    0.68 ms per token,  1472.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     185.20 ms /   259 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      77.51 ms /    36 tokens (    2.15 ms per token,   464.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.58 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     137.85 ms /   208 tokens (    0.66 ms per token,  1508.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     144.98 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     117.61 ms /   139 tokens (    0.85 ms per token,  1181.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     122.63 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     125.85 ms /   167 tokens (    0.75 ms per token,  1326.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.91 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     149.07 ms /   236 tokens (    0.63 ms per token,  1583.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.81 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.87 ms /    81 tokens (    1.11 ms per token,   901.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.20 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     193.04 ms /   294 tokens (    0.66 ms per token,  1522.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.11 ms /   295 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      74.52 ms /    32 tokens (    2.33 ms per token,   429.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.55 ms /    33 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     188.19 ms /   278 tokens (    0.68 ms per token,  1477.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.53 ms /   279 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      74.28 ms /    30 tokens (    2.48 ms per token,   403.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.17 ms /    31 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     183.22 ms /   260 tokens (    0.70 ms per token,  1419.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     192.30 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     187.25 ms /   276 tokens (    0.68 ms per token,  1473.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     197.72 ms /   277 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      89.84 ms /    71 tokens (    1.27 ms per token,   790.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.89 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     148.02 ms /   234 tokens (    0.63 ms per token,  1580.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.26 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      93.72 ms /    97 tokens (    0.97 ms per token,  1034.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.65 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.40 ms /    60 tokens (    1.34 ms per token,   746.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.42 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     141.08 ms /   226 tokens (    0.62 ms per token,  1601.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.27 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     134.94 ms /   199 tokens (    0.68 ms per token,  1474.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.97 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     148.97 ms /   243 tokens (    0.61 ms per token,  1631.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.99 ms /   244 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     148.36 ms /   221 tokens (    0.67 ms per token,  1489.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.87 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     153.99 ms /   233 tokens (    0.66 ms per token,  1513.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.81 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     151.62 ms /   232 tokens (    0.65 ms per token,  1530.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.91 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      92.70 ms /    86 tokens (    1.08 ms per token,   927.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.72 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.50 ms /    31 tokens (    2.44 ms per token,   410.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.46 ms /    32 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      73.75 ms /    13 tokens (    5.67 ms per token,   176.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.16 ms /    14 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     144.96 ms /   205 tokens (    0.71 ms per token,  1414.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.94 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      95.91 ms /    98 tokens (    0.98 ms per token,  1021.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.80 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     100.08 ms /   110 tokens (    0.91 ms per token,  1099.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.23 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     151.50 ms /   224 tokens (    0.68 ms per token,  1478.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.71 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      98.35 ms /   105 tokens (    0.94 ms per token,  1067.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.66 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     204.72 ms /   305 tokens (    0.67 ms per token,  1489.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.43 ms /   306 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.18 ms /    53 tokens (    1.51 ms per token,   661.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.78 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      79.06 ms /    46 tokens (    1.72 ms per token,   581.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.28 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.01 ms /    55 tokens (    1.45 ms per token,   687.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.50 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     148.71 ms /   212 tokens (    0.70 ms per token,  1425.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.10 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      97.18 ms /   118 tokens (    0.82 ms per token,  1214.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.69 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     205.49 ms /   306 tokens (    0.67 ms per token,  1489.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.83 ms /   307 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     192.90 ms /   268 tokens (    0.72 ms per token,  1389.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     202.21 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.61 ms /    12 tokens (    6.05 ms per token,   165.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.24 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     154.84 ms /   236 tokens (    0.66 ms per token,  1524.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.76 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     152.78 ms /   234 tokens (    0.65 ms per token,  1531.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.55 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      95.64 ms /   117 tokens (    0.82 ms per token,  1223.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.79 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     145.93 ms /   203 tokens (    0.72 ms per token,  1391.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.95 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      78.16 ms /    44 tokens (    1.78 ms per token,   562.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.37 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.94 ms /    16 tokens (    4.56 ms per token,   219.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.72 ms /    17 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     151.45 ms /   224 tokens (    0.68 ms per token,  1479.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.91 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      90.26 ms /    74 tokens (    1.22 ms per token,   819.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.60 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      79.70 ms /    46 tokens (    1.73 ms per token,   577.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.50 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     143.60 ms /   195 tokens (    0.74 ms per token,  1357.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.04 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     202.99 ms /   306 tokens (    0.66 ms per token,  1507.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     214.78 ms /   307 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     152.64 ms /   231 tokens (    0.66 ms per token,  1513.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.24 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.14 ms /    53 tokens (    1.51 ms per token,   661.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.70 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     153.43 ms /   233 tokens (    0.66 ms per token,  1518.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.46 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     200.95 ms /   291 tokens (    0.69 ms per token,  1448.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.82 ms /   292 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     152.49 ms /   233 tokens (    0.65 ms per token,  1527.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.67 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     200.57 ms /   291 tokens (    0.69 ms per token,  1450.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.04 ms /   292 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     156.82 ms /   246 tokens (    0.64 ms per token,  1568.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.66 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     201.98 ms /   296 tokens (    0.68 ms per token,  1465.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     212.95 ms /   297 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     143.39 ms /   199 tokens (    0.72 ms per token,  1387.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.97 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     216.40 ms /   340 tokens (    0.64 ms per token,  1571.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     229.08 ms /   341 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.46 ms /    56 tokens (    1.44 ms per token,   695.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.35 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     136.11 ms /   191 tokens (    0.71 ms per token,  1403.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.30 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     185.65 ms /   274 tokens (    0.68 ms per token,  1475.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     196.18 ms /   275 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     262.70 ms /    49 tokens (    5.36 ms per token,   186.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     265.17 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     176.18 ms /    25 tokens (    7.05 ms per token,   141.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     179.80 ms /    26 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     115.63 ms /   142 tokens (    0.81 ms per token,  1228.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     120.81 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      77.01 ms /    33 tokens (    2.33 ms per token,   428.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.17 ms /    34 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      95.47 ms /   121 tokens (    0.79 ms per token,  1267.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.27 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     144.91 ms /   240 tokens (    0.60 ms per token,  1656.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     154.63 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     136.36 ms /   205 tokens (    0.67 ms per token,  1503.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.91 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     121.12 ms /   165 tokens (    0.73 ms per token,  1362.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.85 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      90.53 ms /    86 tokens (    1.05 ms per token,   949.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.00 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     182.91 ms /   284 tokens (    0.64 ms per token,  1552.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     193.01 ms /   285 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     147.39 ms /   254 tokens (    0.58 ms per token,  1723.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.53 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      96.70 ms /   125 tokens (    0.77 ms per token,  1292.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.21 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      78.34 ms /    42 tokens (    1.87 ms per token,   536.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.82 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.44 ms /    24 tokens (    3.14 ms per token,   318.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.41 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      92.19 ms /    91 tokens (    1.01 ms per token,   987.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      95.76 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      96.89 ms /   113 tokens (    0.86 ms per token,  1166.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.05 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     149.01 ms /   255 tokens (    0.58 ms per token,  1711.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     158.15 ms /   256 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     144.14 ms /   230 tokens (    0.63 ms per token,  1595.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.72 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     149.35 ms /   213 tokens (    0.70 ms per token,  1426.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.41 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     146.78 ms /   198 tokens (    0.74 ms per token,  1348.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.92 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.68 ms /   229 tokens (    0.68 ms per token,  1470.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.89 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     126.69 ms /   171 tokens (    0.74 ms per token,  1349.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.05 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     141.16 ms /   209 tokens (    0.68 ms per token,  1480.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     148.85 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     150.16 ms /   241 tokens (    0.62 ms per token,  1604.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.59 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     154.69 ms /   238 tokens (    0.65 ms per token,  1538.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.04 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     154.99 ms /   235 tokens (    0.66 ms per token,  1516.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.93 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     194.24 ms /   259 tokens (    0.75 ms per token,  1333.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     203.78 ms /   260 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     158.17 ms /   248 tokens (    0.64 ms per token,  1567.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.58 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     192.87 ms /   263 tokens (    0.73 ms per token,  1363.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     201.98 ms /   264 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     196.78 ms /   270 tokens (    0.73 ms per token,  1372.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.12 ms /   271 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     160.34 ms /   253 tokens (    0.63 ms per token,  1577.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     168.36 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     158.66 ms /   250 tokens (    0.63 ms per token,  1575.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     167.56 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     197.09 ms /   282 tokens (    0.70 ms per token,  1430.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     207.06 ms /   283 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     195.03 ms /   277 tokens (    0.70 ms per token,  1420.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.27 ms /   278 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     147.89 ms /   224 tokens (    0.66 ms per token,  1514.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.57 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     157.41 ms /   244 tokens (    0.65 ms per token,  1550.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     165.64 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     191.15 ms /   260 tokens (    0.74 ms per token,  1360.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     201.23 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     179.65 ms /   261 tokens (    0.69 ms per token,  1452.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.53 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     186.20 ms /   283 tokens (    0.66 ms per token,  1519.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     195.78 ms /   284 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     196.60 ms /   310 tokens (    0.63 ms per token,  1576.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     208.06 ms /   311 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     201.47 ms /   290 tokens (    0.69 ms per token,  1439.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     212.30 ms /   291 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     194.24 ms /   264 tokens (    0.74 ms per token,  1359.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     202.94 ms /   265 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     198.03 ms /   268 tokens (    0.74 ms per token,  1353.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     207.70 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      91.34 ms /    72 tokens (    1.27 ms per token,   788.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.94 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      42.24 ms /     6 tokens (    7.04 ms per token,   142.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.45 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      76.30 ms /    19 tokens (    4.02 ms per token,   249.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.82 ms /    20 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     149.44 ms /   209 tokens (    0.72 ms per token,  1398.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.07 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     136.58 ms /   186 tokens (    0.73 ms per token,  1361.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.14 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.12 ms /   152 tokens (    0.84 ms per token,  1195.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     132.64 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     147.43 ms /   198 tokens (    0.74 ms per token,  1343.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     154.55 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      90.93 ms /    69 tokens (    1.32 ms per token,   758.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.39 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     102.57 ms /   127 tokens (    0.81 ms per token,  1238.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.37 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     297.35 ms /   512 tokens (    0.58 ms per token,  1721.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     319.21 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     295.38 ms /   512 tokens (    0.58 ms per token,  1733.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     315.56 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     279.02 ms /   512 tokens (    0.54 ms per token,  1834.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     299.12 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     290.46 ms /   512 tokens (    0.57 ms per token,  1762.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     311.05 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     292.68 ms /   512 tokens (    0.57 ms per token,  1749.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     312.51 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     294.92 ms /   512 tokens (    0.58 ms per token,  1736.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     314.16 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     281.89 ms /   512 tokens (    0.55 ms per token,  1816.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     302.41 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     278.52 ms /   512 tokens (    0.54 ms per token,  1838.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     298.26 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     301.84 ms /   512 tokens (    0.59 ms per token,  1696.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     321.70 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     304.91 ms /   512 tokens (    0.60 ms per token,  1679.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     323.98 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     290.07 ms /   512 tokens (    0.57 ms per token,  1765.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     310.50 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     275.51 ms /   512 tokens (    0.54 ms per token,  1858.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     297.52 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     285.60 ms /   512 tokens (    0.56 ms per token,  1792.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     307.43 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     308.20 ms /   512 tokens (    0.60 ms per token,  1661.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     328.69 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     308.36 ms /   512 tokens (    0.60 ms per token,  1660.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     328.32 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     309.51 ms /   512 tokens (    0.60 ms per token,  1654.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     330.94 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     293.29 ms /   512 tokens (    0.57 ms per token,  1745.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     313.14 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     277.04 ms /   512 tokens (    0.54 ms per token,  1848.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     296.21 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     294.44 ms /   512 tokens (    0.58 ms per token,  1738.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     313.64 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     296.15 ms /   512 tokens (    0.58 ms per token,  1728.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     316.44 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     296.37 ms /   512 tokens (    0.58 ms per token,  1727.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     315.65 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     281.17 ms /   512 tokens (    0.55 ms per token,  1820.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     300.44 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     280.00 ms /   512 tokens (    0.55 ms per token,  1828.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     301.07 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     294.60 ms /   512 tokens (    0.58 ms per token,  1737.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     314.91 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     298.71 ms /   512 tokens (    0.58 ms per token,  1714.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     319.00 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     283.35 ms /   512 tokens (    0.55 ms per token,  1806.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     304.30 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     281.83 ms /   512 tokens (    0.55 ms per token,  1816.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     301.37 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     296.45 ms /   512 tokens (    0.58 ms per token,  1727.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     317.25 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     296.34 ms /   512 tokens (    0.58 ms per token,  1727.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     316.11 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     282.90 ms /   512 tokens (    0.55 ms per token,  1809.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     301.86 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     268.38 ms /   512 tokens (    0.52 ms per token,  1907.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     287.54 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     290.57 ms /   512 tokens (    0.57 ms per token,  1762.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     310.32 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     297.48 ms /   512 tokens (    0.58 ms per token,  1721.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     316.48 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     282.00 ms /   512 tokens (    0.55 ms per token,  1815.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     302.04 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     267.29 ms /   512 tokens (    0.52 ms per token,  1915.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     286.71 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     285.36 ms /   512 tokens (    0.56 ms per token,  1794.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     304.85 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     307.11 ms /   512 tokens (    0.60 ms per token,  1667.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     327.01 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     309.29 ms /   512 tokens (    0.60 ms per token,  1655.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     328.13 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     293.27 ms /   512 tokens (    0.57 ms per token,  1745.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     313.57 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     275.45 ms /   512 tokens (    0.54 ms per token,  1858.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     296.28 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     291.53 ms /   512 tokens (    0.57 ms per token,  1756.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     313.04 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     293.38 ms /   512 tokens (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     312.40 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     295.90 ms /   512 tokens (    0.58 ms per token,  1730.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     314.77 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     280.44 ms /   512 tokens (    0.55 ms per token,  1825.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     299.83 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     278.25 ms /   512 tokens (    0.54 ms per token,  1840.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     297.98 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     291.04 ms /   512 tokens (    0.57 ms per token,  1759.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     310.33 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     295.01 ms /   512 tokens (    0.58 ms per token,  1735.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     316.64 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     282.57 ms /   512 tokens (    0.55 ms per token,  1811.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     303.55 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     291.09 ms /   512 tokens (    0.57 ms per token,  1758.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     310.48 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     291.79 ms /   512 tokens (    0.57 ms per token,  1754.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     311.69 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     292.34 ms /   512 tokens (    0.57 ms per token,  1751.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     313.10 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     282.12 ms /   512 tokens (    0.55 ms per token,  1814.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     302.91 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     280.22 ms /   512 tokens (    0.55 ms per token,  1827.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     300.76 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     295.06 ms /   512 tokens (    0.58 ms per token,  1735.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     314.85 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     295.58 ms /   512 tokens (    0.58 ms per token,  1732.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     316.02 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     298.16 ms /   512 tokens (    0.58 ms per token,  1717.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     318.07 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     282.45 ms /   512 tokens (    0.55 ms per token,  1812.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     303.07 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     268.63 ms /   512 tokens (    0.52 ms per token,  1905.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     287.90 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     288.94 ms /   512 tokens (    0.56 ms per token,  1772.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     308.47 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     135.06 ms /   171 tokens (    0.79 ms per token,  1266.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.73 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      71.68 ms /    10 tokens (    7.17 ms per token,   139.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.09 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     127.57 ms /   147 tokens (    0.87 ms per token,  1152.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.19 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     213.05 ms /   305 tokens (    0.70 ms per token,  1431.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     224.21 ms /   306 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     288.88 ms /   474 tokens (    0.61 ms per token,  1640.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     307.38 ms /   475 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.64 ms /   223 tokens (    0.70 ms per token,  1432.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.67 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     159.82 ms /   236 tokens (    0.68 ms per token,  1476.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     167.44 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     130.53 ms /   155 tokens (    0.84 ms per token,  1187.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.04 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     123.81 ms /   135 tokens (    0.92 ms per token,  1090.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.97 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     134.80 ms /   162 tokens (    0.83 ms per token,  1201.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.66 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.54 ms /   218 tokens (    0.71 ms per token,  1401.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.58 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      99.13 ms /   117 tokens (    0.85 ms per token,  1180.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.05 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     160.37 ms /   238 tokens (    0.67 ms per token,  1484.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     168.50 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     156.95 ms /   233 tokens (    0.67 ms per token,  1484.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.88 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     155.84 ms /   236 tokens (    0.66 ms per token,  1514.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     165.51 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     185.68 ms /   267 tokens (    0.70 ms per token,  1437.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     196.33 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     179.52 ms /   273 tokens (    0.66 ms per token,  1520.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     189.32 ms /   274 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     139.53 ms /   227 tokens (    0.61 ms per token,  1626.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     148.48 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      78.27 ms /    45 tokens (    1.74 ms per token,   574.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.98 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      95.80 ms /    83 tokens (    1.15 ms per token,   866.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.33 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     129.00 ms /   156 tokens (    0.83 ms per token,  1209.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     134.61 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     200.06 ms /   275 tokens (    0.73 ms per token,  1374.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     210.51 ms /   276 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     128.87 ms /   144 tokens (    0.89 ms per token,  1117.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     134.20 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.46 ms /    42 tokens (    1.92 ms per token,   521.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.89 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     129.26 ms /   133 tokens (    0.97 ms per token,  1028.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     134.21 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     216.22 ms /   291 tokens (    0.74 ms per token,  1345.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     227.30 ms /   292 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     166.80 ms /   245 tokens (    0.68 ms per token,  1468.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     175.23 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.20 ms /    56 tokens (    1.43 ms per token,   698.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.13 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      92.68 ms /    82 tokens (    1.13 ms per token,   884.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.17 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     152.06 ms /   224 tokens (    0.68 ms per token,  1473.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.89 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     137.58 ms /   192 tokens (    0.72 ms per token,  1395.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     144.37 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      95.56 ms /    99 tokens (    0.97 ms per token,  1036.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.60 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     172.94 ms /   250 tokens (    0.69 ms per token,  1445.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.78 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     218.18 ms /   295 tokens (    0.74 ms per token,  1352.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     229.49 ms /   296 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     170.63 ms /   247 tokens (    0.69 ms per token,  1447.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     178.96 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     144.57 ms /   183 tokens (    0.79 ms per token,  1265.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.97 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     208.52 ms /   270 tokens (    0.77 ms per token,  1294.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.70 ms /   271 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     143.32 ms /   178 tokens (    0.81 ms per token,  1241.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.55 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     142.84 ms /   180 tokens (    0.79 ms per token,  1260.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.21 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     138.45 ms /   160 tokens (    0.87 ms per token,  1155.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     144.96 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     158.09 ms /   211 tokens (    0.75 ms per token,  1334.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     165.55 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     165.00 ms /   228 tokens (    0.72 ms per token,  1381.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     173.28 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     153.07 ms /   221 tokens (    0.69 ms per token,  1443.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.91 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      97.65 ms /   116 tokens (    0.84 ms per token,  1187.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.25 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     152.96 ms /   218 tokens (    0.70 ms per token,  1425.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.08 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     149.15 ms /   189 tokens (    0.79 ms per token,  1267.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.39 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     145.80 ms /   176 tokens (    0.83 ms per token,  1207.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.83 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     216.70 ms /   278 tokens (    0.78 ms per token,  1282.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     226.98 ms /   279 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     221.24 ms /   294 tokens (    0.75 ms per token,  1328.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     232.29 ms /   295 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     147.51 ms /   184 tokens (    0.80 ms per token,  1247.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.94 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     135.70 ms /   142 tokens (    0.96 ms per token,  1046.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.71 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     236.68 ms /   331 tokens (    0.72 ms per token,  1398.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.99 ms /   332 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     325.15 ms /   512 tokens (    0.64 ms per token,  1574.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     345.77 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     318.68 ms /   501 tokens (    0.64 ms per token,  1572.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     338.36 ms /   502 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     240.00 ms /   348 tokens (    0.69 ms per token,  1449.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.76 ms /   349 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      98.19 ms /   101 tokens (    0.97 ms per token,  1028.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.53 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     202.50 ms /   286 tokens (    0.71 ms per token,  1412.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     212.86 ms /   287 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      75.86 ms /    27 tokens (    2.81 ms per token,   355.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.75 ms /    28 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      82.81 ms /    61 tokens (    1.36 ms per token,   736.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.83 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      72.24 ms /    10 tokens (    7.22 ms per token,   138.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.70 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      78.50 ms /    38 tokens (    2.07 ms per token,   484.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.53 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     157.50 ms /   227 tokens (    0.69 ms per token,  1441.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     165.71 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      96.42 ms /    74 tokens (    1.30 ms per token,   767.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.84 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     219.93 ms /   266 tokens (    0.83 ms per token,  1209.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     229.52 ms /   267 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     169.40 ms /   218 tokens (    0.78 ms per token,  1286.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     176.55 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     218.20 ms /   264 tokens (    0.83 ms per token,  1209.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     227.57 ms /   265 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     216.02 ms /   268 tokens (    0.81 ms per token,  1240.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     226.34 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     105.52 ms /   121 tokens (    0.87 ms per token,  1146.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     110.62 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     216.60 ms /   268 tokens (    0.81 ms per token,  1237.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     228.21 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     102.31 ms /   100 tokens (    1.02 ms per token,   977.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.04 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     178.07 ms /   247 tokens (    0.72 ms per token,  1387.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     187.81 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     174.17 ms /   248 tokens (    0.70 ms per token,  1423.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     182.90 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     103.06 ms /    93 tokens (    1.11 ms per token,   902.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     106.87 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     154.89 ms /   190 tokens (    0.82 ms per token,  1226.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.25 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     150.22 ms /   178 tokens (    0.84 ms per token,  1184.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.37 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     164.71 ms /   205 tokens (    0.80 ms per token,  1244.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     172.30 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     148.93 ms /   171 tokens (    0.87 ms per token,  1148.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     154.86 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     171.96 ms /   224 tokens (    0.77 ms per token,  1302.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     180.22 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     139.43 ms /   147 tokens (    0.95 ms per token,  1054.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     144.71 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     151.53 ms /   186 tokens (    0.81 ms per token,  1227.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     158.22 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     102.05 ms /    97 tokens (    1.05 ms per token,   950.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     106.04 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     170.63 ms /   224 tokens (    0.76 ms per token,  1312.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     179.23 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      84.21 ms /    56 tokens (    1.50 ms per token,   664.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.39 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     221.74 ms /   274 tokens (    0.81 ms per token,  1235.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     231.91 ms /   275 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     179.91 ms /   256 tokens (    0.70 ms per token,  1422.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     189.05 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      80.17 ms /    31 tokens (    2.59 ms per token,   386.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.40 ms /    32 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     145.53 ms /   158 tokens (    0.92 ms per token,  1085.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.14 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      86.03 ms /    55 tokens (    1.56 ms per token,   639.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.91 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     219.26 ms /   265 tokens (    0.83 ms per token,  1208.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     228.60 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      82.17 ms /    48 tokens (    1.71 ms per token,   584.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.40 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     103.66 ms /    94 tokens (    1.10 ms per token,   906.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.35 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     101.14 ms /    81 tokens (    1.25 ms per token,   800.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.79 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     100.98 ms /    73 tokens (    1.38 ms per token,   722.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.25 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     106.08 ms /   116 tokens (    0.91 ms per token,  1093.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     110.93 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      42.33 ms /     6 tokens (    7.05 ms per token,   141.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.68 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     105.78 ms /    85 tokens (    1.24 ms per token,   803.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.25 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      97.74 ms /    65 tokens (    1.50 ms per token,   665.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.06 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      86.11 ms /    54 tokens (    1.59 ms per token,   627.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.90 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     147.53 ms /   161 tokens (    0.92 ms per token,  1091.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.42 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =     162.73 ms /   194 tokens (    0.84 ms per token,  1192.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     169.59 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =    2423.91 ms\n",
      "llama_perf_context_print: prompt eval time =      74.96 ms /    13 tokens (    5.77 ms per token,   173.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.67 ms /    14 tokens\n",
      "llama_model_load_from_file_impl: using device CUDA0 (NVIDIA RTX A3000 12GB Laptop GPU) - 8474 MiB free\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Embedding generation for Phi-3-mini-4k-instruct-q4] 179.04s\n",
      "‚úî Saved embeddings to /workspaces/VectorVet/embeddings/Phi-3-mini-4k-instruct-q4_20news_chunks.npy\n",
      "‚Üí Embedding with Llama-3.2-1B-Instruct.Q6_K ‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 35 key-value pairs and 147 tensors from /workspaces/VectorVet/models/Llama-3.2-1B-Instruct.Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Models Meta Llama Llama 3.2 1B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = models-meta-llama-Llama-3.2\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 1B\n",
      "llama_model_loader: - kv   6:                            general.license str              = llama3.2\n",
      "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   9:                          llama.block_count u32              = 16\n",
      "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 2048\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  17:                 llama.attention.key_length u32              = 64\n",
      "llama_model_loader: - kv  18:               llama.attention.value_length u32              = 64\n",
      "llama_model_loader: - kv  19:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  20:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  21:                 llama.rope.dimension_count u32              = 64\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,280147]  = [\"ƒ† ƒ†\", \"ƒ† ƒ†ƒ†ƒ†\", \"ƒ†ƒ† ƒ†ƒ†\", \"...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  29:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  30:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  31:                      quantize.imatrix.file str              = ./Llama-3.2-1B-Instruct-GGUF_imatrix.dat\n",
      "llama_model_loader: - kv  32:                   quantize.imatrix.dataset str              = group_40.txt\n",
      "llama_model_loader: - kv  33:             quantize.imatrix.entries_count i32              = 112\n",
      "llama_model_loader: - kv  34:              quantize.imatrix.chunks_count i32              = 68\n",
      "llama_model_loader: - type  f32:   34 tensors\n",
      "llama_model_loader: - type q6_K:  113 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q6_K\n",
      "print_info: file size   = 967.00 MiB (6.56 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 2048\n",
      "print_info: n_layer          = 16\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 64\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 64\n",
      "print_info: n_embd_head_v    = 64\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 512\n",
      "print_info: n_embd_v_gqa     = 512\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 1B\n",
      "print_info: model params     = 1.24 B\n",
      "print_info: general.name     = Models Meta Llama Llama 3.2 1B Instruct\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'ƒä'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CUDA0\n",
      "load_tensors: layer   1 assigned to device CUDA0\n",
      "load_tensors: layer   2 assigned to device CUDA0\n",
      "load_tensors: layer   3 assigned to device CUDA0\n",
      "load_tensors: layer   4 assigned to device CUDA0\n",
      "load_tensors: layer   5 assigned to device CUDA0\n",
      "load_tensors: layer   6 assigned to device CUDA0\n",
      "load_tensors: layer   7 assigned to device CUDA0\n",
      "load_tensors: layer   8 assigned to device CUDA0\n",
      "load_tensors: layer   9 assigned to device CUDA0\n",
      "load_tensors: layer  10 assigned to device CUDA0\n",
      "load_tensors: layer  11 assigned to device CUDA0\n",
      "load_tensors: layer  12 assigned to device CUDA0\n",
      "load_tensors: layer  13 assigned to device CUDA0\n",
      "load_tensors: layer  14 assigned to device CUDA0\n",
      "load_tensors: layer  15 assigned to device CUDA0\n",
      "load_tensors: layer  16 assigned to device CUDA0\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 0 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors: offloading 16 repeating layers to GPU\n",
      "load_tensors: offloading output layer to GPU\n",
      "load_tensors: offloaded 17/17 layers to GPU\n",
      "load_tensors:        CUDA0 model buffer size =   967.00 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =   205.49 MiB\n",
      "............................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 512\n",
      "llama_init_from_model: n_ctx_per_seq = 512\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 500000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 16, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 512, n_embd_v_gqa = 512\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =    16.00 MiB\n",
      "llama_init_from_model: KV self size  =   16.00 MiB, K (f16):    8.00 MiB, V (f16):    8.00 MiB\n",
      "llama_init_from_model:  CUDA_Host  output buffer size =     0.01 MiB\n",
      "llama_init_from_model:      CUDA0 compute buffer size =   254.50 MiB\n",
      "llama_init_from_model:  CUDA_Host compute buffer size =     5.01 MiB\n",
      "llama_init_from_model: graph nodes  = 518\n",
      "llama_init_from_model: graph splits = 2\n",
      "CUDA : ARCHS = 520 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'llama.embedding_length': '2048', 'llama.feed_forward_length': '8192', 'general.license': 'llama3.2', 'llama.attention.value_length': '64', 'general.size_label': '1B', 'general.type': 'model', 'quantize.imatrix.chunks_count': '68', 'llama.context_length': '131072', 'general.name': 'Models Meta Llama Llama 3.2 1B Instruct', 'tokenizer.ggml.bos_token_id': '128000', 'general.basename': 'models-meta-llama-Llama-3.2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'llama.block_count': '16', 'llama.attention.head_count': '32', 'llama.attention.key_length': '64', 'general.finetune': 'Instruct', 'general.file_type': '18', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.vocab_size': '128256', 'tokenizer.ggml.model': 'gpt2', 'general.quantization_version': '2', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.eos_token_id': '128009', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'llama.rope.dimension_count': '64', 'quantize.imatrix.file': './Llama-3.2-1B-Instruct-GGUF_imatrix.dat', 'quantize.imatrix.dataset': 'group_40.txt', 'llama.attention.head_count_kv': '8', 'quantize.imatrix.entries_count': '112'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c137d4ab3844d3b9348134819decced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding (Llama-3.2-1B-Instruct.Q6_K):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      79.33 ms /   122 tokens (    0.65 ms per token,  1537.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.35 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.45 ms /   116 tokens (    0.27 ms per token,  3688.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.27 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.23 ms /   182 tokens (    0.22 ms per token,  4639.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.16 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.96 ms /   234 tokens (    0.19 ms per token,  5204.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.09 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.28 ms /    26 tokens (    0.97 ms per token,  1028.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.46 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.50 ms /   114 tokens (    0.28 ms per token,  3618.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.67 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.40 ms /   104 tokens (    0.30 ms per token,  3311.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.85 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.91 ms /   103 tokens (    0.29 ms per token,  3443.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.44 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.58 ms /    14 tokens (    1.90 ms per token,   526.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.20 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      56.70 ms /   313 tokens (    0.18 ms per token,  5520.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      63.10 ms /   314 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.41 ms /   158 tokens (    0.24 ms per token,  4223.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.16 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.99 ms /    48 tokens (    0.56 ms per token,  1778.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.55 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.78 ms /   227 tokens (    0.19 ms per token,  5185.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.80 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.46 ms /   198 tokens (    0.21 ms per token,  4776.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.86 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.89 ms /   190 tokens (    0.20 ms per token,  4885.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.47 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.72 ms /   205 tokens (    0.20 ms per token,  5034.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.54 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.84 ms /   224 tokens (    0.19 ms per token,  5229.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.60 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =       8.39 ms /     2 tokens (    4.19 ms per token,   238.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =       9.00 ms /     3 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.49 ms /   148 tokens (    0.24 ms per token,  4170.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.78 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.23 ms /   240 tokens (    0.18 ms per token,  5426.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.45 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.71 ms /   156 tokens (    0.23 ms per token,  4368.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.64 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.92 ms /   105 tokens (    0.28 ms per token,  3509.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.45 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.80 ms /   248 tokens (    0.18 ms per token,  5662.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.02 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.76 ms /    33 tokens (    0.81 ms per token,  1233.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.96 ms /    34 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      54.65 ms /   309 tokens (    0.18 ms per token,  5653.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      61.23 ms /   310 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.50 ms /    68 tokens (    0.40 ms per token,  2472.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.28 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.81 ms /   128 tokens (    0.24 ms per token,  4155.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.79 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.34 ms /   180 tokens (    0.21 ms per token,  4820.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.21 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.85 ms /   174 tokens (    0.22 ms per token,  4479.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.97 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.56 ms /   238 tokens (    0.18 ms per token,  5463.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.44 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      51.04 ms /   260 tokens (    0.20 ms per token,  5094.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.91 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.26 ms /   250 tokens (    0.18 ms per token,  5648.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.77 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.45 ms /   242 tokens (    0.18 ms per token,  5444.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.53 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.81 ms /   250 tokens (    0.18 ms per token,  5706.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.01 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      51.36 ms /   268 tokens (    0.19 ms per token,  5217.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.92 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.66 ms /   240 tokens (    0.18 ms per token,  5496.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.72 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.63 ms /   214 tokens (    0.19 ms per token,  5140.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.53 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.62 ms /   234 tokens (    0.19 ms per token,  5364.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.79 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.66 ms /   167 tokens (    0.23 ms per token,  4434.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.42 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      34.19 ms /   131 tokens (    0.26 ms per token,  3831.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      37.05 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      51.00 ms /   258 tokens (    0.20 ms per token,  5058.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.36 ms /   259 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.63 ms /    49 tokens (    0.54 ms per token,  1840.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.92 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.01 ms /   133 tokens (    0.26 ms per token,  3798.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.06 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.22 ms /   217 tokens (    0.19 ms per token,  5139.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.59 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.23 ms /    44 tokens (    0.62 ms per token,  1615.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.54 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.84 ms /    53 tokens (    0.51 ms per token,  1974.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.24 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.09 ms /    86 tokens (    0.34 ms per token,  2956.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.12 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.19 ms /   173 tokens (    0.21 ms per token,  4652.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.11 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.98 ms /   214 tokens (    0.20 ms per token,  4979.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.35 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      24.41 ms /    17 tokens (    1.44 ms per token,   696.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      25.30 ms /    18 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.40 ms /   237 tokens (    0.19 ms per token,  5337.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.25 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.18 ms /   203 tokens (    0.20 ms per token,  5052.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.46 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.76 ms /   108 tokens (    0.28 ms per token,  3510.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.28 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.88 ms /   185 tokens (    0.20 ms per token,  4883.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.93 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.05 ms /   222 tokens (    0.19 ms per token,  5157.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.91 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.70 ms /    77 tokens (    0.37 ms per token,  2682.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.89 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.73 ms /    37 tokens (    0.70 ms per token,  1437.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.96 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.00 ms /   232 tokens (    0.19 ms per token,  5395.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.89 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.99 ms /    64 tokens (    0.42 ms per token,  2371.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.01 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.85 ms /    37 tokens (    0.70 ms per token,  1431.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.03 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.99 ms /    96 tokens (    0.30 ms per token,  3311.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.30 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.81 ms /   193 tokens (    0.21 ms per token,  4847.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.93 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.85 ms /   187 tokens (    0.21 ms per token,  4813.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.88 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.69 ms /   171 tokens (    0.21 ms per token,  4660.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.64 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.29 ms /   190 tokens (    0.20 ms per token,  4962.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.55 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.19 ms /   110 tokens (    0.29 ms per token,  3416.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.82 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.73 ms /   220 tokens (    0.19 ms per token,  5272.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.72 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.11 ms /   169 tokens (    0.21 ms per token,  4680.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.85 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.88 ms /   229 tokens (    0.19 ms per token,  5218.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.77 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.29 ms /   203 tokens (    0.20 ms per token,  4916.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.76 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.23 ms /   227 tokens (    0.19 ms per token,  5374.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.07 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.17 ms /    58 tokens (    0.49 ms per token,  2058.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.75 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =       9.65 ms /     3 tokens (    3.22 ms per token,   310.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      10.22 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.09 ms /    57 tokens (    0.49 ms per token,  2029.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.72 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      24.56 ms /    14 tokens (    1.75 ms per token,   570.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      25.30 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      51.97 ms /   261 tokens (    0.20 ms per token,  5022.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.41 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.51 ms /   174 tokens (    0.21 ms per token,  4765.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.18 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.13 ms /   220 tokens (    0.19 ms per token,  5221.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.98 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.98 ms /    75 tokens (    0.39 ms per token,  2587.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.09 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.98 ms /    55 tokens (    0.51 ms per token,  1965.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.44 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.39 ms /    26 tokens (    1.01 ms per token,   985.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.32 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.16 ms /   123 tokens (    0.25 ms per token,  3947.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.31 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.81 ms /    60 tokens (    0.48 ms per token,  2082.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.41 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.39 ms /    85 tokens (    0.33 ms per token,  2993.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.56 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.98 ms /   230 tokens (    0.19 ms per token,  5351.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.76 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.96 ms /   208 tokens (    0.20 ms per token,  5078.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.11 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.26 ms /    59 tokens (    0.46 ms per token,  2164.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.83 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.80 ms /   122 tokens (    0.25 ms per token,  3961.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.67 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.42 ms /   223 tokens (    0.19 ms per token,  5257.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.20 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.42 ms /   237 tokens (    0.18 ms per token,  5457.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.47 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.75 ms /   197 tokens (    0.20 ms per token,  4956.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.01 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.33 ms /   186 tokens (    0.21 ms per token,  4852.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.63 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.65 ms /   240 tokens (    0.18 ms per token,  5498.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.80 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.55 ms /    99 tokens (    0.30 ms per token,  3350.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.03 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.52 ms /   139 tokens (    0.26 ms per token,  3913.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.61 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.47 ms /    31 tokens (    0.82 ms per token,  1217.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.48 ms /    32 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.48 ms /    83 tokens (    0.36 ms per token,  2815.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.62 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.74 ms /   160 tokens (    0.22 ms per token,  4477.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.22 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.02 ms /   217 tokens (    0.19 ms per token,  5164.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.80 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.73 ms /    79 tokens (    0.36 ms per token,  2750.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.91 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.55 ms /   211 tokens (    0.20 ms per token,  5078.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.35 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.41 ms /   256 tokens (    0.17 ms per token,  5764.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.20 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      63.14 ms /   371 tokens (    0.17 ms per token,  5875.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.26 ms /   372 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.40 ms /   209 tokens (    0.20 ms per token,  5048.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.04 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.28 ms /   222 tokens (    0.19 ms per token,  5250.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.16 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.62 ms /   153 tokens (    0.23 ms per token,  4295.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.17 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.84 ms /   224 tokens (    0.19 ms per token,  5228.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.57 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.42 ms /   236 tokens (    0.18 ms per token,  5435.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.64 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.96 ms /   174 tokens (    0.21 ms per token,  4707.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.98 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.70 ms /   142 tokens (    0.25 ms per token,  3977.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.96 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.37 ms /   112 tokens (    0.28 ms per token,  3570.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.01 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.15 ms /    28 tokens (    0.93 ms per token,  1070.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.32 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.87 ms /   231 tokens (    0.19 ms per token,  5388.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.52 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.92 ms /    61 tokens (    0.44 ms per token,  2265.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.90 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.93 ms /    42 tokens (    0.64 ms per token,  1559.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.21 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.02 ms /    87 tokens (    0.33 ms per token,  2998.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.15 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.65 ms /   146 tokens (    0.24 ms per token,  4095.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.11 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.35 ms /   207 tokens (    0.20 ms per token,  5006.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.87 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.77 ms /    87 tokens (    0.34 ms per token,  2922.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.98 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.68 ms /   172 tokens (    0.22 ms per token,  4565.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.98 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.61 ms /   182 tokens (    0.21 ms per token,  4714.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.80 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.36 ms /   187 tokens (    0.21 ms per token,  4875.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.54 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.27 ms /   198 tokens (    0.20 ms per token,  4917.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.86 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.42 ms /   168 tokens (    0.22 ms per token,  4612.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.41 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.98 ms /   183 tokens (    0.21 ms per token,  4818.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.37 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.48 ms /    42 tokens (    0.63 ms per token,  1586.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.90 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.17 ms /   256 tokens (    0.18 ms per token,  5667.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.72 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.21 ms /   203 tokens (    0.20 ms per token,  4925.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.16 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.23 ms /   141 tokens (    0.25 ms per token,  4001.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.69 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.41 ms /   217 tokens (    0.20 ms per token,  5116.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.41 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.03 ms /   185 tokens (    0.21 ms per token,  4864.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.27 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.60 ms /   211 tokens (    0.20 ms per token,  5071.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.21 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.21 ms /   112 tokens (    0.29 ms per token,  3477.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.97 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.93 ms /   116 tokens (    0.27 ms per token,  3750.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.88 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.30 ms /   166 tokens (    0.22 ms per token,  4450.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.04 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.65 ms /   215 tokens (    0.19 ms per token,  5161.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.47 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.59 ms /   181 tokens (    0.21 ms per token,  4815.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.98 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      51.74 ms /   266 tokens (    0.19 ms per token,  5140.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.77 ms /   267 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.32 ms /    46 tokens (    0.59 ms per token,  1683.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.79 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.10 ms /   223 tokens (    0.19 ms per token,  5297.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.12 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.35 ms /   194 tokens (    0.21 ms per token,  4807.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.83 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.32 ms /   226 tokens (    0.19 ms per token,  5340.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.70 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.23 ms /   200 tokens (    0.21 ms per token,  4850.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.73 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.41 ms /   165 tokens (    0.22 ms per token,  4531.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.33 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.86 ms /   207 tokens (    0.20 ms per token,  5066.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.96 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.72 ms /   200 tokens (    0.20 ms per token,  4912.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.10 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.28 ms /   115 tokens (    0.28 ms per token,  3562.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.28 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.34 ms /   130 tokens (    0.28 ms per token,  3577.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.32 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.24 ms /   226 tokens (    0.19 ms per token,  5226.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.15 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.31 ms /    51 tokens (    0.54 ms per token,  1867.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.46 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.49 ms /   232 tokens (    0.19 ms per token,  5333.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.62 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.97 ms /    89 tokens (    0.33 ms per token,  3072.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.40 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.47 ms /   221 tokens (    0.19 ms per token,  5203.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.32 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.36 ms /   194 tokens (    0.21 ms per token,  4807.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.06 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.42 ms /   120 tokens (    0.26 ms per token,  3818.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.23 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.43 ms /    64 tokens (    0.43 ms per token,  2333.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.33 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.48 ms /   249 tokens (    0.18 ms per token,  5597.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.80 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.01 ms /    28 tokens (    0.96 ms per token,  1036.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.16 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.98 ms /   201 tokens (    0.20 ms per token,  4904.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.40 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.54 ms /   202 tokens (    0.21 ms per token,  4862.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.28 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.65 ms /   158 tokens (    0.23 ms per token,  4311.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.44 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.80 ms /   111 tokens (    0.29 ms per token,  3490.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.60 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.56 ms /   158 tokens (    0.23 ms per token,  4442.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.25 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.60 ms /   199 tokens (    0.20 ms per token,  4900.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.19 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.36 ms /   159 tokens (    0.23 ms per token,  4372.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.12 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.27 ms /   186 tokens (    0.21 ms per token,  4860.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.42 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.84 ms /   206 tokens (    0.20 ms per token,  5044.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.03 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.62 ms /   160 tokens (    0.22 ms per token,  4491.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.30 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.52 ms /   139 tokens (    0.26 ms per token,  3912.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.82 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.22 ms /   146 tokens (    0.25 ms per token,  4031.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.41 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.75 ms /    74 tokens (    0.39 ms per token,  2573.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.68 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.92 ms /   218 tokens (    0.19 ms per token,  5200.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.60 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.20 ms /   123 tokens (    0.26 ms per token,  3819.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.17 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.45 ms /   221 tokens (    0.19 ms per token,  5206.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.49 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.60 ms /   139 tokens (    0.26 ms per token,  3904.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.96 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.04 ms /    51 tokens (    0.57 ms per token,  1756.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.64 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.16 ms /    41 tokens (    0.64 ms per token,  1567.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.47 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.72 ms /   156 tokens (    0.24 ms per token,  4248.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.44 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.00 ms /   194 tokens (    0.21 ms per token,  4849.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.44 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.11 ms /    74 tokens (    0.39 ms per token,  2542.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.18 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.67 ms /   114 tokens (    0.28 ms per token,  3599.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.46 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.55 ms /   114 tokens (    0.28 ms per token,  3613.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.18 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      51.30 ms /   260 tokens (    0.20 ms per token,  5068.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.85 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.61 ms /   155 tokens (    0.23 ms per token,  4353.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.23 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.66 ms /    63 tokens (    0.42 ms per token,  2363.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.67 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.59 ms /    49 tokens (    0.54 ms per token,  1842.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.04 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.98 ms /    65 tokens (    0.42 ms per token,  2409.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.92 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.74 ms /   204 tokens (    0.20 ms per token,  5007.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.46 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.16 ms /   214 tokens (    0.20 ms per token,  5075.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.92 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      34.71 ms /   131 tokens (    0.26 ms per token,  3774.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      37.87 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.12 ms /   109 tokens (    0.29 ms per token,  3502.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.77 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.51 ms /    99 tokens (    0.30 ms per token,  3355.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.95 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.52 ms /   108 tokens (    0.28 ms per token,  3538.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.42 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.88 ms /   252 tokens (    0.18 ms per token,  5614.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.46 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.42 ms /    96 tokens (    0.31 ms per token,  3262.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.86 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.47 ms /   145 tokens (    0.24 ms per token,  4088.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.93 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.44 ms /   181 tokens (    0.22 ms per token,  4589.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.57 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.86 ms /   215 tokens (    0.19 ms per token,  5135.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.65 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.55 ms /    11 tokens (    2.41 ms per token,   414.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.44 ms /    12 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.42 ms /   182 tokens (    0.21 ms per token,  4863.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.33 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.22 ms /   201 tokens (    0.21 ms per token,  4875.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.59 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.05 ms /   171 tokens (    0.22 ms per token,  4615.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.02 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.75 ms /   117 tokens (    0.27 ms per token,  3685.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.73 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.57 ms /    76 tokens (    0.38 ms per token,  2660.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.76 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.80 ms /   181 tokens (    0.21 ms per token,  4788.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.82 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.64 ms /    36 tokens (    0.74 ms per token,  1351.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.90 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.62 ms /   103 tokens (    0.29 ms per token,  3477.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.12 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.34 ms /    67 tokens (    0.41 ms per token,  2451.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.07 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.34 ms /   165 tokens (    0.22 ms per token,  4540.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.99 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.60 ms /   124 tokens (    0.25 ms per token,  4052.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.49 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.28 ms /    53 tokens (    0.51 ms per token,  1943.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.70 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.62 ms /    66 tokens (    0.42 ms per token,  2389.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.46 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.59 ms /   121 tokens (    0.27 ms per token,  3713.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.65 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.36 ms /    26 tokens (    1.01 ms per token,   986.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.33 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.07 ms /    99 tokens (    0.30 ms per token,  3292.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.50 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.33 ms /   106 tokens (    0.30 ms per token,  3382.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.90 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.01 ms /    46 tokens (    0.57 ms per token,  1768.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.32 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      51.56 ms /   261 tokens (    0.20 ms per token,  5062.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.00 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.15 ms /   237 tokens (    0.20 ms per token,  5026.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.67 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.74 ms /   175 tokens (    0.21 ms per token,  4763.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.49 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.73 ms /   231 tokens (    0.18 ms per token,  5406.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.02 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.81 ms /    72 tokens (    0.39 ms per token,  2589.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.62 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.21 ms /   248 tokens (    0.18 ms per token,  5609.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.42 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      34.23 ms /   132 tokens (    0.26 ms per token,  3856.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      37.20 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.47 ms /    45 tokens (    0.61 ms per token,  1638.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.07 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.61 ms /    15 tokens (    1.84 ms per token,   543.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.34 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.70 ms /   144 tokens (    0.25 ms per token,  4034.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.00 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.47 ms /   207 tokens (    0.20 ms per token,  4992.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.91 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.57 ms /   150 tokens (    0.24 ms per token,  4217.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.90 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.91 ms /    34 tokens (    0.76 ms per token,  1311.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.19 ms /    35 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.73 ms /   193 tokens (    0.21 ms per token,  4857.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.10 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.81 ms /    96 tokens (    0.31 ms per token,  3220.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.33 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.18 ms /   155 tokens (    0.23 ms per token,  4405.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.48 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.23 ms /    75 tokens (    0.38 ms per token,  2656.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.49 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.77 ms /   118 tokens (    0.26 ms per token,  3835.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.74 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.83 ms /    59 tokens (    0.45 ms per token,  2198.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.34 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.24 ms /   224 tokens (    0.19 ms per token,  5302.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.01 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.65 ms /   224 tokens (    0.19 ms per token,  5252.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.80 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      51.42 ms /   257 tokens (    0.20 ms per token,  4998.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.33 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.74 ms /    47 tokens (    0.57 ms per token,  1757.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.74 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.58 ms /   204 tokens (    0.20 ms per token,  4906.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.00 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.69 ms /    59 tokens (    0.47 ms per token,  2130.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.24 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.14 ms /     9 tokens (    2.79 ms per token,   357.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      25.89 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.83 ms /   192 tokens (    0.20 ms per token,  4944.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.91 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.71 ms /    38 tokens (    0.70 ms per token,  1422.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.93 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.24 ms /   134 tokens (    0.27 ms per token,  3697.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.31 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.90 ms /   153 tokens (    0.23 ms per token,  4261.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.25 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      54.06 ms /   292 tokens (    0.19 ms per token,  5400.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      59.85 ms /   293 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.29 ms /    95 tokens (    0.31 ms per token,  3242.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.77 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      75.10 ms /   448 tokens (    0.17 ms per token,  5965.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.60 ms /   449 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.40 ms /   487 tokens (    0.16 ms per token,  6212.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.31 ms /   488 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      75.73 ms /   486 tokens (    0.16 ms per token,  6417.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.01 ms /   487 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      80.27 ms /   493 tokens (    0.16 ms per token,  6141.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.87 ms /   494 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      76.17 ms /   487 tokens (    0.16 ms per token,  6393.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.64 ms /   488 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      75.96 ms /   485 tokens (    0.16 ms per token,  6385.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.67 ms /   486 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      76.30 ms /   490 tokens (    0.16 ms per token,  6421.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.00 ms /   491 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      75.60 ms /   489 tokens (    0.15 ms per token,  6468.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.91 ms /   490 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      52.77 ms /   273 tokens (    0.19 ms per token,  5173.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.96 ms /   274 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.70 ms /   103 tokens (    0.30 ms per token,  3355.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.18 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      24.30 ms /    10 tokens (    2.43 ms per token,   411.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      25.15 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.70 ms /   216 tokens (    0.20 ms per token,  5058.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.28 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      79.92 ms /   512 tokens (    0.16 ms per token,  6406.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.75 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.87 ms /   512 tokens (    0.15 ms per token,  6574.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.93 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.13 ms /   512 tokens (    0.15 ms per token,  6553.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.21 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.27 ms /   512 tokens (    0.15 ms per token,  6541.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.89 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.01 ms /   512 tokens (    0.15 ms per token,  6563.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.36 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.03 ms /   512 tokens (    0.15 ms per token,  6561.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.86 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.93 ms /   512 tokens (    0.15 ms per token,  6569.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.41 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.97 ms /   512 tokens (    0.15 ms per token,  6566.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.54 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.30 ms /   512 tokens (    0.15 ms per token,  6538.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.74 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.94 ms /   512 tokens (    0.15 ms per token,  6569.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.94 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.16 ms /   512 tokens (    0.15 ms per token,  6550.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.49 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.62 ms /   512 tokens (    0.15 ms per token,  6512.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.34 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.90 ms /   512 tokens (    0.15 ms per token,  6572.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.46 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.38 ms /   512 tokens (    0.15 ms per token,  6532.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.92 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.75 ms /   512 tokens (    0.15 ms per token,  6585.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.78 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.92 ms /   512 tokens (    0.15 ms per token,  6571.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.89 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.87 ms /   512 tokens (    0.15 ms per token,  6574.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.68 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.78 ms /   512 tokens (    0.15 ms per token,  6582.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.26 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.54 ms /   512 tokens (    0.15 ms per token,  6603.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.83 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.57 ms /   512 tokens (    0.15 ms per token,  6600.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.42 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.81 ms /   512 tokens (    0.15 ms per token,  6579.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.12 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.80 ms /   512 tokens (    0.15 ms per token,  6580.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.57 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.86 ms /   512 tokens (    0.15 ms per token,  6576.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.45 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.90 ms /   512 tokens (    0.15 ms per token,  6572.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.53 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.40 ms /   512 tokens (    0.15 ms per token,  6614.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.12 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.94 ms /   512 tokens (    0.15 ms per token,  6485.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.20 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.76 ms /   512 tokens (    0.15 ms per token,  6584.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.25 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.02 ms /   512 tokens (    0.15 ms per token,  6562.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.77 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.32 ms /   512 tokens (    0.15 ms per token,  6537.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.90 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.97 ms /   512 tokens (    0.15 ms per token,  6566.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.27 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.33 ms /   512 tokens (    0.15 ms per token,  6536.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.82 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.94 ms /   512 tokens (    0.15 ms per token,  6568.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.34 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.91 ms /   512 tokens (    0.15 ms per token,  6571.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.44 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.41 ms /   512 tokens (    0.15 ms per token,  6530.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.73 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.26 ms /   512 tokens (    0.15 ms per token,  6626.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.37 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.44 ms /   512 tokens (    0.15 ms per token,  6527.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.43 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.01 ms /   512 tokens (    0.15 ms per token,  6563.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.92 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.41 ms /   512 tokens (    0.15 ms per token,  6614.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.54 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.93 ms /   512 tokens (    0.15 ms per token,  6570.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.98 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.45 ms /   512 tokens (    0.15 ms per token,  6526.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.53 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.55 ms /   512 tokens (    0.15 ms per token,  6602.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.23 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.39 ms /   512 tokens (    0.15 ms per token,  6531.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.63 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.19 ms /   512 tokens (    0.15 ms per token,  6548.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.72 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.85 ms /   512 tokens (    0.15 ms per token,  6576.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.76 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.21 ms /   512 tokens (    0.15 ms per token,  6546.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.56 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.54 ms /   512 tokens (    0.15 ms per token,  6602.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.08 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.99 ms /   512 tokens (    0.15 ms per token,  6564.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.08 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.08 ms /   512 tokens (    0.15 ms per token,  6557.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.22 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.24 ms /   512 tokens (    0.15 ms per token,  6543.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.99 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.09 ms /   512 tokens (    0.15 ms per token,  6556.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.28 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.20 ms /   512 tokens (    0.15 ms per token,  6547.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.36 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.90 ms /   512 tokens (    0.15 ms per token,  6572.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.55 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.36 ms /   512 tokens (    0.15 ms per token,  6533.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.57 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.50 ms /   512 tokens (    0.15 ms per token,  6522.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.34 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.62 ms /   512 tokens (    0.15 ms per token,  6596.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.50 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      78.24 ms /   512 tokens (    0.15 ms per token,  6544.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.12 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.98 ms /   512 tokens (    0.15 ms per token,  6565.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.16 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.59 ms /   512 tokens (    0.15 ms per token,  6598.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.83 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      77.86 ms /   512 tokens (    0.15 ms per token,  6575.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.10 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      67.17 ms /   385 tokens (    0.17 ms per token,  5731.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.66 ms /   386 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.21 ms /   192 tokens (    0.20 ms per token,  4896.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.38 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.18 ms /   203 tokens (    0.20 ms per token,  4929.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.54 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.49 ms /   165 tokens (    0.23 ms per token,  4286.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.24 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.05 ms /    50 tokens (    0.54 ms per token,  1848.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.41 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      51.49 ms /   265 tokens (    0.19 ms per token,  5146.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.10 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.34 ms /   190 tokens (    0.20 ms per token,  4955.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.46 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.34 ms /   177 tokens (    0.21 ms per token,  4739.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.22 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.87 ms /    75 tokens (    0.38 ms per token,  2597.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.10 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.41 ms /    32 tokens (    0.79 ms per token,  1259.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.74 ms /    33 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.56 ms /    78 tokens (    0.37 ms per token,  2731.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.52 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.74 ms /    93 tokens (    0.31 ms per token,  3236.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.14 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.60 ms /   209 tokens (    0.20 ms per token,  5023.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.87 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.72 ms /    50 tokens (    0.53 ms per token,  1871.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.33 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      51.68 ms /   260 tokens (    0.20 ms per token,  5031.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.06 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.78 ms /   196 tokens (    0.21 ms per token,  4691.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.26 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.78 ms /   250 tokens (    0.18 ms per token,  5460.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.95 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.14 ms /   180 tokens (    0.21 ms per token,  4719.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.32 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.51 ms /   218 tokens (    0.20 ms per token,  5010.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.46 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.68 ms /   141 tokens (    0.27 ms per token,  3742.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.14 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.29 ms /   230 tokens (    0.19 ms per token,  5193.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.04 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      71.09 ms /   385 tokens (    0.18 ms per token,  5415.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.37 ms /   386 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.44 ms /   212 tokens (    0.20 ms per token,  4995.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.06 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.44 ms /   237 tokens (    0.19 ms per token,  5333.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.72 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.31 ms /    32 tokens (    0.79 ms per token,  1264.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.40 ms /    33 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.81 ms /    78 tokens (    0.37 ms per token,  2707.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.11 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.81 ms /   232 tokens (    0.19 ms per token,  5295.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.02 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.16 ms /   211 tokens (    0.20 ms per token,  4888.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.77 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.76 ms /    81 tokens (    0.36 ms per token,  2816.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.89 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.44 ms /   112 tokens (    0.29 ms per token,  3452.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.03 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      34.69 ms /   130 tokens (    0.27 ms per token,  3747.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      37.78 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.43 ms /   143 tokens (    0.25 ms per token,  3925.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.85 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.73 ms /    77 tokens (    0.37 ms per token,  2679.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.71 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.57 ms /    75 tokens (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.46 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.18 ms /   163 tokens (    0.23 ms per token,  4384.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.82 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.61 ms /   188 tokens (    0.21 ms per token,  4868.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.97 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.93 ms /   125 tokens (    0.26 ms per token,  3914.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.81 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      24.74 ms /    22 tokens (    1.12 ms per token,   889.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      25.59 ms /    23 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.84 ms /   111 tokens (    0.29 ms per token,  3486.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.51 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.74 ms /    19 tokens (    1.35 ms per token,   738.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.57 ms /    20 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.13 ms /   208 tokens (    0.20 ms per token,  5056.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.64 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.30 ms /    38 tokens (    0.69 ms per token,  1444.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.54 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.49 ms /    44 tokens (    0.62 ms per token,  1600.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.81 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.57 ms /    64 tokens (    0.42 ms per token,  2409.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.39 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      52.57 ms /   268 tokens (    0.20 ms per token,  5098.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.15 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.44 ms /    77 tokens (    0.37 ms per token,  2707.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.44 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.10 ms /    24 tokens (    1.09 ms per token,   919.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.05 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.00 ms /    58 tokens (    0.48 ms per token,  2071.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.46 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.83 ms /    29 tokens (    0.89 ms per token,  1122.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.82 ms /    30 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.66 ms /    79 tokens (    0.38 ms per token,  2663.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.64 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.45 ms /    15 tokens (    1.70 ms per token,   589.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.21 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.23 ms /   149 tokens (    0.25 ms per token,  4001.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.76 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.46 ms /   172 tokens (    0.23 ms per token,  4358.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.37 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.38 ms /    83 tokens (    0.35 ms per token,  2825.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.44 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.82 ms /    56 tokens (    0.51 ms per token,  1943.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.37 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.77 ms /   207 tokens (    0.21 ms per token,  4729.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.20 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.60 ms /    92 tokens (    0.33 ms per token,  3006.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.09 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.82 ms /   242 tokens (    0.19 ms per token,  5168.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.99 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.77 ms /   207 tokens (    0.21 ms per token,  4728.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.15 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.03 ms /   157 tokens (    0.25 ms per token,  4022.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.85 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.71 ms /   181 tokens (    0.22 ms per token,  4445.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.27 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.36 ms /    65 tokens (    0.44 ms per token,  2292.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.99 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.00 ms /    26 tokens (    1.00 ms per token,  1000.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.04 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.03 ms /   229 tokens (    0.20 ms per token,  5085.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.91 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.96 ms /    35 tokens (    0.77 ms per token,  1297.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.21 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.88 ms /   141 tokens (    0.26 ms per token,  3823.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.26 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.02 ms /   226 tokens (    0.20 ms per token,  5019.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.87 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.96 ms /    15 tokens (    1.86 ms per token,   536.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.11 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.95 ms /   123 tokens (    0.26 ms per token,  3849.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.95 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.43 ms /    43 tokens (    0.64 ms per token,  1567.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.75 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.23 ms /    59 tokens (    0.46 ms per token,  2166.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.73 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.95 ms /    90 tokens (    0.32 ms per token,  3108.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.36 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      55.34 ms /   267 tokens (    0.21 ms per token,  4825.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.32 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.19 ms /    89 tokens (    0.34 ms per token,  2947.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.50 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.95 ms /    53 tokens (    0.51 ms per token,  1966.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.50 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.48 ms /    53 tokens (    0.52 ms per token,  1928.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.99 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.28 ms /   144 tokens (    0.26 ms per token,  3862.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.57 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.06 ms /    93 tokens (    0.32 ms per token,  3093.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.42 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.89 ms /    42 tokens (    0.62 ms per token,  1622.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.22 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      55.71 ms /   268 tokens (    0.21 ms per token,  4810.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.04 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.90 ms /   214 tokens (    0.21 ms per token,  4874.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.62 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.02 ms /   203 tokens (    0.21 ms per token,  4719.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.50 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.91 ms /   163 tokens (    0.23 ms per token,  4300.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.65 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.67 ms /    91 tokens (    0.34 ms per token,  2966.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.17 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.10 ms /    44 tokens (    0.64 ms per token,  1566.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.45 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.46 ms /    32 tokens (    0.83 ms per token,  1209.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.60 ms /    33 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.81 ms /    77 tokens (    0.37 ms per token,  2672.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.88 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.17 ms /    59 tokens (    0.49 ms per token,  2022.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.81 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.27 ms /   235 tokens (    0.19 ms per token,  5190.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.14 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.34 ms /   237 tokens (    0.20 ms per token,  5114.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.84 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.32 ms /   243 tokens (    0.19 ms per token,  5246.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.68 ms /   244 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.13 ms /   220 tokens (    0.20 ms per token,  5100.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.29 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.66 ms /   143 tokens (    0.25 ms per token,  4010.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.14 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.72 ms /   153 tokens (    0.24 ms per token,  4166.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.49 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.47 ms /   162 tokens (    0.23 ms per token,  4323.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.77 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.80 ms /    44 tokens (    0.63 ms per token,  1582.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.26 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.85 ms /   136 tokens (    0.26 ms per token,  3793.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.23 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.82 ms /   238 tokens (    0.19 ms per token,  5310.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.91 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.09 ms /   203 tokens (    0.21 ms per token,  4822.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.54 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.54 ms /   176 tokens (    0.22 ms per token,  4567.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.76 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.36 ms /   139 tokens (    0.26 ms per token,  3822.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.63 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.03 ms /   162 tokens (    0.23 ms per token,  4374.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.89 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.59 ms /    43 tokens (    0.62 ms per token,  1616.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.98 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.76 ms /   195 tokens (    0.22 ms per token,  4560.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.29 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.81 ms /   238 tokens (    0.19 ms per token,  5311.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.67 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.39 ms /    59 tokens (    0.46 ms per token,  2154.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.16 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.47 ms /   216 tokens (    0.20 ms per token,  5085.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.56 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.47 ms /   100 tokens (    0.30 ms per token,  3281.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.31 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.53 ms /    96 tokens (    0.31 ms per token,  3251.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.36 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.74 ms /   187 tokens (    0.21 ms per token,  4827.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.31 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.63 ms /   185 tokens (    0.21 ms per token,  4668.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.99 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.99 ms /   189 tokens (    0.21 ms per token,  4726.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.42 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      55.38 ms /   272 tokens (    0.20 ms per token,  4911.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      61.86 ms /   273 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.46 ms /    42 tokens (    0.63 ms per token,  1587.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.76 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.70 ms /    79 tokens (    0.39 ms per token,  2573.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.08 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.84 ms /    76 tokens (    0.39 ms per token,  2547.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.81 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.11 ms /   245 tokens (    0.20 ms per token,  4988.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.56 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.86 ms /    40 tokens (    0.67 ms per token,  1489.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.35 ms /    41 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.94 ms /   116 tokens (    0.29 ms per token,  3418.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.79 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.86 ms /    22 tokens (    1.18 ms per token,   850.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.77 ms /    23 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      58.55 ms /   260 tokens (    0.23 ms per token,  4440.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.91 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.34 ms /   106 tokens (    0.31 ms per token,  3179.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.93 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.28 ms /   156 tokens (    0.26 ms per token,  3873.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.74 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.64 ms /    12 tokens (    2.14 ms per token,   467.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.62 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.56 ms /    10 tokens (    2.56 ms per token,   391.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.16 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.16 ms /    75 tokens (    0.40 ms per token,  2487.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.09 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.95 ms /   193 tokens (    0.23 ms per token,  4293.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.51 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.34 ms /   162 tokens (    0.25 ms per token,  4015.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.95 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.07 ms /   256 tokens (    0.19 ms per token,  5217.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.51 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.21 ms /   116 tokens (    0.29 ms per token,  3493.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.98 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.17 ms /   151 tokens (    0.26 ms per token,  3855.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.70 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.87 ms /   123 tokens (    0.26 ms per token,  3860.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.69 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.44 ms /   182 tokens (    0.23 ms per token,  4288.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.18 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.21 ms /   175 tokens (    0.24 ms per token,  4145.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.08 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.15 ms /   124 tokens (    0.26 ms per token,  3856.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.34 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.12 ms /   140 tokens (    0.27 ms per token,  3672.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.35 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.98 ms /   209 tokens (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.79 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.94 ms /    95 tokens (    0.32 ms per token,  3173.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.35 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.62 ms /   133 tokens (    0.28 ms per token,  3535.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.64 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.98 ms /    39 tokens (    0.69 ms per token,  1445.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.26 ms /    40 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.38 ms /   154 tokens (    0.25 ms per token,  4011.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.04 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.75 ms /    48 tokens (    0.58 ms per token,  1729.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.14 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.12 ms /    57 tokens (    0.49 ms per token,  2026.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.79 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.43 ms /   110 tokens (    0.29 ms per token,  3499.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.16 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.21 ms /    43 tokens (    0.63 ms per token,  1580.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.56 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      12.46 ms /     6 tokens (    2.08 ms per token,   481.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      13.00 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.84 ms /    90 tokens (    0.34 ms per token,  2918.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.12 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.00 ms /   165 tokens (    0.24 ms per token,  4230.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.10 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.65 ms /    66 tokens (    0.45 ms per token,  2226.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.43 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.17 ms /    41 tokens (    0.64 ms per token,  1566.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.44 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.58 ms /   121 tokens (    0.27 ms per token,  3714.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.53 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.11 ms /   165 tokens (    0.23 ms per token,  4329.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.97 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.00 ms /    90 tokens (    0.36 ms per token,  2812.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.50 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.99 ms /   197 tokens (    0.22 ms per token,  4582.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.13 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.70 ms /   190 tokens (    0.21 ms per token,  4667.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.83 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.00 ms /    83 tokens (    0.36 ms per token,  2766.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.30 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.29 ms /   226 tokens (    0.20 ms per token,  4990.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.58 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.05 ms /   113 tokens (    0.29 ms per token,  3419.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.88 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.55 ms /   174 tokens (    0.22 ms per token,  4513.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.51 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.38 ms /    66 tokens (    0.43 ms per token,  2325.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.36 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.38 ms /    95 tokens (    0.31 ms per token,  3234.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.93 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.47 ms /   211 tokens (    0.21 ms per token,  4853.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.12 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.37 ms /   233 tokens (    0.19 ms per token,  5135.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.56 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.52 ms /    54 tokens (    0.53 ms per token,  1893.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.12 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.50 ms /    87 tokens (    0.34 ms per token,  2949.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.82 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.61 ms /   182 tokens (    0.21 ms per token,  4713.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.84 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.56 ms /    84 tokens (    0.34 ms per token,  2940.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.99 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.66 ms /    23 tokens (    1.16 ms per token,   862.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.53 ms /    24 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.83 ms /    48 tokens (    0.56 ms per token,  1789.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.38 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      58.16 ms /   302 tokens (    0.19 ms per token,  5192.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.41 ms /   303 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.70 ms /   248 tokens (    0.18 ms per token,  5426.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.32 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.75 ms /    88 tokens (    0.34 ms per token,  2957.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.08 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.80 ms /   226 tokens (    0.20 ms per token,  5044.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.95 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.71 ms /    25 tokens (    1.03 ms per token,   972.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.81 ms /    26 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.26 ms /   160 tokens (    0.23 ms per token,  4294.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.42 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.39 ms /   115 tokens (    0.28 ms per token,  3550.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.17 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.43 ms /   252 tokens (    0.18 ms per token,  5427.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.21 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.25 ms /   100 tokens (    0.30 ms per token,  3305.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.82 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.23 ms /   134 tokens (    0.28 ms per token,  3599.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.44 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.22 ms /   181 tokens (    0.22 ms per token,  4500.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.57 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.64 ms /    14 tokens (    1.90 ms per token,   525.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.35 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.04 ms /   162 tokens (    0.23 ms per token,  4258.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.83 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.64 ms /    53 tokens (    0.52 ms per token,  1917.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.87 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.36 ms /   227 tokens (    0.20 ms per token,  5004.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.61 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.48 ms /   231 tokens (    0.20 ms per token,  5079.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.78 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.40 ms /   100 tokens (    0.30 ms per token,  3289.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.16 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.54 ms /    41 tokens (    0.65 ms per token,  1545.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.01 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.95 ms /    35 tokens (    0.74 ms per token,  1348.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.10 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.98 ms /    84 tokens (    0.34 ms per token,  2898.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.39 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.96 ms /    52 tokens (    0.52 ms per token,  1928.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.48 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.14 ms /   187 tokens (    0.21 ms per token,  4777.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.50 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.02 ms /   150 tokens (    0.25 ms per token,  4051.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.61 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.12 ms /    37 tokens (    0.71 ms per token,  1416.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.47 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.72 ms /    52 tokens (    0.55 ms per token,  1810.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.20 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.61 ms /   157 tokens (    0.25 ms per token,  3963.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.40 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.63 ms /    46 tokens (    0.60 ms per token,  1664.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.29 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.68 ms /   141 tokens (    0.28 ms per token,  3553.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.45 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.55 ms /   182 tokens (    0.23 ms per token,  4379.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.78 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.67 ms /    75 tokens (    0.41 ms per token,  2445.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.65 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.78 ms /    58 tokens (    0.50 ms per token,  2015.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.57 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.03 ms /    53 tokens (    0.53 ms per token,  1890.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.63 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.33 ms /   106 tokens (    0.30 ms per token,  3278.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.20 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.71 ms /    84 tokens (    0.35 ms per token,  2827.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.76 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.30 ms /   118 tokens (    0.28 ms per token,  3543.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.26 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      12.08 ms /     4 tokens (    3.02 ms per token,   331.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      12.52 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.85 ms /    37 tokens (    0.73 ms per token,  1377.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.00 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.55 ms /   158 tokens (    0.25 ms per token,  3994.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.34 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.53 ms /   213 tokens (    0.22 ms per token,  4481.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.55 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.80 ms /   105 tokens (    0.30 ms per token,  3301.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.59 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.67 ms /   180 tokens (    0.23 ms per token,  4319.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.53 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.01 ms /    45 tokens (    0.64 ms per token,  1550.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.00 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.80 ms /    74 tokens (    0.40 ms per token,  2483.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.71 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.94 ms /   110 tokens (    0.31 ms per token,  3240.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.55 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.12 ms /   231 tokens (    0.21 ms per token,  4800.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.06 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.01 ms /   103 tokens (    0.31 ms per token,  3217.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.66 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.91 ms /   188 tokens (    0.22 ms per token,  4485.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.93 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.20 ms /    71 tokens (    0.41 ms per token,  2431.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.10 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.87 ms /    54 tokens (    0.52 ms per token,  1937.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.51 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.56 ms /   128 tokens (    0.26 ms per token,  3813.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.64 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.64 ms /    74 tokens (    0.40 ms per token,  2496.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.53 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.37 ms /    18 tokens (    1.46 ms per token,   682.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.26 ms /    19 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.21 ms /    84 tokens (    0.36 ms per token,  2781.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.51 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.30 ms /   244 tokens (    0.20 ms per token,  4949.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.72 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.13 ms /    39 tokens (    0.67 ms per token,  1492.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.32 ms /    40 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.79 ms /   226 tokens (    0.21 ms per token,  4729.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.91 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      57.58 ms /   267 tokens (    0.22 ms per token,  4637.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      63.23 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.04 ms /   145 tokens (    0.26 ms per token,  3915.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.34 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.57 ms /   171 tokens (    0.24 ms per token,  4214.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.90 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.20 ms /    90 tokens (    0.34 ms per token,  2979.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.92 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.43 ms /   233 tokens (    0.20 ms per token,  4912.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.44 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      16.34 ms /     8 tokens (    2.04 ms per token,   489.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      17.12 ms /     9 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      34.20 ms /   113 tokens (    0.30 ms per token,  3304.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      37.11 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.98 ms /   201 tokens (    0.22 ms per token,  4468.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.06 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.18 ms /    57 tokens (    0.49 ms per token,  2023.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.94 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.73 ms /    66 tokens (    0.44 ms per token,  2296.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.61 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.34 ms /    48 tokens (    0.57 ms per token,  1755.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.83 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.25 ms /    76 tokens (    0.40 ms per token,  2511.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.21 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.91 ms /    24 tokens (    1.08 ms per token,   926.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.82 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.43 ms /   132 tokens (    0.28 ms per token,  3526.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.92 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.81 ms /     9 tokens (    2.87 ms per token,   348.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.63 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.04 ms /    53 tokens (    0.53 ms per token,  1890.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.49 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.68 ms /   153 tokens (    0.25 ms per token,  3955.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.78 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.48 ms /   103 tokens (    0.31 ms per token,  3272.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.67 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.92 ms /    69 tokens (    0.43 ms per token,  2306.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.71 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      14.53 ms /     7 tokens (    2.08 ms per token,   481.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      15.08 ms /     8 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.34 ms /    43 tokens (    0.64 ms per token,  1572.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.72 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.91 ms /   127 tokens (    0.26 ms per token,  3859.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.07 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.23 ms /   149 tokens (    0.26 ms per token,  3897.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.66 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.03 ms /    79 tokens (    0.38 ms per token,  2631.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.44 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.15 ms /   232 tokens (    0.20 ms per token,  4920.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.19 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.74 ms /    77 tokens (    0.41 ms per token,  2426.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.89 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.40 ms /    81 tokens (    0.36 ms per token,  2755.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.88 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.82 ms /    73 tokens (    0.41 ms per token,  2448.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.13 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.02 ms /   231 tokens (    0.20 ms per token,  4912.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.20 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.46 ms /   230 tokens (    0.20 ms per token,  4950.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.61 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.77 ms /   166 tokens (    0.23 ms per token,  4282.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.67 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.12 ms /    91 tokens (    0.34 ms per token,  2923.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.49 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.83 ms /   194 tokens (    0.23 ms per token,  4327.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.31 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.75 ms /   252 tokens (    0.19 ms per token,  5169.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.73 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.64 ms /    57 tokens (    0.52 ms per token,  1922.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.30 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.98 ms /    25 tokens (    1.04 ms per token,   962.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.12 ms /    26 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.80 ms /   217 tokens (    0.21 ms per token,  4738.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.41 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.16 ms /   122 tokens (    0.27 ms per token,  3679.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.92 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.30 ms /   161 tokens (    0.24 ms per token,  4096.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.38 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.67 ms /   135 tokens (    0.28 ms per token,  3583.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.84 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.16 ms /    23 tokens (    1.14 ms per token,   879.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.15 ms /    24 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.00 ms /    65 tokens (    0.45 ms per token,  2240.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.79 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.16 ms /    21 tokens (    1.25 ms per token,   802.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.15 ms /    22 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.09 ms /    63 tokens (    0.45 ms per token,  2243.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.92 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.81 ms /    21 tokens (    1.23 ms per token,   813.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.76 ms /    22 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.43 ms /    47 tokens (    0.60 ms per token,  1653.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.87 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.64 ms /   180 tokens (    0.24 ms per token,  4221.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.20 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.02 ms /    81 tokens (    0.36 ms per token,  2791.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.36 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.30 ms /    85 tokens (    0.36 ms per token,  2805.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.77 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.71 ms /   119 tokens (    0.28 ms per token,  3530.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.65 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.73 ms /   160 tokens (    0.24 ms per token,  4131.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.39 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.91 ms /   161 tokens (    0.25 ms per token,  4033.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.95 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.93 ms /    13 tokens (    1.99 ms per token,   501.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.76 ms /    14 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.21 ms /   237 tokens (    0.20 ms per token,  5020.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.33 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.72 ms /    53 tokens (    0.52 ms per token,  1912.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.29 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      11.70 ms /     4 tokens (    2.93 ms per token,   341.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      12.18 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.15 ms /    70 tokens (    0.43 ms per token,  2321.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.10 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      59.83 ms /   289 tokens (    0.21 ms per token,  4830.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.13 ms /   290 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.93 ms /   118 tokens (    0.27 ms per token,  3695.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.21 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.76 ms /    36 tokens (    0.74 ms per token,  1345.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.35 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.84 ms /    92 tokens (    0.34 ms per token,  2983.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.21 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.63 ms /    76 tokens (    0.39 ms per token,  2564.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.60 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.72 ms /   129 tokens (    0.29 ms per token,  3419.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.96 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.16 ms /   120 tokens (    0.28 ms per token,  3618.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.13 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.26 ms /    93 tokens (    0.33 ms per token,  3073.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.59 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.84 ms /    52 tokens (    0.54 ms per token,  1867.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.47 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.19 ms /    94 tokens (    0.32 ms per token,  3114.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.41 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.94 ms /     9 tokens (    2.99 ms per token,   334.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.56 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.48 ms /    97 tokens (    0.32 ms per token,  3081.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.08 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.05 ms /    74 tokens (    0.42 ms per token,  2383.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.05 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.59 ms /   127 tokens (    0.26 ms per token,  3897.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.59 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.35 ms /   247 tokens (    0.20 ms per token,  5108.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.38 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.60 ms /   129 tokens (    0.28 ms per token,  3623.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.00 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.97 ms /   102 tokens (    0.31 ms per token,  3190.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.77 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.86 ms /   187 tokens (    0.22 ms per token,  4576.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.42 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.43 ms /   176 tokens (    0.23 ms per token,  4352.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.34 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.66 ms /    33 tokens (    0.81 ms per token,  1237.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.95 ms /    34 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.06 ms /    13 tokens (    2.00 ms per token,   498.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.10 ms /    14 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.59 ms /   248 tokens (    0.19 ms per token,  5211.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.36 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.47 ms /   121 tokens (    0.28 ms per token,  3615.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.64 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.10 ms /   215 tokens (    0.21 ms per token,  4663.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.60 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.16 ms /   252 tokens (    0.19 ms per token,  5232.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.70 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.98 ms /    96 tokens (    0.31 ms per token,  3202.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.39 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.45 ms /   223 tokens (    0.20 ms per token,  4906.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.84 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.03 ms /   249 tokens (    0.19 ms per token,  5184.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.38 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.34 ms /   211 tokens (    0.22 ms per token,  4553.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.42 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.34 ms /   127 tokens (    0.25 ms per token,  3927.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.60 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.36 ms /   250 tokens (    0.20 ms per token,  5064.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.11 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.91 ms /   251 tokens (    0.19 ms per token,  5131.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.08 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.65 ms /   103 tokens (    0.31 ms per token,  3254.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.39 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.84 ms /   170 tokens (    0.24 ms per token,  4162.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.01 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.64 ms /   240 tokens (    0.20 ms per token,  4934.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.32 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      34.03 ms /   109 tokens (    0.31 ms per token,  3202.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.68 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.80 ms /   109 tokens (    0.30 ms per token,  3322.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.52 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.05 ms /    16 tokens (    1.63 ms per token,   614.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.79 ms /    17 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.87 ms /    30 tokens (    0.90 ms per token,  1116.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.94 ms /    31 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      58.68 ms /   263 tokens (    0.22 ms per token,  4481.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.71 ms /   264 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      64.53 ms /   329 tokens (    0.20 ms per token,  5098.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.18 ms /   330 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.15 ms /   249 tokens (    0.20 ms per token,  5065.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.64 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.60 ms /    55 tokens (    0.52 ms per token,  1923.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.17 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.35 ms /   202 tokens (    0.23 ms per token,  4358.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.30 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.79 ms /    90 tokens (    0.35 ms per token,  2830.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.61 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.73 ms /   240 tokens (    0.20 ms per token,  4924.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.53 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.72 ms /    68 tokens (    0.44 ms per token,  2287.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.70 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.41 ms /   125 tokens (    0.26 ms per token,  3857.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.53 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.86 ms /    60 tokens (    0.46 ms per token,  2153.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.58 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.26 ms /   116 tokens (    0.29 ms per token,  3487.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.18 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.05 ms /   141 tokens (    0.28 ms per token,  3610.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.43 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.93 ms /   183 tokens (    0.23 ms per token,  4364.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.42 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.93 ms /   232 tokens (    0.21 ms per token,  4840.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.22 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.70 ms /   187 tokens (    0.22 ms per token,  4484.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.36 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.14 ms /    43 tokens (    0.63 ms per token,  1584.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.48 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.87 ms /    23 tokens (    1.17 ms per token,   855.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.93 ms /    24 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.79 ms /   146 tokens (    0.27 ms per token,  3763.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.24 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.69 ms /   187 tokens (    0.22 ms per token,  4485.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.05 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.33 ms /   237 tokens (    0.20 ms per token,  4904.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.90 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.37 ms /    59 tokens (    0.48 ms per token,  2079.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.53 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      59.10 ms /   265 tokens (    0.22 ms per token,  4483.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.38 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.75 ms /    36 tokens (    0.77 ms per token,  1297.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.90 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.30 ms /   217 tokens (    0.22 ms per token,  4587.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.82 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.53 ms /   244 tokens (    0.20 ms per token,  5027.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.09 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.02 ms /   102 tokens (    0.31 ms per token,  3185.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.64 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.15 ms /   170 tokens (    0.25 ms per token,  4033.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.26 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.78 ms /   139 tokens (    0.28 ms per token,  3584.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.43 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.69 ms /   237 tokens (    0.21 ms per token,  4867.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.67 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.27 ms /   245 tokens (    0.20 ms per token,  4972.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.89 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.21 ms /   225 tokens (    0.21 ms per token,  4667.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.51 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.28 ms /    62 tokens (    0.46 ms per token,  2192.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.07 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.86 ms /    91 tokens (    0.34 ms per token,  2948.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.45 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.00 ms /    16 tokens (    1.63 ms per token,   615.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.78 ms /    17 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.69 ms /    56 tokens (    0.51 ms per token,  1952.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.67 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.03 ms /   165 tokens (    0.24 ms per token,  4121.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.84 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.58 ms /   108 tokens (    0.30 ms per token,  3315.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.26 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.79 ms /   124 tokens (    0.26 ms per token,  3782.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.51 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.12 ms /    10 tokens (    2.61 ms per token,   382.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.81 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.37 ms /   181 tokens (    0.23 ms per token,  4375.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.47 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.30 ms /   101 tokens (    0.31 ms per token,  3226.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.99 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.99 ms /   105 tokens (    0.30 ms per token,  3282.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.65 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.49 ms /    12 tokens (    2.21 ms per token,   453.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.22 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.39 ms /    63 tokens (    0.45 ms per token,  2219.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.04 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.00 ms /    41 tokens (    0.66 ms per token,  1518.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.43 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.64 ms /    44 tokens (    0.63 ms per token,  1591.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.00 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.97 ms /    76 tokens (    0.39 ms per token,  2535.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.47 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.49 ms /    81 tokens (    0.36 ms per token,  2746.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.56 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.92 ms /    53 tokens (    0.55 ms per token,  1832.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.52 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.75 ms /    31 tokens (    0.86 ms per token,  1158.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.93 ms /    32 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.18 ms /    24 tokens (    1.09 ms per token,   916.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.20 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.62 ms /    83 tokens (    0.36 ms per token,  2802.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.72 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.84 ms /   216 tokens (    0.22 ms per token,  4611.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.32 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.19 ms /   162 tokens (    0.25 ms per token,  4030.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.06 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.90 ms /   134 tokens (    0.28 ms per token,  3535.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.29 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.30 ms /   134 tokens (    0.29 ms per token,  3498.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.78 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.57 ms /   136 tokens (    0.28 ms per token,  3526.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.88 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.99 ms /   198 tokens (    0.23 ms per token,  4305.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.66 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.59 ms /    35 tokens (    0.76 ms per token,  1316.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.74 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.33 ms /   136 tokens (    0.28 ms per token,  3548.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.61 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.37 ms /   237 tokens (    0.20 ms per token,  4899.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.69 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.78 ms /    42 tokens (    0.66 ms per token,  1511.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.28 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.30 ms /    69 tokens (    0.42 ms per token,  2355.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.39 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.08 ms /   101 tokens (    0.31 ms per token,  3249.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.60 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.62 ms /    68 tokens (    0.44 ms per token,  2295.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.50 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.76 ms /    94 tokens (    0.33 ms per token,  3055.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.12 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.03 ms /    92 tokens (    0.34 ms per token,  2964.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.92 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.13 ms /   165 tokens (    0.24 ms per token,  4111.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.27 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.89 ms /    35 tokens (    0.80 ms per token,  1254.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.06 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.16 ms /   112 tokens (    0.30 ms per token,  3378.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.34 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.57 ms /    80 tokens (    0.37 ms per token,  2705.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.69 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.61 ms /   216 tokens (    0.22 ms per token,  4634.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.87 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.04 ms /   206 tokens (    0.22 ms per token,  4474.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.88 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.50 ms /    73 tokens (    0.42 ms per token,  2393.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.58 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      12.79 ms /     5 tokens (    2.56 ms per token,   390.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      13.31 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.00 ms /   126 tokens (    0.26 ms per token,  3818.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.92 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.08 ms /    54 tokens (    0.52 ms per token,  1923.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.74 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.31 ms /    96 tokens (    0.32 ms per token,  3166.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.65 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.70 ms /   213 tokens (    0.22 ms per token,  4560.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.69 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.48 ms /    96 tokens (    0.32 ms per token,  3149.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.09 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.87 ms /   242 tokens (    0.20 ms per token,  4952.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.56 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.13 ms /    28 tokens (    1.00 ms per token,   995.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.21 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.96 ms /   189 tokens (    0.22 ms per token,  4503.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.36 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.23 ms /   237 tokens (    0.21 ms per token,  4814.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.80 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.78 ms /    29 tokens (    0.92 ms per token,  1082.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.85 ms /    30 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.04 ms /   171 tokens (    0.24 ms per token,  4166.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.21 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.96 ms /   111 tokens (    0.30 ms per token,  3367.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.84 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.12 ms /   147 tokens (    0.27 ms per token,  3757.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.72 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.18 ms /   203 tokens (    0.23 ms per token,  4395.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.74 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.45 ms /    70 tokens (    0.42 ms per token,  2377.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.48 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.75 ms /   227 tokens (    0.21 ms per token,  4753.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.04 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.66 ms /    27 tokens (    0.99 ms per token,  1012.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.85 ms /    28 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.82 ms /   249 tokens (    0.20 ms per token,  4997.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.72 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.86 ms /    24 tokens (    1.16 ms per token,   861.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.08 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.87 ms /   232 tokens (    0.21 ms per token,  4846.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.33 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.07 ms /   233 tokens (    0.21 ms per token,  4847.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.51 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.07 ms /    65 tokens (    0.46 ms per token,  2161.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.97 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.10 ms /   203 tokens (    0.23 ms per token,  4403.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.79 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.75 ms /    86 tokens (    0.36 ms per token,  2796.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.17 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.74 ms /    49 tokens (    0.57 ms per token,  1766.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.22 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.20 ms /   194 tokens (    0.23 ms per token,  4292.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.67 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.77 ms /   164 tokens (    0.25 ms per token,  4022.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.68 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.52 ms /   219 tokens (    0.22 ms per token,  4608.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.85 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.12 ms /   199 tokens (    0.23 ms per token,  4314.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.63 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.84 ms /   203 tokens (    0.23 ms per token,  4428.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.85 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.58 ms /   208 tokens (    0.22 ms per token,  4465.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.33 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.87 ms /    79 tokens (    0.39 ms per token,  2559.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.14 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.19 ms /    24 tokens (    1.13 ms per token,   882.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.51 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.81 ms /    12 tokens (    2.15 ms per token,   464.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.48 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.87 ms /   175 tokens (    0.23 ms per token,  4281.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.96 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.71 ms /    83 tokens (    0.36 ms per token,  2793.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.95 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.03 ms /   101 tokens (    0.31 ms per token,  3254.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.76 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.56 ms /   197 tokens (    0.23 ms per token,  4324.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.01 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.23 ms /    93 tokens (    0.33 ms per token,  3076.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.70 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      58.88 ms /   265 tokens (    0.22 ms per token,  4500.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.80 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.10 ms /    49 tokens (    0.57 ms per token,  1743.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.94 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.45 ms /    37 tokens (    0.74 ms per token,  1348.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.68 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.07 ms /    34 tokens (    0.80 ms per token,  1255.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.24 ms /    35 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.77 ms /   190 tokens (    0.22 ms per token,  4548.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.26 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.75 ms /    98 tokens (    0.31 ms per token,  3186.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.25 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.51 ms /   252 tokens (    0.20 ms per token,  5090.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.04 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.89 ms /   239 tokens (    0.20 ms per token,  4888.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.61 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.46 ms /    12 tokens (    2.20 ms per token,   453.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.31 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.66 ms /   196 tokens (    0.23 ms per token,  4292.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.21 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.85 ms /   204 tokens (    0.22 ms per token,  4449.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.64 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.00 ms /    96 tokens (    0.32 ms per token,  3096.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.57 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.51 ms /   162 tokens (    0.25 ms per token,  3999.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.61 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.13 ms /    36 tokens (    0.75 ms per token,  1326.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.42 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.61 ms /    15 tokens (    1.77 ms per token,   563.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.32 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.88 ms /   179 tokens (    0.23 ms per token,  4274.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.33 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.74 ms /    62 tokens (    0.46 ms per token,  2157.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.70 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.37 ms /    38 tokens (    0.72 ms per token,  1388.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.68 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.83 ms /   171 tokens (    0.24 ms per token,  4188.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.82 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.24 ms /   246 tokens (    0.20 ms per token,  4996.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.15 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.17 ms /   205 tokens (    0.23 ms per token,  4440.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.21 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.02 ms /    41 tokens (    0.68 ms per token,  1463.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.00 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.45 ms /   182 tokens (    0.23 ms per token,  4391.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.74 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.83 ms /   248 tokens (    0.20 ms per token,  5078.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.54 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.39 ms /   195 tokens (    0.22 ms per token,  4493.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.70 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      56.59 ms /   260 tokens (    0.22 ms per token,  4594.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      63.16 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.54 ms /   208 tokens (    0.20 ms per token,  4890.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.51 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.44 ms /   254 tokens (    0.18 ms per token,  5469.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.90 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      35.96 ms /   153 tokens (    0.24 ms per token,  4254.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.56 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      60.42 ms /   288 tokens (    0.21 ms per token,  4766.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.72 ms /   289 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.80 ms /    53 tokens (    0.52 ms per token,  1906.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.47 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.31 ms /   154 tokens (    0.26 ms per token,  3820.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.23 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.01 ms /   227 tokens (    0.21 ms per token,  4727.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.35 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.57 ms /    42 tokens (    0.63 ms per token,  1580.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.86 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.53 ms /    23 tokens (    1.15 ms per token,   867.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.66 ms /    24 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.08 ms /   116 tokens (    0.29 ms per token,  3506.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.91 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.99 ms /    21 tokens (    1.24 ms per token,   807.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.96 ms /    22 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.77 ms /    97 tokens (    0.33 ms per token,  3053.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.43 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.21 ms /   211 tokens (    0.22 ms per token,  4566.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.94 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.35 ms /   181 tokens (    0.23 ms per token,  4274.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.25 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.04 ms /   147 tokens (    0.27 ms per token,  3765.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.61 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.42 ms /    75 tokens (    0.41 ms per token,  2465.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.87 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.32 ms /   233 tokens (    0.21 ms per token,  4821.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.58 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.58 ms /   209 tokens (    0.22 ms per token,  4487.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.32 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.66 ms /    97 tokens (    0.32 ms per token,  3163.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.11 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.53 ms /    38 tokens (    0.70 ms per token,  1432.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.85 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.55 ms /    19 tokens (    1.34 ms per token,   743.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.36 ms /    20 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.10 ms /    82 tokens (    0.35 ms per token,  2817.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.37 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.50 ms /    92 tokens (    0.32 ms per token,  3118.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.96 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.26 ms /   225 tokens (    0.21 ms per token,  4760.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.06 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.73 ms /   207 tokens (    0.22 ms per token,  4526.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.17 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.40 ms /   194 tokens (    0.24 ms per token,  4180.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.48 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.52 ms /   171 tokens (    0.23 ms per token,  4326.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.93 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.09 ms /   195 tokens (    0.23 ms per token,  4422.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.92 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.90 ms /   156 tokens (    0.25 ms per token,  4010.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.87 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.12 ms /   187 tokens (    0.23 ms per token,  4439.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.87 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.31 ms /   199 tokens (    0.23 ms per token,  4297.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.93 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.08 ms /   208 tokens (    0.22 ms per token,  4513.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.16 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.32 ms /   210 tokens (    0.22 ms per token,  4533.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.03 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.31 ms /   221 tokens (    0.21 ms per token,  4670.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.59 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.62 ms /   213 tokens (    0.22 ms per token,  4569.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.85 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.19 ms /   230 tokens (    0.21 ms per token,  4772.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.95 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.77 ms /   228 tokens (    0.21 ms per token,  4773.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.26 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.75 ms /   215 tokens (    0.22 ms per token,  4599.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.98 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.84 ms /   217 tokens (    0.22 ms per token,  4632.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.32 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.40 ms /   235 tokens (    0.20 ms per token,  4958.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.28 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.95 ms /   239 tokens (    0.20 ms per token,  5089.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.71 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.81 ms /   186 tokens (    0.21 ms per token,  4671.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.37 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.95 ms /   200 tokens (    0.21 ms per token,  4767.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.01 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.65 ms /   220 tokens (    0.20 ms per token,  5040.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.40 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.18 ms /   224 tokens (    0.19 ms per token,  5187.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.31 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.25 ms /   226 tokens (    0.20 ms per token,  4994.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.35 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      53.32 ms /   268 tokens (    0.20 ms per token,  5026.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      59.27 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.05 ms /   247 tokens (    0.18 ms per token,  5483.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.04 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.55 ms /   218 tokens (    0.20 ms per token,  5006.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.65 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.57 ms /   214 tokens (    0.20 ms per token,  4911.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.71 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.77 ms /    57 tokens (    0.49 ms per token,  2052.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.57 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      11.88 ms /     6 tokens (    1.98 ms per token,   505.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      12.52 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.50 ms /    16 tokens (    1.59 ms per token,   627.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.33 ms /    17 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.24 ms /   194 tokens (    0.21 ms per token,  4704.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.87 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.52 ms /   166 tokens (    0.23 ms per token,  4309.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.56 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.12 ms /   134 tokens (    0.27 ms per token,  3710.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.55 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.94 ms /   168 tokens (    0.23 ms per token,  4314.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.17 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.60 ms /    63 tokens (    0.45 ms per token,  2202.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.42 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.20 ms /   108 tokens (    0.30 ms per token,  3354.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.20 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      86.45 ms /   512 tokens (    0.17 ms per token,  5922.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.74 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.93 ms /   512 tokens (    0.17 ms per token,  6028.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.52 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.62 ms /   512 tokens (    0.17 ms per token,  6050.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.37 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      87.06 ms /   512 tokens (    0.17 ms per token,  5881.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.07 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      87.70 ms /   512 tokens (    0.17 ms per token,  5838.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     103.00 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.18 ms /   512 tokens (    0.16 ms per token,  6082.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.49 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.23 ms /   512 tokens (    0.17 ms per token,  5803.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.59 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      87.79 ms /   512 tokens (    0.17 ms per token,  5831.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.08 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.46 ms /   512 tokens (    0.16 ms per token,  6061.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.40 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.05 ms /   512 tokens (    0.17 ms per token,  5815.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.61 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      87.76 ms /   512 tokens (    0.17 ms per token,  5834.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.25 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      83.54 ms /   512 tokens (    0.16 ms per token,  6128.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.11 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      83.31 ms /   512 tokens (    0.16 ms per token,  6145.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.47 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      83.25 ms /   512 tokens (    0.16 ms per token,  6150.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.02 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      79.83 ms /   512 tokens (    0.16 ms per token,  6413.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.65 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =     168.91 ms /   512 tokens (    0.33 ms per token,  3031.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     183.25 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =     131.12 ms /   512 tokens (    0.26 ms per token,  3904.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     144.29 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =     106.87 ms /   512 tokens (    0.21 ms per token,  4790.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.45 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      89.33 ms /   512 tokens (    0.17 ms per token,  5731.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.38 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.20 ms /   512 tokens (    0.17 ms per token,  5804.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.75 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      85.23 ms /   512 tokens (    0.17 ms per token,  6006.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.40 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.84 ms /   512 tokens (    0.17 ms per token,  6035.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.86 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      85.22 ms /   512 tokens (    0.17 ms per token,  6008.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.82 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.52 ms /   512 tokens (    0.17 ms per token,  6057.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.99 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      86.35 ms /   512 tokens (    0.17 ms per token,  5929.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.69 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.23 ms /   512 tokens (    0.17 ms per token,  5803.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.24 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      85.05 ms /   512 tokens (    0.17 ms per token,  6019.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.07 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.16 ms /   512 tokens (    0.16 ms per token,  6083.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.94 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.14 ms /   512 tokens (    0.17 ms per token,  5808.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.95 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.66 ms /   512 tokens (    0.17 ms per token,  6047.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.15 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      85.90 ms /   512 tokens (    0.17 ms per token,  5960.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.23 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.66 ms /   512 tokens (    0.17 ms per token,  5775.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.33 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      86.24 ms /   512 tokens (    0.17 ms per token,  5936.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.10 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      85.66 ms /   512 tokens (    0.17 ms per token,  5977.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.37 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.73 ms /   512 tokens (    0.17 ms per token,  5770.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.26 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.43 ms /   512 tokens (    0.16 ms per token,  6064.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.48 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      87.87 ms /   512 tokens (    0.17 ms per token,  5826.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.93 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.45 ms /   512 tokens (    0.17 ms per token,  5788.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.75 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.69 ms /   512 tokens (    0.17 ms per token,  6045.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.95 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      85.87 ms /   512 tokens (    0.17 ms per token,  5962.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.00 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.52 ms /   512 tokens (    0.17 ms per token,  5783.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.36 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      85.59 ms /   512 tokens (    0.17 ms per token,  5982.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.52 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      87.96 ms /   512 tokens (    0.17 ms per token,  5820.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.25 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.03 ms /   512 tokens (    0.17 ms per token,  5816.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.09 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.28 ms /   512 tokens (    0.16 ms per token,  6074.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.24 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      86.86 ms /   512 tokens (    0.17 ms per token,  5894.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.14 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.21 ms /   512 tokens (    0.17 ms per token,  5804.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.09 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.48 ms /   512 tokens (    0.16 ms per token,  6060.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.09 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      87.99 ms /   512 tokens (    0.17 ms per token,  5818.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.91 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.04 ms /   512 tokens (    0.17 ms per token,  5815.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.39 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      86.33 ms /   512 tokens (    0.17 ms per token,  5930.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.48 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      90.03 ms /   512 tokens (    0.18 ms per token,  5686.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.61 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      87.77 ms /   512 tokens (    0.17 ms per token,  5833.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.06 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      84.64 ms /   512 tokens (    0.17 ms per token,  6048.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.56 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.20 ms /   512 tokens (    0.17 ms per token,  5805.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.00 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      88.69 ms /   512 tokens (    0.17 ms per token,  5772.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.44 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      83.42 ms /   512 tokens (    0.16 ms per token,  6137.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.43 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      85.92 ms /   512 tokens (    0.17 ms per token,  5958.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.74 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      87.39 ms /   512 tokens (    0.17 ms per token,  5858.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.90 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      36.04 ms /   139 tokens (    0.26 ms per token,  3856.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.88 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.72 ms /     9 tokens (    2.86 ms per token,   349.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.51 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.38 ms /   131 tokens (    0.29 ms per token,  3413.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.64 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.13 ms /   235 tokens (    0.20 ms per token,  4882.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.00 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      75.59 ms /   392 tokens (    0.19 ms per token,  5185.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.72 ms /   393 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.22 ms /   174 tokens (    0.23 ms per token,  4436.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.68 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.95 ms /   200 tokens (    0.23 ms per token,  4353.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.78 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.51 ms /   133 tokens (    0.29 ms per token,  3453.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.42 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.30 ms /   115 tokens (    0.29 ms per token,  3453.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.51 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      37.31 ms /   132 tokens (    0.28 ms per token,  3537.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.76 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.47 ms /   182 tokens (    0.22 ms per token,  4497.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.18 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.91 ms /   101 tokens (    0.31 ms per token,  3267.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.52 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.34 ms /   194 tokens (    0.23 ms per token,  4279.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.83 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.38 ms /   196 tokens (    0.24 ms per token,  4226.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.58 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.05 ms /   199 tokens (    0.23 ms per token,  4416.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.79 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.24 ms /   223 tokens (    0.21 ms per token,  4720.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.68 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.11 ms /   246 tokens (    0.20 ms per token,  5113.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.75 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.74 ms /   197 tokens (    0.22 ms per token,  4503.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.30 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.23 ms /    36 tokens (    0.78 ms per token,  1275.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.67 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.66 ms /    70 tokens (    0.42 ms per token,  2360.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.66 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.61 ms /   128 tokens (    0.26 ms per token,  3808.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.65 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.86 ms /   240 tokens (    0.20 ms per token,  4912.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.87 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      32.80 ms /   114 tokens (    0.29 ms per token,  3475.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.97 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.02 ms /    35 tokens (    0.77 ms per token,  1295.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.16 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.21 ms /   116 tokens (    0.29 ms per token,  3493.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.22 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.60 ms /   244 tokens (    0.20 ms per token,  5020.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.17 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.28 ms /   209 tokens (    0.23 ms per token,  4420.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.36 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.72 ms /    53 tokens (    0.52 ms per token,  1912.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.36 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.17 ms /    65 tokens (    0.45 ms per token,  2228.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.20 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.44 ms /   204 tokens (    0.23 ms per token,  4392.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.25 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.00 ms /   173 tokens (    0.24 ms per token,  4219.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.21 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.25 ms /    93 tokens (    0.34 ms per token,  2976.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.22 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.23 ms /   215 tokens (    0.22 ms per token,  4552.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.03 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.85 ms /   248 tokens (    0.19 ms per token,  5183.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.56 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.59 ms /   210 tokens (    0.22 ms per token,  4507.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.92 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.01 ms /   165 tokens (    0.25 ms per token,  4023.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.12 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.16 ms /   234 tokens (    0.21 ms per token,  4759.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.66 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.54 ms /   151 tokens (    0.26 ms per token,  3819.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.15 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.79 ms /   156 tokens (    0.26 ms per token,  3920.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.05 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.77 ms /   139 tokens (    0.28 ms per token,  3585.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.04 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      42.14 ms /   188 tokens (    0.22 ms per token,  4460.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.90 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.50 ms /   199 tokens (    0.23 ms per token,  4279.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.40 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      43.31 ms /   192 tokens (    0.23 ms per token,  4433.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.12 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.14 ms /   102 tokens (    0.31 ms per token,  3275.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.74 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.98 ms /   196 tokens (    0.23 ms per token,  4357.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.44 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.72 ms /   176 tokens (    0.23 ms per token,  4321.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.95 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.44 ms /   162 tokens (    0.26 ms per token,  3908.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.88 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.16 ms /   243 tokens (    0.20 ms per token,  4943.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.82 ms /   244 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.41 ms /   225 tokens (    0.21 ms per token,  4745.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.66 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.39 ms /   155 tokens (    0.25 ms per token,  3934.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.25 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.37 ms /   110 tokens (    0.30 ms per token,  3296.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.68 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      59.91 ms /   283 tokens (    0.21 ms per token,  4723.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.43 ms /   284 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      85.14 ms /   512 tokens (    0.17 ms per token,  6013.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.37 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      79.02 ms /   466 tokens (    0.17 ms per token,  5897.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.13 ms /   467 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      64.27 ms /   323 tokens (    0.20 ms per token,  5025.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.50 ms /   324 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.89 ms /    87 tokens (    0.36 ms per token,  2816.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.10 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.12 ms /   247 tokens (    0.20 ms per token,  5028.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.52 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.94 ms /    18 tokens (    1.55 ms per token,   644.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.09 ms /    19 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.79 ms /    50 tokens (    0.58 ms per token,  1737.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.25 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.81 ms /    10 tokens (    2.58 ms per token,   387.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.46 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.76 ms /    37 tokens (    0.72 ms per token,  1382.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      27.98 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.98 ms /   193 tokens (    0.23 ms per token,  4290.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.83 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.96 ms /    66 tokens (    0.45 ms per token,  2202.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.90 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      49.16 ms /   233 tokens (    0.21 ms per token,  4739.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.14 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      44.55 ms /   199 tokens (    0.22 ms per token,  4466.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.09 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.16 ms /   234 tokens (    0.21 ms per token,  4858.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.10 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.24 ms /   230 tokens (    0.21 ms per token,  4767.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.99 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      31.65 ms /   105 tokens (    0.30 ms per token,  3317.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.34 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.80 ms /   247 tokens (    0.20 ms per token,  5061.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.27 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.75 ms /    87 tokens (    0.35 ms per token,  2828.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.12 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      46.47 ms /   214 tokens (    0.22 ms per token,  4605.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.60 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.24 ms /   203 tokens (    0.23 ms per token,  4297.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.73 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.13 ms /    77 tokens (    0.39 ms per token,  2555.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.18 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.54 ms /   170 tokens (    0.24 ms per token,  4193.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.74 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.09 ms /   162 tokens (    0.25 ms per token,  3942.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.09 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      40.83 ms /   170 tokens (    0.24 ms per token,  4163.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.22 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      39.08 ms /   151 tokens (    0.26 ms per token,  3864.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.72 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.55 ms /   195 tokens (    0.23 ms per token,  4280.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.33 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      33.54 ms /   119 tokens (    0.28 ms per token,  3548.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.57 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.71 ms /   166 tokens (    0.25 ms per token,  3980.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      46.08 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.64 ms /    89 tokens (    0.34 ms per token,  2904.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.10 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      45.80 ms /   201 tokens (    0.23 ms per token,  4388.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.56 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.30 ms /    53 tokens (    0.55 ms per token,  1808.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.09 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      48.33 ms /   228 tokens (    0.21 ms per token,  4718.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.81 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.71 ms /   229 tokens (    0.21 ms per token,  4800.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.74 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.57 ms /    29 tokens (    0.95 ms per token,  1052.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.01 ms /    30 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.70 ms /   134 tokens (    0.29 ms per token,  3462.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.06 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      26.86 ms /    42 tokens (    0.64 ms per token,  1563.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.24 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      47.36 ms /   224 tokens (    0.21 ms per token,  4729.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.79 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.07 ms /    44 tokens (    0.64 ms per token,  1567.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.59 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.94 ms /    83 tokens (    0.36 ms per token,  2772.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.32 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.62 ms /    72 tokens (    0.41 ms per token,  2430.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.94 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      28.34 ms /    64 tokens (    0.44 ms per token,  2258.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.32 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      30.50 ms /    95 tokens (    0.32 ms per token,  3114.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      32.98 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      14.16 ms /     6 tokens (    2.36 ms per token,   423.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      14.69 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      29.27 ms /    69 tokens (    0.42 ms per token,  2357.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.16 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.59 ms /    49 tokens (    0.56 ms per token,  1776.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.41 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      27.00 ms /    42 tokens (    0.64 ms per token,  1555.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      28.48 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      38.16 ms /   135 tokens (    0.28 ms per token,  3537.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.39 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      41.47 ms /   173 tokens (    0.24 ms per token,  4171.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.71 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =      80.02 ms\n",
      "llama_perf_context_print: prompt eval time =      25.69 ms /    10 tokens (    2.57 ms per token,   389.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      26.30 ms /    11 tokens\n",
      "llama_model_load_from_file_impl: using device CUDA0 (NVIDIA RTX A3000 12GB Laptop GPU) - 9332 MiB free\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Embedding generation for Llama-3.2-1B-Instruct.Q6_K] 62.73s\n",
      "‚úî Saved embeddings to /workspaces/VectorVet/embeddings/Llama-3.2-1B-Instruct.Q6_K_20news_chunks.npy\n",
      "‚Üí Embedding with Llama-3.1-8b-instruct-q6_k ‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 33 key-value pairs and 292 tensors from /workspaces/VectorVet/models/Llama-3.1-8b-instruct-q6_k.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Meta-Llama-3.1\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 8B\n",
      "llama_model_loader: - kv   6:                            general.license str              = llama3.1\n",
      "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   9:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  17:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"ƒ† ƒ†\", \"ƒ† ƒ†ƒ†ƒ†\", \"ƒ†ƒ† ƒ†ƒ†\", \"...\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  28:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  29:                      quantize.imatrix.file str              = /models_out/Meta-Llama-3.1-8B-Instruc...\n",
      "llama_model_loader: - kv  30:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  31:             quantize.imatrix.entries_count i32              = 224\n",
      "llama_model_loader: - kv  32:              quantize.imatrix.chunks_count i32              = 125\n",
      "llama_model_loader: - type  f32:   66 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q6_K\n",
      "print_info: file size   = 6.14 GiB (6.56 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 8B\n",
      "print_info: model params     = 8.03 B\n",
      "print_info: general.name     = Meta Llama 3.1 8B Instruct\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'ƒä'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CUDA0\n",
      "load_tensors: layer   1 assigned to device CUDA0\n",
      "load_tensors: layer   2 assigned to device CUDA0\n",
      "load_tensors: layer   3 assigned to device CUDA0\n",
      "load_tensors: layer   4 assigned to device CUDA0\n",
      "load_tensors: layer   5 assigned to device CUDA0\n",
      "load_tensors: layer   6 assigned to device CUDA0\n",
      "load_tensors: layer   7 assigned to device CUDA0\n",
      "load_tensors: layer   8 assigned to device CUDA0\n",
      "load_tensors: layer   9 assigned to device CUDA0\n",
      "load_tensors: layer  10 assigned to device CUDA0\n",
      "load_tensors: layer  11 assigned to device CUDA0\n",
      "load_tensors: layer  12 assigned to device CUDA0\n",
      "load_tensors: layer  13 assigned to device CUDA0\n",
      "load_tensors: layer  14 assigned to device CUDA0\n",
      "load_tensors: layer  15 assigned to device CUDA0\n",
      "load_tensors: layer  16 assigned to device CUDA0\n",
      "load_tensors: layer  17 assigned to device CUDA0\n",
      "load_tensors: layer  18 assigned to device CUDA0\n",
      "load_tensors: layer  19 assigned to device CUDA0\n",
      "load_tensors: layer  20 assigned to device CUDA0\n",
      "load_tensors: layer  21 assigned to device CUDA0\n",
      "load_tensors: layer  22 assigned to device CUDA0\n",
      "load_tensors: layer  23 assigned to device CUDA0\n",
      "load_tensors: layer  24 assigned to device CUDA0\n",
      "load_tensors: layer  25 assigned to device CUDA0\n",
      "load_tensors: layer  26 assigned to device CUDA0\n",
      "load_tensors: layer  27 assigned to device CUDA0\n",
      "load_tensors: layer  28 assigned to device CUDA0\n",
      "load_tensors: layer  29 assigned to device CUDA0\n",
      "load_tensors: layer  30 assigned to device CUDA0\n",
      "load_tensors: layer  31 assigned to device CUDA0\n",
      "load_tensors: layer  32 assigned to device CUDA0\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 0 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors: offloading 32 repeating layers to GPU\n",
      "load_tensors: offloading output layer to GPU\n",
      "load_tensors: offloaded 33/33 layers to GPU\n",
      "load_tensors:        CUDA0 model buffer size =  5871.99 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =   410.98 MiB\n",
      ".........................................................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 512\n",
      "llama_init_from_model: n_ctx_per_seq = 512\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 500000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =    64.00 MiB\n",
      "llama_init_from_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_init_from_model:  CUDA_Host  output buffer size =     0.02 MiB\n",
      "llama_init_from_model:      CUDA0 compute buffer size =   258.50 MiB\n",
      "llama_init_from_model:  CUDA_Host compute buffer size =     9.01 MiB\n",
      "llama_init_from_model: graph nodes  = 1030\n",
      "llama_init_from_model: graph splits = 2\n",
      "CUDA : ARCHS = 520 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'quantize.imatrix.entries_count': '224', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'quantize.imatrix.chunks_count': '125', 'quantize.imatrix.file': '/models_out/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct.imatrix', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \"Tools: \" + builtin_tools | reject(\\'equalto\\', \\'code_interpreter\\') | join(\", \") + \"\\\\n\\\\n\"}}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + \\'=\"\\' + arg_val + \\'\"\\' }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \")\" }}\\n        {%- else  %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n            {{- \\'\"parameters\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \"}\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we\\'re in ipython mode #}\\n            {{- \"<|eom_id|>\" }}\\n        {%- else %}\\n            {{- \"<|eot_id|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '18', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '500000.000000', 'general.architecture': 'llama', 'general.basename': 'Meta-Llama-3.1', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Meta Llama 3.1 8B Instruct', 'general.finetune': 'Instruct', 'general.type': 'model', 'general.size_label': '8B', 'general.license': 'llama3.1', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- set date_string = \"26 Jul 2024\" %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message + builtin tools #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if builtin_tools is defined or tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{%- if builtin_tools is defined %}\n",
      "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
      "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
      "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
      "                {%- if not loop.last %}\n",
      "                    {{- \", \" }}\n",
      "                {%- endif %}\n",
      "                {%- endfor %}\n",
      "            {{- \")\" }}\n",
      "        {%- else  %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "            {{- '\"parameters\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- \"}\" }}\n",
      "        {%- endif %}\n",
      "        {%- if builtin_tools is defined %}\n",
      "            {#- This means we're in ipython mode #}\n",
      "            {{- \"<|eom_id|>\" }}\n",
      "        {%- else %}\n",
      "            {{- \"<|eot_id|>\" }}\n",
      "        {%- endif %}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac9a5249a55414593dc49bbf6864298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding (Llama-3.1-8b-instruct-q6_k):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     164.24 ms /   122 tokens (    1.35 ms per token,   742.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.62 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.21 ms /   116 tokens (    1.35 ms per token,   742.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.66 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     198.29 ms /   182 tokens (    1.09 ms per token,   917.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     208.03 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     206.98 ms /   234 tokens (    0.88 ms per token,  1130.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.13 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     134.90 ms /    26 tokens (    5.19 ms per token,   192.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     137.09 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     155.91 ms /   114 tokens (    1.37 ms per token,   731.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.28 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     153.47 ms /   104 tokens (    1.48 ms per token,   677.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     158.78 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.52 ms /   103 tokens (    1.50 ms per token,   666.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.83 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     130.71 ms /    14 tokens (    9.34 ms per token,   107.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.98 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     260.54 ms /   313 tokens (    0.83 ms per token,  1201.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     277.76 ms /   314 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     191.39 ms /   158 tokens (    1.21 ms per token,   825.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.55 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     137.79 ms /    48 tokens (    2.87 ms per token,   348.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.66 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     203.55 ms /   227 tokens (    0.90 ms per token,  1115.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     214.93 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.58 ms /   198 tokens (    0.99 ms per token,  1012.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.18 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.57 ms /   190 tokens (    1.03 ms per token,   971.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.06 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.98 ms /   205 tokens (    0.96 ms per token,  1046.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.70 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     200.66 ms /   224 tokens (    0.90 ms per token,  1116.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.43 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =      30.02 ms /     2 tokens (   15.01 ms per token,    66.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      30.79 ms /     3 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     186.85 ms /   148 tokens (    1.26 ms per token,   792.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     193.77 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     205.44 ms /   240 tokens (    0.86 ms per token,  1168.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.76 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     189.18 ms /   156 tokens (    1.21 ms per token,   824.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     196.05 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     152.40 ms /   105 tokens (    1.45 ms per token,   688.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.70 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     207.88 ms /   248 tokens (    0.84 ms per token,  1193.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     221.58 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     133.92 ms /    33 tokens (    4.06 ms per token,   246.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.42 ms /    34 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     257.93 ms /   309 tokens (    0.83 ms per token,  1198.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     274.57 ms /   310 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     144.15 ms /    68 tokens (    2.12 ms per token,   471.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     147.72 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     157.33 ms /   128 tokens (    1.23 ms per token,   813.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.49 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     194.62 ms /   180 tokens (    1.08 ms per token,   924.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     203.20 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     193.31 ms /   174 tokens (    1.11 ms per token,   900.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     201.71 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     205.22 ms /   238 tokens (    0.86 ms per token,  1159.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.88 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     244.80 ms /   260 tokens (    0.94 ms per token,  1062.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     257.91 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     209.09 ms /   250 tokens (    0.84 ms per token,  1195.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     221.40 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     206.88 ms /   242 tokens (    0.85 ms per token,  1169.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.01 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     208.81 ms /   250 tokens (    0.84 ms per token,  1197.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     221.34 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     247.46 ms /   268 tokens (    0.92 ms per token,  1083.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     260.78 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     205.53 ms /   240 tokens (    0.86 ms per token,  1167.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.34 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     199.25 ms /   214 tokens (    0.93 ms per token,  1074.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     209.18 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     204.81 ms /   234 tokens (    0.88 ms per token,  1142.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.57 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     191.63 ms /   167 tokens (    1.15 ms per token,   871.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.00 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     182.24 ms /   131 tokens (    1.39 ms per token,   718.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     187.93 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     244.84 ms /   258 tokens (    0.95 ms per token,  1053.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     258.51 ms /   259 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     136.97 ms /    49 tokens (    2.80 ms per token,   357.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.23 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     182.60 ms /   133 tokens (    1.37 ms per token,   728.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.85 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     200.40 ms /   217 tokens (    0.92 ms per token,  1082.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.25 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     135.81 ms /    44 tokens (    3.09 ms per token,   323.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.75 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.24 ms /    53 tokens (    2.63 ms per token,   380.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.01 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     148.01 ms /    86 tokens (    1.72 ms per token,   581.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.13 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     193.22 ms /   173 tokens (    1.12 ms per token,   895.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     201.68 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     199.72 ms /   214 tokens (    0.93 ms per token,  1071.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     210.25 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     130.86 ms /    17 tokens (    7.70 ms per token,   129.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     132.37 ms /    18 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     205.85 ms /   237 tokens (    0.87 ms per token,  1151.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.55 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     197.18 ms /   203 tokens (    0.97 ms per token,  1029.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.65 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     153.43 ms /   108 tokens (    1.42 ms per token,   703.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     158.97 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.34 ms /   185 tokens (    1.06 ms per token,   947.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     203.21 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     201.46 ms /   222 tokens (    0.91 ms per token,  1101.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     212.66 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     146.91 ms /    77 tokens (    1.91 ms per token,   524.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.75 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     134.43 ms /    37 tokens (    3.63 ms per token,   275.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     137.38 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     204.27 ms /   232 tokens (    0.88 ms per token,  1135.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.76 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     140.40 ms /    64 tokens (    2.19 ms per token,   455.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.80 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     133.96 ms /    37 tokens (    3.62 ms per token,   276.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.58 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     150.87 ms /    96 tokens (    1.57 ms per token,   636.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.63 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     194.51 ms /   193 tokens (    1.01 ms per token,   992.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.10 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.61 ms /   187 tokens (    1.05 ms per token,   955.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.81 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     192.85 ms /   171 tokens (    1.13 ms per token,   886.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     200.44 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.08 ms /   190 tokens (    1.03 ms per token,   968.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.76 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.26 ms /   110 tokens (    1.40 ms per token,   713.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.43 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     200.84 ms /   220 tokens (    0.91 ms per token,  1095.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.09 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     192.33 ms /   169 tokens (    1.14 ms per token,   878.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.39 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     203.91 ms /   229 tokens (    0.89 ms per token,  1123.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     214.91 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     197.38 ms /   203 tokens (    0.97 ms per token,  1028.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.93 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     203.99 ms /   227 tokens (    0.90 ms per token,  1112.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     214.64 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     140.15 ms /    58 tokens (    2.42 ms per token,   413.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.55 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =      34.23 ms /     3 tokens (   11.41 ms per token,    87.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.14 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.55 ms /    57 tokens (    2.45 ms per token,   408.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.44 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     129.01 ms /    14 tokens (    9.21 ms per token,   108.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.33 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     246.87 ms /   261 tokens (    0.95 ms per token,  1057.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     259.66 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     194.00 ms /   174 tokens (    1.11 ms per token,   896.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     201.51 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     201.28 ms /   220 tokens (    0.91 ms per token,  1093.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.72 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     147.47 ms /    75 tokens (    1.97 ms per token,   508.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.35 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     138.75 ms /    55 tokens (    2.52 ms per token,   396.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.80 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     133.88 ms /    26 tokens (    5.15 ms per token,   194.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.19 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     157.50 ms /   123 tokens (    1.28 ms per token,   780.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.57 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.61 ms /    60 tokens (    2.33 ms per token,   429.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.01 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     148.02 ms /    85 tokens (    1.74 ms per token,   574.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.36 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     204.22 ms /   230 tokens (    0.89 ms per token,  1126.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.09 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     198.68 ms /   208 tokens (    0.96 ms per token,  1046.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     208.91 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     140.27 ms /    59 tokens (    2.38 ms per token,   420.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.82 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.65 ms /   122 tokens (    1.28 ms per token,   778.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.44 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     202.72 ms /   223 tokens (    0.91 ms per token,  1100.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     214.38 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     205.64 ms /   237 tokens (    0.87 ms per token,  1152.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.80 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.44 ms /   197 tokens (    1.00 ms per token,  1002.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     207.09 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.04 ms /   186 tokens (    1.05 ms per token,   948.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.38 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     206.62 ms /   240 tokens (    0.86 ms per token,  1161.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     220.90 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     151.21 ms /    99 tokens (    1.53 ms per token,   654.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.19 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     184.18 ms /   139 tokens (    1.33 ms per token,   754.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.80 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     133.58 ms /    31 tokens (    4.31 ms per token,   232.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.66 ms /    32 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     148.32 ms /    83 tokens (    1.79 ms per token,   559.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.56 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     191.10 ms /   160 tokens (    1.19 ms per token,   837.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.29 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     201.29 ms /   217 tokens (    0.93 ms per token,  1078.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     212.32 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     147.56 ms /    79 tokens (    1.87 ms per token,   535.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.81 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     200.91 ms /   211 tokens (    0.95 ms per token,  1050.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.90 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     211.71 ms /   256 tokens (    0.83 ms per token,  1209.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.91 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     282.99 ms /   371 tokens (    0.76 ms per token,  1310.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     302.48 ms /   372 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     199.29 ms /   209 tokens (    0.95 ms per token,  1048.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     208.26 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     203.08 ms /   222 tokens (    0.91 ms per token,  1093.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     213.64 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     189.45 ms /   153 tokens (    1.24 ms per token,   807.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     196.65 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     203.38 ms /   224 tokens (    0.91 ms per token,  1101.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     214.29 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     206.54 ms /   236 tokens (    0.88 ms per token,  1142.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.32 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     194.81 ms /   174 tokens (    1.12 ms per token,   893.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     202.74 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     185.11 ms /   142 tokens (    1.30 ms per token,   767.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.84 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.42 ms /   112 tokens (    1.38 ms per token,   725.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.84 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     131.95 ms /    28 tokens (    4.71 ms per token,   212.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.83 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     205.36 ms /   231 tokens (    0.89 ms per token,  1124.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.15 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.63 ms /    61 tokens (    2.29 ms per token,   436.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.90 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     134.74 ms /    42 tokens (    3.21 ms per token,   311.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     137.59 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     148.58 ms /    87 tokens (    1.71 ms per token,   585.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.29 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     186.30 ms /   146 tokens (    1.28 ms per token,   783.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     193.10 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     199.84 ms /   207 tokens (    0.97 ms per token,  1035.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     210.55 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     149.07 ms /    87 tokens (    1.71 ms per token,   583.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.48 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     193.79 ms /   172 tokens (    1.13 ms per token,   887.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     201.69 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.85 ms /   182 tokens (    1.08 ms per token,   929.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.60 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.33 ms /   187 tokens (    1.05 ms per token,   952.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.95 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     197.42 ms /   198 tokens (    1.00 ms per token,  1002.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.67 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     192.91 ms /   168 tokens (    1.15 ms per token,   870.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     200.49 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.31 ms /   183 tokens (    1.07 ms per token,   932.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.66 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     135.95 ms /    42 tokens (    3.24 ms per token,   308.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.44 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     212.00 ms /   256 tokens (    0.83 ms per token,  1207.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     225.08 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     198.75 ms /   203 tokens (    0.98 ms per token,  1021.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     208.35 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     185.81 ms /   141 tokens (    1.32 ms per token,   758.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.96 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     201.72 ms /   217 tokens (    0.93 ms per token,  1075.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     212.28 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.33 ms /   185 tokens (    1.06 ms per token,   942.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.29 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     200.56 ms /   211 tokens (    0.95 ms per token,  1052.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.22 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.85 ms /   112 tokens (    1.38 ms per token,   723.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.22 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     155.43 ms /   116 tokens (    1.34 ms per token,   746.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.87 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     192.08 ms /   166 tokens (    1.16 ms per token,   864.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.48 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     202.17 ms /   215 tokens (    0.94 ms per token,  1063.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     212.88 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.43 ms /   181 tokens (    1.08 ms per token,   926.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.48 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     250.55 ms /   266 tokens (    0.94 ms per token,  1061.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     264.07 ms /   267 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     137.35 ms /    46 tokens (    2.99 ms per token,   334.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.30 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     203.70 ms /   223 tokens (    0.91 ms per token,  1094.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.17 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.72 ms /   194 tokens (    1.01 ms per token,   991.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.54 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     204.66 ms /   226 tokens (    0.91 ms per token,  1104.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.79 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     197.63 ms /   200 tokens (    0.99 ms per token,  1012.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     207.17 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     192.19 ms /   165 tokens (    1.16 ms per token,   858.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.77 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     199.72 ms /   207 tokens (    0.96 ms per token,  1036.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     209.41 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     198.15 ms /   200 tokens (    0.99 ms per token,  1009.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     207.55 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.99 ms /   115 tokens (    1.35 ms per token,   741.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.74 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     182.36 ms /   130 tokens (    1.40 ms per token,   712.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.15 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     204.87 ms /   226 tokens (    0.91 ms per token,  1103.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.72 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     137.16 ms /    51 tokens (    2.69 ms per token,   371.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.23 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     206.24 ms /   232 tokens (    0.89 ms per token,  1124.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.08 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     148.86 ms /    89 tokens (    1.67 ms per token,   597.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.50 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     203.49 ms /   221 tokens (    0.92 ms per token,  1086.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     214.81 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.96 ms /   194 tokens (    1.02 ms per token,   984.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.08 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.77 ms /   120 tokens (    1.31 ms per token,   765.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.35 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.90 ms /    64 tokens (    2.19 ms per token,   457.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.39 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     210.83 ms /   249 tokens (    0.85 ms per token,  1181.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.41 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     132.78 ms /    28 tokens (    4.74 ms per token,   210.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.02 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     198.50 ms /   201 tokens (    0.99 ms per token,  1012.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     208.26 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     198.47 ms /   202 tokens (    0.98 ms per token,  1017.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     208.93 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     190.65 ms /   158 tokens (    1.21 ms per token,   828.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     200.23 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.60 ms /   111 tokens (    1.39 ms per token,   717.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.89 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     189.97 ms /   158 tokens (    1.20 ms per token,   831.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     197.14 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     198.27 ms /   199 tokens (    1.00 ms per token,  1003.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     208.06 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     191.29 ms /   159 tokens (    1.20 ms per token,   831.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.32 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.95 ms /   186 tokens (    1.06 ms per token,   944.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.20 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     199.64 ms /   206 tokens (    0.97 ms per token,  1031.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     209.68 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     191.90 ms /   160 tokens (    1.20 ms per token,   833.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.24 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     185.62 ms /   139 tokens (    1.34 ms per token,   748.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     192.66 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     187.89 ms /   146 tokens (    1.29 ms per token,   777.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     194.62 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     146.47 ms /    74 tokens (    1.98 ms per token,   505.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.28 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     202.77 ms /   218 tokens (    0.93 ms per token,  1075.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     214.05 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     157.45 ms /   123 tokens (    1.28 ms per token,   781.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.15 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     203.82 ms /   221 tokens (    0.92 ms per token,  1084.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.30 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     185.36 ms /   139 tokens (    1.33 ms per token,   749.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.79 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     138.47 ms /    51 tokens (    2.71 ms per token,   368.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.60 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     135.20 ms /    41 tokens (    3.30 ms per token,   303.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     137.82 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     189.85 ms /   156 tokens (    1.22 ms per token,   821.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.20 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.49 ms /   194 tokens (    1.01 ms per token,   987.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.98 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     146.88 ms /    74 tokens (    1.98 ms per token,   503.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.73 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     155.92 ms /   114 tokens (    1.37 ms per token,   731.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.52 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.91 ms /   114 tokens (    1.36 ms per token,   735.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.17 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     249.68 ms /   260 tokens (    0.96 ms per token,  1041.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     264.53 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     189.80 ms /   155 tokens (    1.22 ms per token,   816.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     197.06 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.85 ms /    63 tokens (    2.22 ms per token,   450.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.73 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.38 ms /    49 tokens (    2.84 ms per token,   351.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.88 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     143.38 ms /    65 tokens (    2.21 ms per token,   453.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     147.02 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     200.08 ms /   204 tokens (    0.98 ms per token,  1019.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     210.62 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     201.61 ms /   214 tokens (    0.94 ms per token,  1061.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     213.00 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     183.49 ms /   131 tokens (    1.40 ms per token,   713.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     189.89 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.00 ms /   109 tokens (    1.41 ms per token,   707.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.39 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     151.55 ms /    99 tokens (    1.53 ms per token,   653.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.21 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.14 ms /   108 tokens (    1.43 ms per token,   700.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.55 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     212.41 ms /   252 tokens (    0.84 ms per token,  1186.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     225.23 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     151.93 ms /    96 tokens (    1.58 ms per token,   631.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.53 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     186.62 ms /   145 tokens (    1.29 ms per token,   776.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     196.36 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.68 ms /   181 tokens (    1.08 ms per token,   924.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.73 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     202.09 ms /   215 tokens (    0.94 ms per token,  1063.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     213.61 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     127.87 ms /    11 tokens (   11.62 ms per token,    86.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     129.22 ms /    12 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.48 ms /   182 tokens (    1.08 ms per token,   926.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.74 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     198.99 ms /   201 tokens (    0.99 ms per token,  1010.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     208.35 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     193.87 ms /   171 tokens (    1.13 ms per token,   882.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     201.74 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.69 ms /   117 tokens (    1.34 ms per token,   746.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.29 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     147.62 ms /    76 tokens (    1.94 ms per token,   514.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.71 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.73 ms /   181 tokens (    1.09 ms per token,   920.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.65 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     133.85 ms /    36 tokens (    3.72 ms per token,   268.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.21 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     152.53 ms /   103 tokens (    1.48 ms per token,   675.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.41 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     145.40 ms /    67 tokens (    2.17 ms per token,   460.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.19 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     193.34 ms /   165 tokens (    1.17 ms per token,   853.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     200.49 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     158.71 ms /   124 tokens (    1.28 ms per token,   781.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.61 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.03 ms /    53 tokens (    2.62 ms per token,   381.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.77 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     144.92 ms /    66 tokens (    2.20 ms per token,   455.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     148.18 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     157.72 ms /   121 tokens (    1.30 ms per token,   767.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.86 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     132.12 ms /    26 tokens (    5.08 ms per token,   196.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.96 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     152.75 ms /    99 tokens (    1.54 ms per token,   648.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.66 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.05 ms /   106 tokens (    1.45 ms per token,   688.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.31 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     136.83 ms /    46 tokens (    2.97 ms per token,   336.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     139.41 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     251.36 ms /   261 tokens (    0.96 ms per token,  1038.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     264.53 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     208.41 ms /   237 tokens (    0.88 ms per token,  1137.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.76 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.54 ms /   175 tokens (    1.12 ms per token,   894.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     203.13 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     207.17 ms /   231 tokens (    0.90 ms per token,  1115.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.98 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     146.68 ms /    72 tokens (    2.04 ms per token,   490.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.32 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     211.85 ms /   248 tokens (    0.85 ms per token,  1170.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.78 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     183.85 ms /   132 tokens (    1.39 ms per token,   717.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     190.16 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     136.20 ms /    45 tokens (    3.03 ms per token,   330.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.88 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     129.14 ms /    15 tokens (    8.61 ms per token,   116.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.52 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     186.49 ms /   144 tokens (    1.30 ms per token,   772.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     193.14 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     200.85 ms /   207 tokens (    0.97 ms per token,  1030.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.46 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     188.75 ms /   150 tokens (    1.26 ms per token,   794.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     195.68 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     134.55 ms /    34 tokens (    3.96 ms per token,   252.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.91 ms /    35 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     197.17 ms /   193 tokens (    1.02 ms per token,   978.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.05 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     151.47 ms /    96 tokens (    1.58 ms per token,   633.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.08 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     190.94 ms /   155 tokens (    1.23 ms per token,   811.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     197.71 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     146.68 ms /    75 tokens (    1.96 ms per token,   511.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.67 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.22 ms /   118 tokens (    1.32 ms per token,   755.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.89 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.34 ms /    59 tokens (    2.36 ms per token,   423.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.60 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     205.95 ms /   224 tokens (    0.92 ms per token,  1087.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.25 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     205.94 ms /   224 tokens (    0.92 ms per token,  1087.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.64 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     250.81 ms /   257 tokens (    0.98 ms per token,  1024.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     264.57 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     137.86 ms /    47 tokens (    2.93 ms per token,   340.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.81 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     200.37 ms /   204 tokens (    0.98 ms per token,  1018.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     209.66 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     138.94 ms /    59 tokens (    2.35 ms per token,   424.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.51 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     128.86 ms /     9 tokens (   14.32 ms per token,    69.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.06 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     198.44 ms /   192 tokens (    1.03 ms per token,   967.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.97 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     135.18 ms /    38 tokens (    3.56 ms per token,   281.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     137.66 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     185.32 ms /   134 tokens (    1.38 ms per token,   723.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.48 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     190.15 ms /   153 tokens (    1.24 ms per token,   804.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     196.85 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     260.58 ms /   292 tokens (    0.89 ms per token,  1120.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     275.28 ms /   293 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     151.59 ms /    95 tokens (    1.60 ms per token,   626.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.46 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     339.15 ms /   448 tokens (    0.76 ms per token,  1320.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     363.08 ms /   449 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     350.43 ms /   487 tokens (    0.72 ms per token,  1389.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     376.16 ms /   488 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     345.31 ms /   486 tokens (    0.71 ms per token,  1407.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     371.30 ms /   487 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     351.74 ms /   493 tokens (    0.71 ms per token,  1401.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     378.70 ms /   494 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     345.72 ms /   487 tokens (    0.71 ms per token,  1408.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     370.82 ms /   488 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     346.28 ms /   485 tokens (    0.71 ms per token,  1400.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     371.39 ms /   486 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     346.43 ms /   490 tokens (    0.71 ms per token,  1414.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     371.33 ms /   491 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     347.27 ms /   489 tokens (    0.71 ms per token,  1408.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     374.59 ms /   490 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     255.03 ms /   273 tokens (    0.93 ms per token,  1070.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     269.57 ms /   274 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     153.46 ms /   103 tokens (    1.49 ms per token,   671.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     158.65 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     129.15 ms /    10 tokens (   12.92 ms per token,    77.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.50 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     204.32 ms /   216 tokens (    0.95 ms per token,  1057.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.02 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     357.77 ms /   512 tokens (    0.70 ms per token,  1431.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     386.34 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     353.13 ms /   512 tokens (    0.69 ms per token,  1449.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     381.89 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     353.94 ms /   512 tokens (    0.69 ms per token,  1446.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     380.93 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     353.30 ms /   512 tokens (    0.69 ms per token,  1449.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     381.14 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     353.30 ms /   512 tokens (    0.69 ms per token,  1449.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     381.06 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     354.04 ms /   512 tokens (    0.69 ms per token,  1446.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     384.23 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     354.43 ms /   512 tokens (    0.69 ms per token,  1444.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     382.33 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     354.31 ms /   512 tokens (    0.69 ms per token,  1445.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     381.63 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     360.12 ms /   512 tokens (    0.70 ms per token,  1421.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     388.15 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     357.36 ms /   512 tokens (    0.70 ms per token,  1432.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     385.31 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     355.92 ms /   512 tokens (    0.70 ms per token,  1438.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     382.82 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     356.42 ms /   512 tokens (    0.70 ms per token,  1436.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     386.91 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     359.93 ms /   512 tokens (    0.70 ms per token,  1422.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     386.21 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     366.37 ms /   512 tokens (    0.72 ms per token,  1397.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     392.32 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     360.11 ms /   512 tokens (    0.70 ms per token,  1421.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     388.52 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     357.67 ms /   512 tokens (    0.70 ms per token,  1431.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     385.17 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     363.81 ms /   512 tokens (    0.71 ms per token,  1407.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     391.14 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     375.46 ms /   512 tokens (    0.73 ms per token,  1363.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     403.48 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     366.45 ms /   512 tokens (    0.72 ms per token,  1397.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     395.70 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     366.33 ms /   512 tokens (    0.72 ms per token,  1397.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     395.18 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     379.64 ms /   512 tokens (    0.74 ms per token,  1348.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     408.28 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     372.41 ms /   512 tokens (    0.73 ms per token,  1374.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     400.35 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     374.61 ms /   512 tokens (    0.73 ms per token,  1366.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     403.09 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     380.92 ms /   512 tokens (    0.74 ms per token,  1344.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     408.97 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     379.26 ms /   512 tokens (    0.74 ms per token,  1350.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     406.66 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     375.10 ms /   512 tokens (    0.73 ms per token,  1364.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     403.31 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     381.02 ms /   512 tokens (    0.74 ms per token,  1343.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     413.49 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     379.88 ms /   512 tokens (    0.74 ms per token,  1347.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     412.95 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     380.30 ms /   512 tokens (    0.74 ms per token,  1346.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     409.54 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     380.17 ms /   512 tokens (    0.74 ms per token,  1346.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     408.03 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     379.94 ms /   512 tokens (    0.74 ms per token,  1347.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     408.01 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     380.26 ms /   512 tokens (    0.74 ms per token,  1346.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     409.45 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     384.24 ms /   512 tokens (    0.75 ms per token,  1332.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     411.04 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     379.27 ms /   512 tokens (    0.74 ms per token,  1349.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     407.86 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     379.64 ms /   512 tokens (    0.74 ms per token,  1348.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     408.31 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     377.54 ms /   512 tokens (    0.74 ms per token,  1356.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     407.60 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     376.45 ms /   512 tokens (    0.74 ms per token,  1360.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     404.63 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     379.38 ms /   512 tokens (    0.74 ms per token,  1349.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     408.78 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     380.93 ms /   512 tokens (    0.74 ms per token,  1344.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     407.49 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     379.25 ms /   512 tokens (    0.74 ms per token,  1350.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     407.73 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     384.72 ms /   512 tokens (    0.75 ms per token,  1330.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     413.45 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     380.87 ms /   512 tokens (    0.74 ms per token,  1344.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     408.45 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     380.62 ms /   512 tokens (    0.74 ms per token,  1345.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     409.81 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     384.68 ms /   512 tokens (    0.75 ms per token,  1330.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     414.72 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     372.20 ms /   512 tokens (    0.73 ms per token,  1375.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     400.75 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     381.04 ms /   512 tokens (    0.74 ms per token,  1343.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     410.66 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     382.88 ms /   512 tokens (    0.75 ms per token,  1337.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     410.42 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     378.46 ms /   512 tokens (    0.74 ms per token,  1352.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     407.22 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     381.60 ms /   512 tokens (    0.75 ms per token,  1341.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     415.32 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     381.12 ms /   512 tokens (    0.74 ms per token,  1343.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     410.35 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     380.67 ms /   512 tokens (    0.74 ms per token,  1345.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     409.08 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     384.49 ms /   512 tokens (    0.75 ms per token,  1331.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     412.28 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     405.56 ms /   512 tokens (    0.79 ms per token,  1262.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     434.20 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     388.62 ms /   512 tokens (    0.76 ms per token,  1317.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     418.44 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     387.15 ms /   512 tokens (    0.76 ms per token,  1322.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     417.38 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     376.95 ms /   512 tokens (    0.74 ms per token,  1358.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     404.42 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     383.77 ms /   512 tokens (    0.75 ms per token,  1334.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     412.76 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     387.57 ms /   512 tokens (    0.76 ms per token,  1321.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     416.18 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     388.25 ms /   512 tokens (    0.76 ms per token,  1318.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     416.55 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     355.50 ms /   385 tokens (    0.92 ms per token,  1082.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     376.30 ms /   386 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     211.41 ms /   192 tokens (    1.10 ms per token,   908.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     220.09 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     223.76 ms /   203 tokens (    1.10 ms per token,   907.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     232.99 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     202.55 ms /   165 tokens (    1.23 ms per token,   814.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     209.74 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     140.97 ms /    50 tokens (    2.82 ms per token,   354.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.79 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     281.85 ms /   265 tokens (    1.06 ms per token,   940.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     297.43 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     206.84 ms /   190 tokens (    1.09 ms per token,   918.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.91 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     208.45 ms /   177 tokens (    1.18 ms per token,   849.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.08 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     153.04 ms /    75 tokens (    2.04 ms per token,   490.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.79 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     137.44 ms /    32 tokens (    4.29 ms per token,   232.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     139.80 ms /    33 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.08 ms /    78 tokens (    1.98 ms per token,   506.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     158.30 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     157.07 ms /    93 tokens (    1.69 ms per token,   592.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.80 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     225.86 ms /   209 tokens (    1.08 ms per token,   925.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     242.47 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     140.47 ms /    50 tokens (    2.81 ms per token,   355.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.45 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     287.81 ms /   260 tokens (    1.11 ms per token,   903.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     301.49 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     218.37 ms /   196 tokens (    1.11 ms per token,   897.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     227.71 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     235.66 ms /   250 tokens (    0.94 ms per token,  1060.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     248.75 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     208.36 ms /   180 tokens (    1.16 ms per token,   863.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.50 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     225.33 ms /   218 tokens (    1.03 ms per token,   967.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     237.75 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     198.38 ms /   141 tokens (    1.41 ms per token,   710.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.13 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     234.04 ms /   230 tokens (    1.02 ms per token,   982.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     247.68 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     391.12 ms /   385 tokens (    1.02 ms per token,   984.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     414.70 ms /   386 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     225.53 ms /   212 tokens (    1.06 ms per token,   940.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     237.25 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     234.56 ms /   237 tokens (    0.99 ms per token,  1010.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     246.64 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     137.25 ms /    32 tokens (    4.29 ms per token,   233.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     139.39 ms /    33 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     153.44 ms /    78 tokens (    1.97 ms per token,   508.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.41 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     237.44 ms /   232 tokens (    1.02 ms per token,   977.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.40 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     236.06 ms /   211 tokens (    1.12 ms per token,   893.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     248.04 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.11 ms /    81 tokens (    1.93 ms per token,   518.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.25 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     164.82 ms /   112 tokens (    1.47 ms per token,   679.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.45 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     204.63 ms /   130 tokens (    1.57 ms per token,   635.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.21 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     207.09 ms /   143 tokens (    1.45 ms per token,   690.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.98 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     155.69 ms /    77 tokens (    2.02 ms per token,   494.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.72 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.89 ms /    75 tokens (    2.07 ms per token,   484.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.38 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     215.28 ms /   163 tokens (    1.32 ms per token,   757.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     224.54 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     218.90 ms /   188 tokens (    1.16 ms per token,   858.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     229.98 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     167.17 ms /   125 tokens (    1.34 ms per token,   747.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     174.37 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     136.08 ms /    22 tokens (    6.19 ms per token,   161.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.12 ms /    23 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     164.68 ms /   111 tokens (    1.48 ms per token,   674.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.35 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     136.80 ms /    19 tokens (    7.20 ms per token,   138.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.60 ms /    20 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     260.31 ms /   208 tokens (    1.25 ms per token,   799.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     273.95 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     142.09 ms /    38 tokens (    3.74 ms per token,   267.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.15 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     142.86 ms /    44 tokens (    3.25 ms per token,   308.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.73 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     147.06 ms /    64 tokens (    2.30 ms per token,   435.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.22 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     337.15 ms /   268 tokens (    1.26 ms per token,   794.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     351.32 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     162.11 ms /    77 tokens (    2.11 ms per token,   474.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.36 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     138.56 ms /    24 tokens (    5.77 ms per token,   173.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     140.50 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     144.91 ms /    58 tokens (    2.50 ms per token,   400.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     148.79 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.60 ms /    29 tokens (    4.81 ms per token,   207.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.74 ms /    30 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     163.40 ms /    79 tokens (    2.07 ms per token,   483.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     168.69 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     134.86 ms /    15 tokens (    8.99 ms per token,   111.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.84 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     230.09 ms /   149 tokens (    1.54 ms per token,   647.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     237.87 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     238.18 ms /   172 tokens (    1.38 ms per token,   722.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     246.73 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     164.68 ms /    83 tokens (    1.98 ms per token,   504.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.34 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     144.87 ms /    56 tokens (    2.59 ms per token,   386.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     148.21 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     260.71 ms /   207 tokens (    1.26 ms per token,   793.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     274.40 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     165.59 ms /    92 tokens (    1.80 ms per token,   555.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.68 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     273.98 ms /   242 tokens (    1.13 ms per token,   883.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     287.61 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     241.25 ms /   207 tokens (    1.17 ms per token,   858.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.75 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     234.34 ms /   157 tokens (    1.49 ms per token,   669.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     241.61 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     246.11 ms /   181 tokens (    1.36 ms per token,   735.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     255.53 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     160.10 ms /    65 tokens (    2.46 ms per token,   406.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.79 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.35 ms /    26 tokens (    5.36 ms per token,   186.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.29 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     274.59 ms /   229 tokens (    1.20 ms per token,   833.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     286.96 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     141.44 ms /    35 tokens (    4.04 ms per token,   247.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.84 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     229.97 ms /   141 tokens (    1.63 ms per token,   613.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     237.19 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     274.06 ms /   226 tokens (    1.21 ms per token,   824.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     286.55 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     134.73 ms /    15 tokens (    8.98 ms per token,   111.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.27 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     179.09 ms /   123 tokens (    1.46 ms per token,   686.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     185.74 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     142.49 ms /    43 tokens (    3.31 ms per token,   301.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.41 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     146.10 ms /    59 tokens (    2.48 ms per token,   403.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.36 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     167.77 ms /    90 tokens (    1.86 ms per token,   536.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     172.95 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     347.20 ms /   267 tokens (    1.30 ms per token,   769.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     361.70 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     161.31 ms /    89 tokens (    1.81 ms per token,   551.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.88 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     143.46 ms /    53 tokens (    2.71 ms per token,   369.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     146.60 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     142.70 ms /    53 tokens (    2.69 ms per token,   371.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.92 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     243.42 ms /   144 tokens (    1.69 ms per token,   591.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.28 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.01 ms /    93 tokens (    2.11 ms per token,   474.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     201.58 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.00 ms /    42 tokens (    3.67 ms per token,   272.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.52 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     432.93 ms /   268 tokens (    1.62 ms per token,   619.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     447.76 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     269.19 ms /   214 tokens (    1.26 ms per token,   794.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     280.21 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     262.56 ms /   203 tokens (    1.29 ms per token,   773.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     273.54 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     240.22 ms /   163 tokens (    1.47 ms per token,   678.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     248.12 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     167.76 ms /    91 tokens (    1.84 ms per token,   542.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     173.12 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     142.44 ms /    44 tokens (    3.24 ms per token,   308.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.09 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     141.05 ms /    32 tokens (    4.41 ms per token,   226.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.29 ms /    33 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     164.85 ms /    77 tokens (    2.14 ms per token,   467.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     168.91 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     146.81 ms /    59 tokens (    2.49 ms per token,   401.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.98 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     314.98 ms /   235 tokens (    1.34 ms per token,   746.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     327.25 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     306.52 ms /   237 tokens (    1.29 ms per token,   773.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     320.25 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     264.13 ms /   243 tokens (    1.09 ms per token,   919.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     275.91 ms /   244 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     256.39 ms /   220 tokens (    1.17 ms per token,   858.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     268.40 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     218.69 ms /   143 tokens (    1.53 ms per token,   653.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     225.46 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     261.93 ms /   153 tokens (    1.71 ms per token,   584.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     269.43 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     267.16 ms /   162 tokens (    1.65 ms per token,   606.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     275.22 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     144.31 ms /    44 tokens (    3.28 ms per token,   304.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     147.17 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     258.65 ms /   136 tokens (    1.90 ms per token,   525.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     265.20 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     312.73 ms /   238 tokens (    1.31 ms per token,   761.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     325.02 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     250.30 ms /   203 tokens (    1.23 ms per token,   811.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     260.44 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     246.73 ms /   176 tokens (    1.40 ms per token,   713.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     254.58 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     246.87 ms /   139 tokens (    1.78 ms per token,   563.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.53 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     261.21 ms /   162 tokens (    1.61 ms per token,   620.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     269.86 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     144.29 ms /    43 tokens (    3.36 ms per token,   298.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     147.70 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     281.76 ms /   195 tokens (    1.44 ms per token,   692.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     292.20 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     262.01 ms /   238 tokens (    1.10 ms per token,   908.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     274.37 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     147.32 ms /    59 tokens (    2.50 ms per token,   400.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.87 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     300.57 ms /   216 tokens (    1.39 ms per token,   718.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     311.13 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     179.53 ms /   100 tokens (    1.80 ms per token,   557.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     184.27 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     183.61 ms /    96 tokens (    1.91 ms per token,   522.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.35 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     275.53 ms /   187 tokens (    1.47 ms per token,   678.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     285.71 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     270.60 ms /   185 tokens (    1.46 ms per token,   683.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     279.17 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     273.43 ms /   189 tokens (    1.45 ms per token,   691.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     283.33 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     384.03 ms /   272 tokens (    1.41 ms per token,   708.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     398.86 ms /   273 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     142.82 ms /    42 tokens (    3.40 ms per token,   294.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.28 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     165.16 ms /    79 tokens (    2.09 ms per token,   478.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     169.73 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     174.10 ms /    76 tokens (    2.29 ms per token,   436.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     178.11 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     315.45 ms /   245 tokens (    1.29 ms per token,   776.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     329.28 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     144.40 ms /    40 tokens (    3.61 ms per token,   277.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     147.21 ms /    41 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     190.35 ms /   116 tokens (    1.64 ms per token,   609.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     196.80 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     141.33 ms /    22 tokens (    6.42 ms per token,   155.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.28 ms /    23 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     382.62 ms /   260 tokens (    1.47 ms per token,   679.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     396.61 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     169.22 ms /   106 tokens (    1.60 ms per token,   626.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     174.69 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     223.54 ms /   156 tokens (    1.43 ms per token,   697.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     231.11 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     133.98 ms /    12 tokens (   11.17 ms per token,    89.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.35 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     134.65 ms /    10 tokens (   13.47 ms per token,    74.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.01 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     178.93 ms /    75 tokens (    2.39 ms per token,   419.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     182.68 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     344.37 ms /   193 tokens (    1.78 ms per token,   560.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     353.67 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     303.99 ms /   162 tokens (    1.88 ms per token,   532.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     311.75 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     301.35 ms /   256 tokens (    1.18 ms per token,   849.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     315.77 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     180.00 ms /   116 tokens (    1.55 ms per token,   644.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     185.67 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     246.23 ms /   151 tokens (    1.63 ms per token,   613.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.41 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     184.15 ms /   123 tokens (    1.50 ms per token,   667.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     190.08 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     315.93 ms /   182 tokens (    1.74 ms per token,   576.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     325.55 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     259.64 ms /   175 tokens (    1.48 ms per token,   674.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     269.11 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     185.25 ms /   124 tokens (    1.49 ms per token,   669.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.40 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     295.27 ms /   140 tokens (    2.11 ms per token,   474.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     301.91 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     336.64 ms /   209 tokens (    1.61 ms per token,   620.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     347.72 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     199.80 ms /    95 tokens (    2.10 ms per token,   475.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.80 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     287.79 ms /   133 tokens (    2.16 ms per token,   462.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     295.20 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     151.80 ms /    39 tokens (    3.89 ms per token,   256.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     154.15 ms /    40 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     302.43 ms /   154 tokens (    1.96 ms per token,   509.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     310.24 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     144.68 ms /    48 tokens (    3.01 ms per token,   331.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     147.85 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     145.97 ms /    57 tokens (    2.56 ms per token,   390.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.29 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     182.33 ms /   110 tokens (    1.66 ms per token,   603.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.86 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     152.55 ms /    43 tokens (    3.55 ms per token,   281.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.30 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     106.54 ms /     6 tokens (   17.76 ms per token,    56.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.72 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     214.40 ms /    90 tokens (    2.38 ms per token,   419.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.69 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     299.09 ms /   165 tokens (    1.81 ms per token,   551.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     308.03 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     187.04 ms /    66 tokens (    2.83 ms per token,   352.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     190.55 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.29 ms /    41 tokens (    3.81 ms per token,   262.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     158.73 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     220.94 ms /   121 tokens (    1.83 ms per token,   547.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     227.27 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     295.37 ms /   165 tokens (    1.79 ms per token,   558.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     303.03 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     198.43 ms /    90 tokens (    2.20 ms per token,   453.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     203.42 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     326.00 ms /   197 tokens (    1.65 ms per token,   604.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     336.59 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     302.37 ms /   190 tokens (    1.59 ms per token,   628.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     311.89 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     172.28 ms /    83 tokens (    2.08 ms per token,   481.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     176.56 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     278.81 ms /   226 tokens (    1.23 ms per token,   810.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     292.07 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     205.58 ms /   113 tokens (    1.82 ms per token,   549.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.23 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     311.47 ms /   174 tokens (    1.79 ms per token,   558.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     320.20 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     188.75 ms /    66 tokens (    2.86 ms per token,   349.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     192.90 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     210.16 ms /    95 tokens (    2.21 ms per token,   452.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.25 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     339.11 ms /   211 tokens (    1.61 ms per token,   622.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     349.38 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     344.88 ms /   233 tokens (    1.48 ms per token,   675.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     357.16 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     144.97 ms /    54 tokens (    2.68 ms per token,   372.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     148.11 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     168.92 ms /    87 tokens (    1.94 ms per token,   515.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     173.39 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     255.94 ms /   182 tokens (    1.41 ms per token,   711.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     265.69 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     192.53 ms /    84 tokens (    2.29 ms per token,   436.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     197.71 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     148.47 ms /    23 tokens (    6.46 ms per token,   154.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.72 ms /    24 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     159.90 ms /    48 tokens (    3.33 ms per token,   300.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.99 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     475.11 ms /   302 tokens (    1.57 ms per token,   635.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     492.84 ms /   303 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     348.32 ms /   248 tokens (    1.40 ms per token,   711.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     363.25 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     193.96 ms /    88 tokens (    2.20 ms per token,   453.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.86 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     349.45 ms /   226 tokens (    1.55 ms per token,   646.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     362.17 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     142.95 ms /    25 tokens (    5.72 ms per token,   174.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.03 ms /    26 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     306.02 ms /   160 tokens (    1.91 ms per token,   522.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     314.64 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     208.52 ms /   115 tokens (    1.81 ms per token,   551.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     214.32 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     358.14 ms /   252 tokens (    1.42 ms per token,   703.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     372.09 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     201.43 ms /   100 tokens (    2.01 ms per token,   496.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.66 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     282.64 ms /   134 tokens (    2.11 ms per token,   474.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     289.93 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     307.10 ms /   181 tokens (    1.70 ms per token,   589.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     319.41 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     141.87 ms /    14 tokens (   10.13 ms per token,    98.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.29 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     313.74 ms /   162 tokens (    1.94 ms per token,   516.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     322.51 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.04 ms /    53 tokens (    2.94 ms per token,   339.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.38 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     357.96 ms /   227 tokens (    1.58 ms per token,   634.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     370.25 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     343.47 ms /   231 tokens (    1.49 ms per token,   672.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     355.13 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     200.21 ms /   100 tokens (    2.00 ms per token,   499.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.97 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.98 ms /    41 tokens (    3.83 ms per token,   261.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.03 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     155.79 ms /    35 tokens (    4.45 ms per token,   224.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     158.12 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     209.34 ms /    84 tokens (    2.49 ms per token,   401.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     214.01 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     160.33 ms /    52 tokens (    3.08 ms per token,   324.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.26 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     388.01 ms /   187 tokens (    2.07 ms per token,   481.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     398.12 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     378.00 ms /   150 tokens (    2.52 ms per token,   396.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     385.66 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     187.06 ms /    37 tokens (    5.06 ms per token,   197.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     189.50 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     216.33 ms /    52 tokens (    4.16 ms per token,   240.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.42 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     416.63 ms /   157 tokens (    2.65 ms per token,   376.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     425.01 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     163.70 ms /    46 tokens (    3.56 ms per token,   281.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     167.29 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     293.92 ms /   141 tokens (    2.08 ms per token,   479.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     300.64 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     307.25 ms /   182 tokens (    1.69 ms per token,   592.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     315.98 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     192.10 ms /    75 tokens (    2.56 ms per token,   390.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     196.53 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     161.03 ms /    58 tokens (    2.78 ms per token,   360.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     165.16 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     163.81 ms /    53 tokens (    3.09 ms per token,   323.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     167.10 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     218.30 ms /   106 tokens (    2.06 ms per token,   485.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.77 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     201.48 ms /    84 tokens (    2.40 ms per token,   416.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.03 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     215.75 ms /   118 tokens (    1.83 ms per token,   546.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     222.21 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =      72.41 ms /     4 tokens (   18.10 ms per token,    55.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.42 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     161.78 ms /    37 tokens (    4.37 ms per token,   228.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.11 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     360.99 ms /   158 tokens (    2.28 ms per token,   437.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     369.17 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     441.38 ms /   213 tokens (    2.07 ms per token,   482.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     452.72 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     217.36 ms /   105 tokens (    2.07 ms per token,   483.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     222.53 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     301.45 ms /   180 tokens (    1.67 ms per token,   597.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     310.08 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     151.79 ms /    45 tokens (    3.37 ms per token,   296.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.69 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     215.73 ms /    74 tokens (    2.92 ms per token,   343.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.41 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     273.64 ms /   110 tokens (    2.49 ms per token,   401.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     279.47 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     452.04 ms /   231 tokens (    1.96 ms per token,   511.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     463.91 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     250.01 ms /   103 tokens (    2.43 ms per token,   411.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     256.06 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     308.23 ms /   188 tokens (    1.64 ms per token,   609.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     319.42 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     181.82 ms /    71 tokens (    2.56 ms per token,   390.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     186.08 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     161.65 ms /    54 tokens (    2.99 ms per token,   334.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.99 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     275.41 ms /   128 tokens (    2.15 ms per token,   464.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     281.37 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     233.59 ms /    74 tokens (    3.16 ms per token,   316.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     238.11 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     166.81 ms /    18 tokens (    9.27 ms per token,   107.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     168.51 ms /    19 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     254.93 ms /    84 tokens (    3.03 ms per token,   329.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     259.43 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     436.32 ms /   244 tokens (    1.79 ms per token,   559.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     449.39 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     163.18 ms /    39 tokens (    4.18 ms per token,   239.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     165.90 ms /    40 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     432.76 ms /   226 tokens (    1.91 ms per token,   522.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     444.51 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     402.38 ms /   267 tokens (    1.51 ms per token,   663.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     417.40 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     278.75 ms /   145 tokens (    1.92 ms per token,   520.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     285.47 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     347.91 ms /   171 tokens (    2.03 ms per token,   491.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     356.62 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     225.83 ms /    90 tokens (    2.51 ms per token,   398.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     230.66 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     397.39 ms /   233 tokens (    1.71 ms per token,   586.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     409.72 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     109.73 ms /     8 tokens (   13.72 ms per token,    72.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     111.19 ms /     9 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     204.22 ms /   113 tokens (    1.81 ms per token,   553.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     209.63 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     317.80 ms /   201 tokens (    1.58 ms per token,   632.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     328.29 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.73 ms /    57 tokens (    2.71 ms per token,   368.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     158.17 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     245.30 ms /    66 tokens (    3.72 ms per token,   269.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.24 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.48 ms /    48 tokens (    4.07 ms per token,   245.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.68 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     244.88 ms /    76 tokens (    3.22 ms per token,   310.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.42 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     174.37 ms /    24 tokens (    7.27 ms per token,   137.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     176.19 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     374.32 ms /   132 tokens (    2.84 ms per token,   352.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     381.05 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     165.48 ms /     9 tokens (   18.39 ms per token,    54.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     167.06 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     211.69 ms /    53 tokens (    3.99 ms per token,   250.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.21 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     383.58 ms /   153 tokens (    2.51 ms per token,   398.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     391.60 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     254.47 ms /   103 tokens (    2.47 ms per token,   404.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     259.80 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     235.66 ms /    69 tokens (    3.42 ms per token,   292.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     239.91 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     153.44 ms /     7 tokens (   21.92 ms per token,    45.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     154.67 ms /     8 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     202.84 ms /    43 tokens (    4.72 ms per token,   211.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.75 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     284.22 ms /   127 tokens (    2.24 ms per token,   446.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     291.13 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     362.04 ms /   149 tokens (    2.43 ms per token,   411.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     369.35 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     236.89 ms /    79 tokens (    3.00 ms per token,   333.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     240.86 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     438.27 ms /   232 tokens (    1.89 ms per token,   529.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     452.85 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     225.31 ms /    77 tokens (    2.93 ms per token,   341.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     229.94 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     245.47 ms /    81 tokens (    3.03 ms per token,   329.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.91 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     242.19 ms /    73 tokens (    3.32 ms per token,   301.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     246.47 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     448.82 ms /   231 tokens (    1.94 ms per token,   514.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     460.95 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     422.14 ms /   230 tokens (    1.84 ms per token,   544.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     435.02 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     289.79 ms /   166 tokens (    1.75 ms per token,   572.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     299.30 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     201.27 ms /    91 tokens (    2.21 ms per token,   452.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.42 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     419.09 ms /   194 tokens (    2.16 ms per token,   462.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     428.77 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     347.63 ms /   252 tokens (    1.38 ms per token,   724.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     360.88 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     150.46 ms /    57 tokens (    2.64 ms per token,   378.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.74 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     149.47 ms /    25 tokens (    5.98 ms per token,   167.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.30 ms /    26 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     426.28 ms /   217 tokens (    1.96 ms per token,   509.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     438.88 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     246.91 ms /   122 tokens (    2.02 ms per token,   494.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.42 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     370.34 ms /   161 tokens (    2.30 ms per token,   434.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     378.21 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     338.63 ms /   135 tokens (    2.51 ms per token,   398.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     345.57 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     164.72 ms /    23 tokens (    7.16 ms per token,   139.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.62 ms /    24 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     241.42 ms /    65 tokens (    3.71 ms per token,   269.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     245.48 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     172.72 ms /    21 tokens (    8.22 ms per token,   121.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     174.52 ms /    22 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     202.93 ms /    63 tokens (    3.22 ms per token,   310.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.94 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     175.04 ms /    21 tokens (    8.34 ms per token,   119.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     177.80 ms /    22 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.22 ms /    47 tokens (    4.15 ms per token,   240.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.16 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     390.56 ms /   180 tokens (    2.17 ms per token,   460.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     400.50 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     230.66 ms /    81 tokens (    2.85 ms per token,   351.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     235.31 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     245.73 ms /    85 tokens (    2.89 ms per token,   345.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.68 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     261.76 ms /   119 tokens (    2.20 ms per token,   454.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     268.18 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     364.99 ms /   160 tokens (    2.28 ms per token,   438.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     372.68 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     366.31 ms /   161 tokens (    2.28 ms per token,   439.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     374.23 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     163.75 ms /    13 tokens (   12.60 ms per token,    79.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     165.11 ms /    14 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     448.84 ms /   237 tokens (    1.89 ms per token,   528.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     460.65 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     174.23 ms /    53 tokens (    3.29 ms per token,   304.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     177.55 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     102.38 ms /     4 tokens (   25.59 ms per token,    39.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     103.38 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     253.92 ms /    70 tokens (    3.63 ms per token,   275.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     257.84 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     558.08 ms /   289 tokens (    1.93 ms per token,   517.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     575.26 ms /   290 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.41 ms /   118 tokens (    1.66 ms per token,   600.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     202.79 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     283.87 ms /    36 tokens (    7.89 ms per token,   126.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     286.69 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     381.05 ms /    92 tokens (    4.14 ms per token,   241.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     385.72 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     273.27 ms /    76 tokens (    3.60 ms per token,   278.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     277.08 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     403.65 ms /   129 tokens (    3.13 ms per token,   319.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     410.64 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     292.40 ms /   120 tokens (    2.44 ms per token,   410.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     298.49 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     282.74 ms /    93 tokens (    3.04 ms per token,   328.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     287.75 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     217.06 ms /    52 tokens (    4.17 ms per token,   239.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     220.13 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     304.03 ms /    94 tokens (    3.23 ms per token,   309.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     308.68 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     196.75 ms /     9 tokens (   21.86 ms per token,    45.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.05 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     302.71 ms /    97 tokens (    3.12 ms per token,   320.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     308.26 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     267.55 ms /    74 tokens (    3.62 ms per token,   276.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     271.88 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     311.03 ms /   127 tokens (    2.45 ms per token,   408.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     317.22 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     504.78 ms /   247 tokens (    2.04 ms per token,   489.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     517.31 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     379.75 ms /   129 tokens (    2.94 ms per token,   339.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     387.00 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     286.87 ms /   102 tokens (    2.81 ms per token,   355.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     291.95 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     435.22 ms /   187 tokens (    2.33 ms per token,   429.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     445.27 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     313.23 ms /   176 tokens (    1.78 ms per token,   561.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     321.86 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     148.67 ms /    33 tokens (    4.51 ms per token,   221.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.88 ms /    34 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     152.69 ms /    13 tokens (   11.75 ms per token,    85.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     154.06 ms /    14 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     377.89 ms /   248 tokens (    1.52 ms per token,   656.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     391.47 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     214.62 ms /   121 tokens (    1.77 ms per token,   563.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     221.24 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     344.69 ms /   215 tokens (    1.60 ms per token,   623.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     356.12 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     359.54 ms /   252 tokens (    1.43 ms per token,   700.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     371.97 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     200.94 ms /    96 tokens (    2.09 ms per token,   477.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.35 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     352.14 ms /   223 tokens (    1.58 ms per token,   633.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     363.40 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     359.64 ms /   249 tokens (    1.44 ms per token,   692.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     373.05 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     335.71 ms /   211 tokens (    1.59 ms per token,   628.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     345.86 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     218.33 ms /   127 tokens (    1.72 ms per token,   581.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     224.41 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     364.80 ms /   250 tokens (    1.46 ms per token,   685.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     378.70 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     356.99 ms /   251 tokens (    1.42 ms per token,   703.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     371.32 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     202.44 ms /   103 tokens (    1.97 ms per token,   508.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     208.56 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     313.67 ms /   170 tokens (    1.85 ms per token,   541.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     321.72 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     361.37 ms /   240 tokens (    1.51 ms per token,   664.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     373.97 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     210.30 ms /   109 tokens (    1.93 ms per token,   518.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.93 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     216.55 ms /   109 tokens (    1.99 ms per token,   503.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     222.08 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     150.68 ms /    16 tokens (    9.42 ms per token,   106.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.47 ms /    17 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     169.63 ms /    30 tokens (    5.65 ms per token,   176.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     171.69 ms /    31 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     619.16 ms /   263 tokens (    2.35 ms per token,   424.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     633.98 ms /   264 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     620.34 ms /   329 tokens (    1.89 ms per token,   530.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     638.89 ms /   330 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     352.10 ms /   249 tokens (    1.41 ms per token,   707.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     369.08 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     145.38 ms /    55 tokens (    2.64 ms per token,   378.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     148.85 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     271.21 ms /   202 tokens (    1.34 ms per token,   744.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     281.59 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     218.76 ms /    90 tokens (    2.43 ms per token,   411.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.19 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     499.33 ms /   240 tokens (    2.08 ms per token,   480.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     513.48 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     241.43 ms /    68 tokens (    3.55 ms per token,   281.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     245.43 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     313.81 ms /   125 tokens (    2.51 ms per token,   398.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     319.78 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     210.63 ms /    60 tokens (    3.51 ms per token,   284.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     214.01 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     305.70 ms /   116 tokens (    2.64 ms per token,   379.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     311.69 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     304.65 ms /   141 tokens (    2.16 ms per token,   462.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     311.08 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     313.59 ms /   183 tokens (    1.71 ms per token,   583.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     322.66 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     350.99 ms /   232 tokens (    1.51 ms per token,   661.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     363.05 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     310.08 ms /   187 tokens (    1.66 ms per token,   603.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     319.77 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     152.47 ms /    43 tokens (    3.55 ms per token,   282.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.19 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     153.28 ms /    23 tokens (    6.66 ms per token,   150.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     154.96 ms /    24 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     306.73 ms /   146 tokens (    2.10 ms per token,   475.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     313.73 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     318.68 ms /   187 tokens (    1.70 ms per token,   586.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     327.89 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     349.79 ms /   237 tokens (    1.48 ms per token,   677.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     362.35 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.36 ms /    59 tokens (    2.65 ms per token,   377.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.61 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     459.44 ms /   265 tokens (    1.73 ms per token,   576.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     474.44 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     148.26 ms /    36 tokens (    4.12 ms per token,   242.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.22 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     354.70 ms /   217 tokens (    1.63 ms per token,   611.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     366.29 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     298.24 ms /   244 tokens (    1.22 ms per token,   818.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     310.58 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     211.43 ms /   102 tokens (    2.07 ms per token,   482.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.98 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     337.64 ms /   170 tokens (    1.99 ms per token,   503.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     346.61 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     313.20 ms /   139 tokens (    2.25 ms per token,   443.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     319.88 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     386.06 ms /   237 tokens (    1.63 ms per token,   613.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     398.42 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     382.00 ms /   245 tokens (    1.56 ms per token,   641.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     394.58 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     366.75 ms /   225 tokens (    1.63 ms per token,   613.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     377.86 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     163.63 ms /    62 tokens (    2.64 ms per token,   378.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     168.19 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     230.37 ms /    91 tokens (    2.53 ms per token,   395.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     234.76 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     159.15 ms /    16 tokens (    9.95 ms per token,   100.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.63 ms /    17 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     184.51 ms /    56 tokens (    3.29 ms per token,   303.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     187.57 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     344.52 ms /   165 tokens (    2.09 ms per token,   478.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     352.39 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     228.58 ms /   108 tokens (    2.12 ms per token,   472.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     234.00 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     242.03 ms /   124 tokens (    1.95 ms per token,   512.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     247.93 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     150.65 ms /    10 tokens (   15.07 ms per token,    66.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.88 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     355.58 ms /   181 tokens (    1.96 ms per token,   509.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     364.95 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     220.28 ms /   101 tokens (    2.18 ms per token,   458.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     225.15 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     230.36 ms /   105 tokens (    2.19 ms per token,   455.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     236.95 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.61 ms /    12 tokens (   13.05 ms per token,    76.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.93 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     190.29 ms /    63 tokens (    3.02 ms per token,   331.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     194.11 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     172.91 ms /    41 tokens (    4.22 ms per token,   237.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     175.38 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     175.87 ms /    44 tokens (    4.00 ms per token,   250.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     178.68 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     223.62 ms /    76 tokens (    2.94 ms per token,   339.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     227.60 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     221.87 ms /    81 tokens (    2.74 ms per token,   365.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     226.31 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     172.36 ms /    53 tokens (    3.25 ms per token,   307.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     175.79 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     168.74 ms /    31 tokens (    5.44 ms per token,   183.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     171.03 ms /    32 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     164.87 ms /    24 tokens (    6.87 ms per token,   145.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.85 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     228.89 ms /    83 tokens (    2.76 ms per token,   362.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     233.45 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     377.59 ms /   216 tokens (    1.75 ms per token,   572.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     388.80 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     263.17 ms /   162 tokens (    1.62 ms per token,   615.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     271.32 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     316.07 ms /   134 tokens (    2.36 ms per token,   423.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     322.64 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     313.88 ms /   134 tokens (    2.34 ms per token,   426.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     320.93 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     312.10 ms /   136 tokens (    2.29 ms per token,   435.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     318.95 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     360.69 ms /   198 tokens (    1.82 ms per token,   548.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     371.17 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     153.88 ms /    35 tokens (    4.40 ms per token,   227.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.49 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     320.25 ms /   136 tokens (    2.35 ms per token,   424.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     327.24 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     388.16 ms /   237 tokens (    1.64 ms per token,   610.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     401.25 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     155.16 ms /    42 tokens (    3.69 ms per token,   270.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.84 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     220.33 ms /    69 tokens (    3.19 ms per token,   313.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.99 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     233.85 ms /   101 tokens (    2.32 ms per token,   431.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     239.65 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     213.02 ms /    68 tokens (    3.13 ms per token,   319.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.73 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     227.41 ms /    94 tokens (    2.42 ms per token,   413.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     232.35 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     227.29 ms /    92 tokens (    2.47 ms per token,   404.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     231.89 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     335.32 ms /   165 tokens (    2.03 ms per token,   492.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     343.95 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     158.75 ms /    35 tokens (    4.54 ms per token,   220.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.18 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     245.32 ms /   112 tokens (    2.19 ms per token,   456.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     251.00 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     218.30 ms /    80 tokens (    2.73 ms per token,   366.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     222.42 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     381.02 ms /   216 tokens (    1.76 ms per token,   566.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     392.24 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     359.17 ms /   206 tokens (    1.74 ms per token,   573.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     369.77 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     204.27 ms /    73 tokens (    2.80 ms per token,   357.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     208.24 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =      99.11 ms /     5 tokens (   19.82 ms per token,    50.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.28 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     260.53 ms /   126 tokens (    2.07 ms per token,   483.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     266.76 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     169.42 ms /    54 tokens (    3.14 ms per token,   318.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     172.41 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     233.65 ms /    96 tokens (    2.43 ms per token,   410.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     238.95 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     373.87 ms /   213 tokens (    1.76 ms per token,   569.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     384.77 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     213.26 ms /    96 tokens (    2.22 ms per token,   450.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.54 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     394.34 ms /   242 tokens (    1.63 ms per token,   613.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     408.99 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     150.09 ms /    28 tokens (    5.36 ms per token,   186.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.46 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     362.98 ms /   189 tokens (    1.92 ms per token,   520.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     373.59 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     378.83 ms /   237 tokens (    1.60 ms per token,   625.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     391.46 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     150.81 ms /    29 tokens (    5.20 ms per token,   192.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.04 ms /    30 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     345.41 ms /   171 tokens (    2.02 ms per token,   495.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     356.56 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     224.53 ms /   111 tokens (    2.02 ms per token,   494.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     230.89 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     322.16 ms /   147 tokens (    2.19 ms per token,   456.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     329.28 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     365.80 ms /   203 tokens (    1.80 ms per token,   554.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     376.21 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     202.32 ms /    70 tokens (    2.89 ms per token,   345.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.14 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     384.97 ms /   227 tokens (    1.70 ms per token,   589.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     397.29 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     149.49 ms /    27 tokens (    5.54 ms per token,   180.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.62 ms /    28 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     407.51 ms /   249 tokens (    1.64 ms per token,   611.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     421.43 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     148.49 ms /    24 tokens (    6.19 ms per token,   161.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.23 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     396.61 ms /   232 tokens (    1.71 ms per token,   584.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     410.05 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     374.29 ms /   233 tokens (    1.61 ms per token,   622.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     386.59 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     197.25 ms /    65 tokens (    3.03 ms per token,   329.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     200.79 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     371.53 ms /   203 tokens (    1.83 ms per token,   546.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     382.25 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     210.83 ms /    86 tokens (    2.45 ms per token,   407.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.18 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     167.00 ms /    49 tokens (    3.41 ms per token,   293.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.05 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     369.90 ms /   194 tokens (    1.91 ms per token,   524.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     380.67 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     323.18 ms /   164 tokens (    1.97 ms per token,   507.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     331.44 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     373.28 ms /   219 tokens (    1.70 ms per token,   586.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     384.65 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     350.86 ms /   199 tokens (    1.76 ms per token,   567.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     361.10 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     358.91 ms /   203 tokens (    1.77 ms per token,   565.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     368.38 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     366.31 ms /   208 tokens (    1.76 ms per token,   567.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     376.89 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     205.11 ms /    79 tokens (    2.60 ms per token,   385.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     209.43 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     159.43 ms /    24 tokens (    6.64 ms per token,   150.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.17 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     350.52 ms /    12 tokens (   29.21 ms per token,    34.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     351.77 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     481.10 ms /   175 tokens (    2.75 ms per token,   363.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     490.22 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     251.50 ms /    83 tokens (    3.03 ms per token,   330.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     255.82 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     272.22 ms /   101 tokens (    2.70 ms per token,   371.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     277.51 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     438.69 ms /   197 tokens (    2.23 ms per token,   449.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     449.25 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     248.95 ms /    93 tokens (    2.68 ms per token,   373.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     254.16 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     584.40 ms /   265 tokens (    2.21 ms per token,   453.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     598.39 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     180.65 ms /    49 tokens (    3.69 ms per token,   271.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     183.84 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     205.69 ms /    37 tokens (    5.56 ms per token,   179.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     207.95 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     206.12 ms /    34 tokens (    6.06 ms per token,   164.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     208.29 ms /    35 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     428.95 ms /   190 tokens (    2.26 ms per token,   442.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     439.49 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     253.29 ms /    98 tokens (    2.58 ms per token,   386.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     258.84 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     479.07 ms /   252 tokens (    1.90 ms per token,   526.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     492.38 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     442.19 ms /   239 tokens (    1.85 ms per token,   540.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     455.12 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     165.76 ms /    12 tokens (   13.81 ms per token,    72.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     167.41 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     449.12 ms /   196 tokens (    2.29 ms per token,   436.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     459.14 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     329.78 ms /   204 tokens (    1.62 ms per token,   618.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     339.45 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.41 ms /    96 tokens (    2.04 ms per token,   491.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     200.39 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     265.94 ms /   162 tokens (    1.64 ms per token,   609.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     273.99 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     157.87 ms /    36 tokens (    4.39 ms per token,   228.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.21 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     214.00 ms /    15 tokens (   14.27 ms per token,    70.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.48 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     482.24 ms /   179 tokens (    2.69 ms per token,   371.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     491.30 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     219.96 ms /    62 tokens (    3.55 ms per token,   281.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.77 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     230.93 ms /    38 tokens (    6.08 ms per token,   164.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     233.51 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     475.73 ms /   171 tokens (    2.78 ms per token,   359.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     484.38 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     479.97 ms /   246 tokens (    1.95 ms per token,   512.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     494.76 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     341.70 ms /   205 tokens (    1.67 ms per token,   599.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     351.76 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     143.08 ms /    41 tokens (    3.49 ms per token,   286.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.91 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     244.90 ms /   182 tokens (    1.35 ms per token,   743.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.89 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     339.81 ms /   248 tokens (    1.37 ms per token,   729.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     353.28 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     360.78 ms /   195 tokens (    1.85 ms per token,   540.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     371.53 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     485.76 ms /   260 tokens (    1.87 ms per token,   535.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     498.72 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     363.29 ms /   208 tokens (    1.75 ms per token,   572.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     373.46 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     399.86 ms /   254 tokens (    1.57 ms per token,   635.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     412.73 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     320.52 ms /   153 tokens (    2.09 ms per token,   477.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     328.57 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     502.51 ms /   288 tokens (    1.74 ms per token,   573.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     516.81 ms /   289 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     162.02 ms /    53 tokens (    3.06 ms per token,   327.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.86 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     346.10 ms /   154 tokens (    2.25 ms per token,   444.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     354.39 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     388.57 ms /   227 tokens (    1.71 ms per token,   584.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     401.23 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     160.25 ms /    42 tokens (    3.82 ms per token,   262.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.10 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     167.39 ms /    23 tokens (    7.28 ms per token,   137.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     169.51 ms /    24 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     252.76 ms /   116 tokens (    2.18 ms per token,   458.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     259.24 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.36 ms /    21 tokens (    7.45 ms per token,   134.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.99 ms /    22 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     241.72 ms /    97 tokens (    2.49 ms per token,   401.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     247.01 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     381.07 ms /   211 tokens (    1.81 ms per token,   553.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     393.08 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     335.00 ms /   181 tokens (    1.85 ms per token,   540.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     343.70 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     328.73 ms /   147 tokens (    2.24 ms per token,   447.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     335.70 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     217.24 ms /    75 tokens (    2.90 ms per token,   345.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     221.18 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     401.68 ms /   233 tokens (    1.72 ms per token,   580.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     413.96 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     366.26 ms /   209 tokens (    1.75 ms per token,   570.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     377.21 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     219.99 ms /    97 tokens (    2.27 ms per token,   440.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     224.85 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     168.66 ms /    38 tokens (    4.44 ms per token,   225.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     171.12 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     166.63 ms /    19 tokens (    8.77 ms per token,   114.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     168.27 ms /    20 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     234.80 ms /    82 tokens (    2.86 ms per token,   349.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     239.15 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     230.15 ms /    92 tokens (    2.50 ms per token,   399.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     235.12 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     393.44 ms /   225 tokens (    1.75 ms per token,   571.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     404.79 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     373.55 ms /   207 tokens (    1.80 ms per token,   554.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     384.14 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     359.54 ms /   194 tokens (    1.85 ms per token,   539.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     368.32 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     280.29 ms /   171 tokens (    1.64 ms per token,   610.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     288.90 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     368.25 ms /   195 tokens (    1.89 ms per token,   529.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     377.54 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     325.35 ms /   156 tokens (    2.09 ms per token,   479.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     332.59 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     351.30 ms /   187 tokens (    1.88 ms per token,   532.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     360.71 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     368.46 ms /   199 tokens (    1.85 ms per token,   540.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     377.81 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     370.87 ms /   208 tokens (    1.78 ms per token,   560.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     381.90 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     376.19 ms /   210 tokens (    1.79 ms per token,   558.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     386.81 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     380.36 ms /   221 tokens (    1.72 ms per token,   581.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     391.60 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     367.34 ms /   213 tokens (    1.72 ms per token,   579.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     378.72 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     384.46 ms /   230 tokens (    1.67 ms per token,   598.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     396.12 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     382.20 ms /   228 tokens (    1.68 ms per token,   596.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     394.24 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     375.71 ms /   215 tokens (    1.75 ms per token,   572.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     387.12 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     365.21 ms /   217 tokens (    1.68 ms per token,   594.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     377.10 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     382.20 ms /   235 tokens (    1.63 ms per token,   614.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     395.60 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     391.78 ms /   239 tokens (    1.64 ms per token,   610.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     404.51 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     339.31 ms /   186 tokens (    1.82 ms per token,   548.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     348.18 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     364.84 ms /   200 tokens (    1.82 ms per token,   548.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     374.57 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     371.90 ms /   220 tokens (    1.69 ms per token,   591.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     383.06 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     376.24 ms /   224 tokens (    1.68 ms per token,   595.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     387.86 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     378.89 ms /   226 tokens (    1.68 ms per token,   596.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     391.10 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     389.65 ms /   268 tokens (    1.45 ms per token,   687.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     403.09 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     336.45 ms /   247 tokens (    1.36 ms per token,   734.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     349.47 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     384.90 ms /   218 tokens (    1.77 ms per token,   566.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     396.58 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     383.69 ms /   214 tokens (    1.79 ms per token,   557.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     394.82 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     171.72 ms /    57 tokens (    3.01 ms per token,   331.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     174.85 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     130.57 ms /     6 tokens (   21.76 ms per token,    45.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.74 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     185.29 ms /    16 tokens (   11.58 ms per token,    86.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     187.38 ms /    17 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     401.67 ms /   194 tokens (    2.07 ms per token,   482.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     412.47 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     342.21 ms /   166 tokens (    2.06 ms per token,   485.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     350.22 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     331.80 ms /   134 tokens (    2.48 ms per token,   403.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     338.08 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     354.91 ms /   168 tokens (    2.11 ms per token,   473.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     362.10 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     179.87 ms /    63 tokens (    2.86 ms per token,   350.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     183.28 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     256.06 ms /   108 tokens (    2.37 ms per token,   421.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     261.56 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     761.50 ms /   512 tokens (    1.49 ms per token,   672.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     793.23 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     588.58 ms /   512 tokens (    1.15 ms per token,   869.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     616.45 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     579.94 ms /   512 tokens (    1.13 ms per token,   882.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     609.55 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     584.52 ms /   512 tokens (    1.14 ms per token,   875.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     619.48 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     562.23 ms /   512 tokens (    1.10 ms per token,   910.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     592.76 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     575.34 ms /   512 tokens (    1.12 ms per token,   889.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     614.28 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     594.06 ms /   512 tokens (    1.16 ms per token,   861.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     634.32 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     534.05 ms /   512 tokens (    1.04 ms per token,   958.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     564.76 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     712.48 ms /   512 tokens (    1.39 ms per token,   718.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     746.50 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     850.37 ms /   512 tokens (    1.66 ms per token,   602.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     880.98 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     640.45 ms /   512 tokens (    1.25 ms per token,   799.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     671.76 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     646.02 ms /   512 tokens (    1.26 ms per token,   792.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     687.28 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     643.29 ms /   512 tokens (    1.26 ms per token,   795.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     677.32 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     697.75 ms /   512 tokens (    1.36 ms per token,   733.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     731.34 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     623.17 ms /   512 tokens (    1.22 ms per token,   821.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     655.41 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     665.97 ms /   512 tokens (    1.30 ms per token,   768.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     695.32 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     819.87 ms /   512 tokens (    1.60 ms per token,   624.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     864.65 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     633.79 ms /   512 tokens (    1.24 ms per token,   807.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     691.47 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     637.89 ms /   512 tokens (    1.25 ms per token,   802.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     679.26 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     535.62 ms /   512 tokens (    1.05 ms per token,   955.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     574.70 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     564.33 ms /   512 tokens (    1.10 ms per token,   907.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     600.70 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     770.20 ms /   512 tokens (    1.50 ms per token,   664.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     810.21 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     589.54 ms /   512 tokens (    1.15 ms per token,   868.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     626.05 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     590.06 ms /   512 tokens (    1.15 ms per token,   867.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     624.87 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     570.25 ms /   512 tokens (    1.11 ms per token,   897.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     608.74 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     520.22 ms /   512 tokens (    1.02 ms per token,   984.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     557.19 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     613.56 ms /   512 tokens (    1.20 ms per token,   834.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     650.12 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     527.48 ms /   512 tokens (    1.03 ms per token,   970.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     571.78 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     597.76 ms /   512 tokens (    1.17 ms per token,   856.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     641.64 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     529.65 ms /   512 tokens (    1.03 ms per token,   966.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     569.74 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     524.44 ms /   512 tokens (    1.02 ms per token,   976.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     567.57 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     562.19 ms /   512 tokens (    1.10 ms per token,   910.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     607.00 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     494.31 ms /   512 tokens (    0.97 ms per token,  1035.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     527.79 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     521.30 ms /   512 tokens (    1.02 ms per token,   982.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     554.72 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     530.24 ms /   512 tokens (    1.04 ms per token,   965.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     565.67 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     605.47 ms /   512 tokens (    1.18 ms per token,   845.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     646.20 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     509.38 ms /   512 tokens (    0.99 ms per token,  1005.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     542.27 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     515.61 ms /   512 tokens (    1.01 ms per token,   993.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     547.29 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     542.97 ms /   512 tokens (    1.06 ms per token,   942.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     574.95 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     527.83 ms /   512 tokens (    1.03 ms per token,   970.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     561.22 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     534.79 ms /   512 tokens (    1.04 ms per token,   957.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     567.51 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     529.27 ms /   512 tokens (    1.03 ms per token,   967.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     562.41 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     532.49 ms /   512 tokens (    1.04 ms per token,   961.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     562.98 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     506.86 ms /   512 tokens (    0.99 ms per token,  1010.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     537.63 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     526.65 ms /   512 tokens (    1.03 ms per token,   972.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     558.35 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     491.08 ms /   512 tokens (    0.96 ms per token,  1042.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     531.72 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     513.28 ms /   512 tokens (    1.00 ms per token,   997.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     554.76 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     520.43 ms /   512 tokens (    1.02 ms per token,   983.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     560.95 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     463.18 ms /   512 tokens (    0.90 ms per token,  1105.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     500.35 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     515.99 ms /   512 tokens (    1.01 ms per token,   992.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     554.52 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     514.43 ms /   512 tokens (    1.00 ms per token,   995.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     555.88 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     512.17 ms /   512 tokens (    1.00 ms per token,   999.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     548.74 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     512.64 ms /   512 tokens (    1.00 ms per token,   998.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     548.06 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     474.54 ms /   512 tokens (    0.93 ms per token,  1078.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     511.35 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     657.96 ms /   512 tokens (    1.29 ms per token,   778.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     689.45 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     551.60 ms /   512 tokens (    1.08 ms per token,   928.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     584.33 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     524.76 ms /   512 tokens (    1.02 ms per token,   975.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     556.96 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     453.93 ms /   512 tokens (    0.89 ms per token,  1127.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     486.18 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     522.26 ms /   512 tokens (    1.02 ms per token,   980.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     555.01 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     241.09 ms /   139 tokens (    1.73 ms per token,   576.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     248.91 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     134.28 ms /     9 tokens (   14.92 ms per token,    67.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.73 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     240.86 ms /   131 tokens (    1.84 ms per token,   543.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     248.23 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     290.22 ms /   235 tokens (    1.23 ms per token,   809.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     305.71 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     472.25 ms /   392 tokens (    1.20 ms per token,   830.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     504.80 ms /   393 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     250.54 ms /   174 tokens (    1.44 ms per token,   694.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     262.02 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     270.06 ms /   200 tokens (    1.35 ms per token,   740.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     288.60 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     234.86 ms /   133 tokens (    1.77 ms per token,   566.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     243.96 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     179.22 ms /   115 tokens (    1.56 ms per token,   641.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     187.16 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     236.14 ms /   132 tokens (    1.79 ms per token,   558.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     244.61 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     256.08 ms /   182 tokens (    1.41 ms per token,   710.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     267.73 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     173.43 ms /   101 tokens (    1.72 ms per token,   582.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     179.01 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     272.65 ms /   194 tokens (    1.41 ms per token,   711.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     283.74 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     269.55 ms /   196 tokens (    1.38 ms per token,   727.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     280.01 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     269.73 ms /   199 tokens (    1.36 ms per token,   737.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     280.62 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     282.83 ms /   223 tokens (    1.27 ms per token,   788.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     295.63 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     291.72 ms /   246 tokens (    1.19 ms per token,   843.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     306.66 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     242.31 ms /   197 tokens (    1.23 ms per token,   812.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.71 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     142.14 ms /    36 tokens (    3.95 ms per token,   253.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     144.76 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     170.68 ms /    70 tokens (    2.44 ms per token,   410.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     174.80 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     195.53 ms /   128 tokens (    1.53 ms per token,   654.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     202.45 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     303.72 ms /   240 tokens (    1.27 ms per token,   790.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     318.89 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     170.23 ms /   114 tokens (    1.49 ms per token,   669.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     176.40 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.87 ms /    35 tokens (    4.00 ms per token,   250.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.23 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     178.70 ms /   116 tokens (    1.54 ms per token,   649.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     186.85 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     345.24 ms /   244 tokens (    1.41 ms per token,   706.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     359.66 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     339.01 ms /   209 tokens (    1.62 ms per token,   616.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     350.79 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     154.14 ms /    53 tokens (    2.91 ms per token,   343.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.56 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     204.88 ms /    65 tokens (    3.15 ms per token,   317.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     209.44 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     335.76 ms /   204 tokens (    1.65 ms per token,   607.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     347.72 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     302.49 ms /   173 tokens (    1.75 ms per token,   571.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     312.10 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     172.88 ms /    93 tokens (    1.86 ms per token,   537.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     178.20 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     250.57 ms /   215 tokens (    1.17 ms per token,   858.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     263.45 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     302.42 ms /   248 tokens (    1.22 ms per token,   820.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     316.84 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     283.81 ms /   210 tokens (    1.35 ms per token,   739.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     295.57 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     254.65 ms /   165 tokens (    1.54 ms per token,   647.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     263.70 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     295.89 ms /   234 tokens (    1.26 ms per token,   790.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     309.32 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     248.41 ms /   151 tokens (    1.65 ms per token,   607.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     256.42 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     255.89 ms /   156 tokens (    1.64 ms per token,   609.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     266.14 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     242.38 ms /   139 tokens (    1.74 ms per token,   573.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.74 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     265.47 ms /   188 tokens (    1.41 ms per token,   708.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     278.10 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     277.32 ms /   199 tokens (    1.39 ms per token,   717.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     291.35 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     266.56 ms /   192 tokens (    1.39 ms per token,   720.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     279.48 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     167.37 ms /   102 tokens (    1.64 ms per token,   609.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     175.02 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     240.61 ms /   196 tokens (    1.23 ms per token,   814.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.47 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     264.15 ms /   176 tokens (    1.50 ms per token,   666.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     274.43 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     257.45 ms /   162 tokens (    1.59 ms per token,   629.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     266.86 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     305.22 ms /   243 tokens (    1.26 ms per token,   796.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     321.24 ms /   244 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     256.83 ms /   225 tokens (    1.14 ms per token,   876.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     270.43 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     247.83 ms /   155 tokens (    1.60 ms per token,   625.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     257.71 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     179.03 ms /   110 tokens (    1.63 ms per token,   614.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     186.93 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     372.25 ms /   283 tokens (    1.32 ms per token,   760.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     392.02 ms /   284 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     542.85 ms /   512 tokens (    1.06 ms per token,   943.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     577.92 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     455.27 ms /   466 tokens (    0.98 ms per token,  1023.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     486.71 ms /   467 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     337.25 ms /   323 tokens (    1.04 ms per token,   957.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     358.51 ms /   324 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     161.04 ms /    87 tokens (    1.85 ms per token,   540.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.53 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     298.10 ms /   247 tokens (    1.21 ms per token,   828.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     313.75 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     136.59 ms /    18 tokens (    7.59 ms per token,   131.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.57 ms /    19 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     143.95 ms /    50 tokens (    2.88 ms per token,   347.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     147.48 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     134.88 ms /    10 tokens (   13.49 ms per token,    74.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.22 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     153.92 ms /    37 tokens (    4.16 ms per token,   240.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.48 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     344.89 ms /   193 tokens (    1.79 ms per token,   559.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     356.48 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     168.66 ms /    66 tokens (    2.56 ms per token,   391.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     173.38 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     289.45 ms /   233 tokens (    1.24 ms per token,   804.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     302.89 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     268.43 ms /   199 tokens (    1.35 ms per token,   741.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     278.91 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     286.32 ms /   234 tokens (    1.22 ms per token,   817.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     300.16 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     283.43 ms /   230 tokens (    1.23 ms per token,   811.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     296.61 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     174.55 ms /   105 tokens (    1.66 ms per token,   601.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     182.80 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     290.43 ms /   247 tokens (    1.18 ms per token,   850.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     304.70 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     160.64 ms /    87 tokens (    1.85 ms per token,   541.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     165.81 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     246.41 ms /   214 tokens (    1.15 ms per token,   868.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     258.24 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     274.10 ms /   203 tokens (    1.35 ms per token,   740.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     289.82 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     184.15 ms /    77 tokens (    2.39 ms per token,   418.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     190.01 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     289.21 ms /   170 tokens (    1.70 ms per token,   587.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     299.52 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     279.95 ms /   162 tokens (    1.73 ms per token,   578.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     292.92 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     284.06 ms /   170 tokens (    1.67 ms per token,   598.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     296.55 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     274.39 ms /   151 tokens (    1.82 ms per token,   550.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     283.14 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     307.18 ms /   195 tokens (    1.58 ms per token,   634.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     318.66 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     174.81 ms /   119 tokens (    1.47 ms per token,   680.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.57 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     240.28 ms /   166 tokens (    1.45 ms per token,   690.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.06 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     193.23 ms /    89 tokens (    2.17 ms per token,   460.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.30 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     325.62 ms /   201 tokens (    1.62 ms per token,   617.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     337.69 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     151.83 ms /    53 tokens (    2.86 ms per token,   349.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.36 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     344.34 ms /   228 tokens (    1.51 ms per token,   662.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     357.90 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     277.43 ms /   229 tokens (    1.21 ms per token,   825.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     291.49 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     139.62 ms /    29 tokens (    4.81 ms per token,   207.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.89 ms /    30 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     250.62 ms /   134 tokens (    1.87 ms per token,   534.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     258.32 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     150.56 ms /    42 tokens (    3.58 ms per token,   278.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.38 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     346.38 ms /   224 tokens (    1.55 ms per token,   646.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     360.20 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     150.37 ms /    44 tokens (    3.42 ms per token,   292.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.72 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     204.14 ms /    83 tokens (    2.46 ms per token,   406.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     209.61 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     192.06 ms /    72 tokens (    2.67 ms per token,   374.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     200.62 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     157.88 ms /    64 tokens (    2.47 ms per token,   405.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.21 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     206.03 ms /    95 tokens (    2.17 ms per token,   461.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     212.11 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     100.32 ms /     6 tokens (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.45 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     207.56 ms /    69 tokens (    3.01 ms per token,   332.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     212.45 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.44 ms /    49 tokens (    3.19 ms per token,   313.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.32 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     156.17 ms /    42 tokens (    3.72 ms per token,   268.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.30 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     288.41 ms /   135 tokens (    2.14 ms per token,   468.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     298.08 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     299.18 ms /   173 tokens (    1.73 ms per token,   578.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     308.61 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     165.04 ms\n",
      "llama_perf_context_print: prompt eval time =     135.13 ms /    10 tokens (   13.51 ms per token,    74.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.60 ms /    11 tokens\n",
      "llama_model_load_from_file_impl: using device CUDA0 (NVIDIA RTX A3000 12GB Laptop GPU) - 3874 MiB free\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Embedding generation for Llama-3.1-8b-instruct-q6_k] 306.61s\n",
      "‚úî Saved embeddings to /workspaces/VectorVet/embeddings/Llama-3.1-8b-instruct-q6_k_20news_chunks.npy\n",
      "‚Üí Embedding with phi-2.Q6_K ‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 325 tensors from /workspaces/VectorVet/models/phi-2.Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi2\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi2\n",
      "llama_model_loader: - kv   2:                        phi2.context_length u32              = 2048\n",
      "llama_model_loader: - kv   3:                      phi2.embedding_length u32              = 2560\n",
      "llama_model_loader: - kv   4:                   phi2.feed_forward_length u32              = 10240\n",
      "llama_model_loader: - kv   5:                           phi2.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  phi2.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:               phi2.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   8:          phi2.attention.layer_norm_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   9:                  phi2.rope.dimension_count u32              = 32\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  11:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,51200]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,51200]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,50000]   = [\"ƒ† t\", \"ƒ† a\", \"h e\", \"i n\", \"r e\",...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 50256\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 50256\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 50256\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  195 tensors\n",
      "llama_model_loader: - type q6_K:  130 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q6_K\n",
      "print_info: file size   = 2.13 GiB (6.57 BPW) \n",
      "load: missing pre-tokenizer type, using: 'default'\n",
      "load:                                             \n",
      "load: ************************************        \n",
      "load: GENERATION QUALITY WILL BE DEGRADED!        \n",
      "load: CONSIDER REGENERATING THE MODEL             \n",
      "load: ************************************        \n",
      "load:                                             \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: special tokens cache size = 944\n",
      "load: token to piece cache size = 0.3151 MB\n",
      "print_info: arch             = phi2\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 2048\n",
      "print_info: n_embd           = 2560\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 32\n",
      "print_info: n_rot            = 32\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 80\n",
      "print_info: n_embd_head_v    = 80\n",
      "print_info: n_gqa            = 1\n",
      "print_info: n_embd_k_gqa     = 2560\n",
      "print_info: n_embd_v_gqa     = 2560\n",
      "print_info: f_norm_eps       = 1.0e-05\n",
      "print_info: f_norm_rms_eps   = 0.0e+00\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 10240\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 2048\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 2.78 B\n",
      "print_info: general.name     = Phi2\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 51200\n",
      "print_info: n_merges         = 50000\n",
      "print_info: BOS token        = 50256 '<|endoftext|>'\n",
      "print_info: EOS token        = 50256 '<|endoftext|>'\n",
      "print_info: EOT token        = 50256 '<|endoftext|>'\n",
      "print_info: UNK token        = 50256 '<|endoftext|>'\n",
      "print_info: LF token         = 198 'ƒä'\n",
      "print_info: EOG token        = 50256 '<|endoftext|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CUDA0\n",
      "load_tensors: layer   1 assigned to device CUDA0\n",
      "load_tensors: layer   2 assigned to device CUDA0\n",
      "load_tensors: layer   3 assigned to device CUDA0\n",
      "load_tensors: layer   4 assigned to device CUDA0\n",
      "load_tensors: layer   5 assigned to device CUDA0\n",
      "load_tensors: layer   6 assigned to device CUDA0\n",
      "load_tensors: layer   7 assigned to device CUDA0\n",
      "load_tensors: layer   8 assigned to device CUDA0\n",
      "load_tensors: layer   9 assigned to device CUDA0\n",
      "load_tensors: layer  10 assigned to device CUDA0\n",
      "load_tensors: layer  11 assigned to device CUDA0\n",
      "load_tensors: layer  12 assigned to device CUDA0\n",
      "load_tensors: layer  13 assigned to device CUDA0\n",
      "load_tensors: layer  14 assigned to device CUDA0\n",
      "load_tensors: layer  15 assigned to device CUDA0\n",
      "load_tensors: layer  16 assigned to device CUDA0\n",
      "load_tensors: layer  17 assigned to device CUDA0\n",
      "load_tensors: layer  18 assigned to device CUDA0\n",
      "load_tensors: layer  19 assigned to device CUDA0\n",
      "load_tensors: layer  20 assigned to device CUDA0\n",
      "load_tensors: layer  21 assigned to device CUDA0\n",
      "load_tensors: layer  22 assigned to device CUDA0\n",
      "load_tensors: layer  23 assigned to device CUDA0\n",
      "load_tensors: layer  24 assigned to device CUDA0\n",
      "load_tensors: layer  25 assigned to device CUDA0\n",
      "load_tensors: layer  26 assigned to device CUDA0\n",
      "load_tensors: layer  27 assigned to device CUDA0\n",
      "load_tensors: layer  28 assigned to device CUDA0\n",
      "load_tensors: layer  29 assigned to device CUDA0\n",
      "load_tensors: layer  30 assigned to device CUDA0\n",
      "load_tensors: layer  31 assigned to device CUDA0\n",
      "load_tensors: layer  32 assigned to device CUDA0\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 0 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors: offloading 32 repeating layers to GPU\n",
      "load_tensors: offloading output layer to GPU\n",
      "load_tensors: offloaded 33/33 layers to GPU\n",
      "load_tensors:        CUDA0 model buffer size =  2074.94 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =   102.54 MiB\n",
      ".............................................................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 512\n",
      "llama_init_from_model: n_ctx_per_seq = 512\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 10000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (512) < n_ctx_train (2048) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   160.00 MiB\n",
      "llama_init_from_model: KV self size  =  160.00 MiB, K (f16):   80.00 MiB, V (f16):   80.00 MiB\n",
      "llama_init_from_model:  CUDA_Host  output buffer size =     0.01 MiB\n",
      "llama_init_from_model:      CUDA0 compute buffer size =   105.00 MiB\n",
      "llama_init_from_model:  CUDA_Host compute buffer size =     6.01 MiB\n",
      "llama_init_from_model: graph nodes  = 1225\n",
      "llama_init_from_model: graph splits = 2\n",
      "CUDA : ARCHS = 520 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '50256', 'tokenizer.ggml.eos_token_id': '50256', 'tokenizer.ggml.bos_token_id': '50256', 'general.architecture': 'phi2', 'general.name': 'Phi2', 'phi2.context_length': '2048', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.add_bos_token': 'false', 'phi2.embedding_length': '2560', 'phi2.attention.head_count': '32', 'phi2.attention.head_count_kv': '32', 'phi2.feed_forward_length': '10240', 'phi2.attention.layer_norm_epsilon': '0.000010', 'phi2.block_count': '32', 'phi2.rope.dimension_count': '32', 'general.file_type': '18'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3f202035084c22aec10d1d83b0fb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding (phi-2.Q6_K):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      73.28 ms /   126 tokens (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.29 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.92 ms /   120 tokens (    0.55 ms per token,  1820.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.54 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      92.15 ms /   196 tokens (    0.47 ms per token,  2126.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.00 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     120.47 ms /   259 tokens (    0.47 ms per token,  2149.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.03 ms /   260 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      52.49 ms /    27 tokens (    1.94 ms per token,   514.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.51 ms /    28 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.37 ms /   125 tokens (    0.53 ms per token,  1883.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.10 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.03 ms /   109 tokens (    0.59 ms per token,  1702.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.70 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      69.60 ms /   118 tokens (    0.59 ms per token,  1695.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.10 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      54.95 ms /    15 tokens (    3.66 ms per token,   273.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.69 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     138.26 ms /   355 tokens (    0.39 ms per token,  2567.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.18 ms /   356 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.80 ms /   176 tokens (    0.49 ms per token,  2051.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.29 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      57.01 ms /    55 tokens (    1.04 ms per token,   964.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.74 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      99.22 ms /   250 tokens (    0.40 ms per token,  2519.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.50 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.80 ms /   214 tokens (    0.44 ms per token,  2257.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.48 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.20 ms /   199 tokens (    0.47 ms per token,  2112.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.31 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      93.85 ms /   215 tokens (    0.44 ms per token,  2290.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.13 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      97.55 ms /   233 tokens (    0.42 ms per token,  2388.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.80 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =     478.03 ms /     1 runs   (  478.03 ms per token,     2.09 tokens per second)\n",
      "llama_perf_context_print:       total time =     479.27 ms /     2 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      82.96 ms /   162 tokens (    0.51 ms per token,  1952.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.05 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     117.66 ms /   264 tokens (    0.45 ms per token,  2243.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.08 ms /   265 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      83.66 ms /   169 tokens (    0.50 ms per token,  2020.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.68 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.82 ms /   119 tokens (    0.55 ms per token,  1807.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.32 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     118.83 ms /   272 tokens (    0.44 ms per token,  2288.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.49 ms /   273 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.07 ms /    34 tokens (    1.62 ms per token,   617.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.26 ms /    35 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     140.74 ms /   358 tokens (    0.39 ms per token,  2543.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.31 ms /   359 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      60.50 ms /    74 tokens (    0.82 ms per token,  1223.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.24 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      78.08 ms /   135 tokens (    0.58 ms per token,  1728.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.34 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      91.31 ms /   201 tokens (    0.45 ms per token,  2201.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.16 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      89.41 ms /   194 tokens (    0.46 ms per token,  2169.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.52 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     120.59 ms /   279 tokens (    0.43 ms per token,  2313.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.51 ms /   280 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     123.79 ms /   296 tokens (    0.42 ms per token,  2391.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     134.57 ms /   297 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     121.03 ms /   283 tokens (    0.43 ms per token,  2338.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.29 ms /   284 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     116.32 ms /   259 tokens (    0.45 ms per token,  2226.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.34 ms /   260 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     120.53 ms /   278 tokens (    0.43 ms per token,  2306.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.06 ms /   279 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     131.89 ms /   328 tokens (    0.40 ms per token,  2486.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.61 ms /   329 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     120.54 ms /   274 tokens (    0.44 ms per token,  2273.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.67 ms /   275 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     116.54 ms /   257 tokens (    0.45 ms per token,  2205.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.38 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     118.76 ms /   259 tokens (    0.46 ms per token,  2180.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.46 ms /   260 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.50 ms /   177 tokens (    0.48 ms per token,  2070.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.65 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      78.36 ms /   140 tokens (    0.56 ms per token,  1786.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.80 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     120.81 ms /   282 tokens (    0.43 ms per token,  2334.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.96 ms /   283 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.26 ms /    54 tokens (    1.08 ms per token,   926.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      61.55 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      78.26 ms /   140 tokens (    0.56 ms per token,  1788.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.39 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      99.56 ms /   243 tokens (    0.41 ms per token,  2440.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.75 ms /   244 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      56.09 ms /    48 tokens (    1.17 ms per token,   855.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      59.11 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.97 ms /    53 tokens (    1.06 ms per token,   946.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.66 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      62.13 ms /    90 tokens (    0.69 ms per token,  1448.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.07 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.09 ms /   198 tokens (    0.46 ms per token,  2197.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.45 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      96.20 ms /   231 tokens (    0.42 ms per token,  2401.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.18 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      51.49 ms /    21 tokens (    2.45 ms per token,   407.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.18 ms /    22 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     100.38 ms /   251 tokens (    0.40 ms per token,  2500.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.05 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.29 ms /   224 tokens (    0.42 ms per token,  2375.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.89 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.82 ms /   118 tokens (    0.56 ms per token,  1792.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.40 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.49 ms /   195 tokens (    0.46 ms per token,  2154.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.42 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      97.13 ms /   232 tokens (    0.42 ms per token,  2388.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.34 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.46 ms /    81 tokens (    0.76 ms per token,  1317.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.84 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      54.48 ms /    38 tokens (    1.43 ms per token,   697.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.70 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.30 ms /   244 tokens (    0.40 ms per token,  2482.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.08 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.74 ms /    66 tokens (    0.89 ms per token,  1123.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.14 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      54.38 ms /    37 tokens (    1.47 ms per token,   680.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.70 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.92 ms /   105 tokens (    0.61 ms per token,  1642.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.98 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      93.25 ms /   212 tokens (    0.44 ms per token,  2273.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.46 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.78 ms /   193 tokens (    0.47 ms per token,  2126.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.00 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      84.44 ms /   172 tokens (    0.49 ms per token,  2036.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.53 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      87.80 ms /   191 tokens (    0.46 ms per token,  2175.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      95.60 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.63 ms /   118 tokens (    0.56 ms per token,  1797.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.71 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      99.02 ms /   245 tokens (    0.40 ms per token,  2474.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.07 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.30 ms /   178 tokens (    0.48 ms per token,  2086.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.77 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.28 ms /   241 tokens (    0.41 ms per token,  2452.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     106.81 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.10 ms /   221 tokens (    0.43 ms per token,  2348.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.34 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      97.44 ms /   235 tokens (    0.41 ms per token,  2411.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.51 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.79 ms /    61 tokens (    0.91 ms per token,  1093.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.90 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      18.91 ms /     2 tokens (    9.46 ms per token,   105.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      20.01 ms /     3 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      57.72 ms /    61 tokens (    0.95 ms per token,  1056.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.62 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      51.08 ms /    14 tokens (    3.65 ms per token,   274.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.55 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     119.61 ms /   272 tokens (    0.44 ms per token,  2274.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.79 ms /   273 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.22 ms /   177 tokens (    0.48 ms per token,  2077.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.74 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      95.35 ms /   225 tokens (    0.42 ms per token,  2359.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     103.61 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      60.34 ms /    77 tokens (    0.78 ms per token,  1276.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      63.88 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.47 ms /    64 tokens (    0.87 ms per token,  1153.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.38 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      52.49 ms /    28 tokens (    1.87 ms per token,   533.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.45 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      80.21 ms /   148 tokens (    0.54 ms per token,  1845.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.69 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.89 ms /    65 tokens (    0.91 ms per token,  1103.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.47 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.43 ms /   101 tokens (    0.66 ms per token,  1520.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.71 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     100.62 ms /   252 tokens (    0.40 ms per token,  2504.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.82 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.76 ms /   222 tokens (    0.43 ms per token,  2342.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.99 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      56.37 ms /    61 tokens (    0.92 ms per token,  1082.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      59.84 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      76.67 ms /   131 tokens (    0.59 ms per token,  1708.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.96 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      97.80 ms /   235 tokens (    0.42 ms per token,  2402.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     106.67 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.75 ms /   244 tokens (    0.40 ms per token,  2470.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.76 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      91.66 ms /   204 tokens (    0.45 ms per token,  2225.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.12 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.27 ms /   195 tokens (    0.46 ms per token,  2160.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.29 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     119.10 ms /   260 tokens (    0.46 ms per token,  2183.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.67 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      62.76 ms /    99 tokens (    0.63 ms per token,  1577.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.71 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      79.05 ms /   144 tokens (    0.55 ms per token,  1821.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.57 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      53.17 ms /    31 tokens (    1.72 ms per token,   583.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.30 ms /    32 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      62.88 ms /    96 tokens (    0.66 ms per token,  1526.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.81 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      86.50 ms /   183 tokens (    0.47 ms per token,  2115.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.36 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      95.77 ms /   227 tokens (    0.42 ms per token,  2370.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     103.67 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      62.22 ms /    86 tokens (    0.72 ms per token,  1382.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.02 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.21 ms /   222 tokens (    0.42 ms per token,  2356.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.20 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     122.54 ms /   286 tokens (    0.43 ms per token,  2333.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     132.72 ms /   287 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     160.39 ms /   406 tokens (    0.40 ms per token,  2531.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     175.94 ms /   407 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.64 ms /   223 tokens (    0.42 ms per token,  2356.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.66 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      97.64 ms /   236 tokens (    0.41 ms per token,  2417.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.95 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      81.78 ms /   160 tokens (    0.51 ms per token,  1956.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.80 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     118.48 ms /   260 tokens (    0.46 ms per token,  2194.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.83 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     123.02 ms /   288 tokens (    0.43 ms per token,  2341.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     134.02 ms /   289 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      92.29 ms /   207 tokens (    0.45 ms per token,  2242.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.86 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      81.75 ms /   158 tokens (    0.52 ms per token,  1932.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.84 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.48 ms /   125 tokens (    0.53 ms per token,  1880.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.54 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      52.63 ms /    31 tokens (    1.70 ms per token,   589.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.79 ms /    32 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     100.65 ms /   254 tokens (    0.40 ms per token,  2523.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.27 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.57 ms /    67 tokens (    0.87 ms per token,  1143.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      61.69 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.48 ms /    53 tokens (    1.05 ms per token,   955.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.22 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.73 ms /    88 tokens (    0.70 ms per token,  1425.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.60 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      83.05 ms /   162 tokens (    0.51 ms per token,  1950.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.45 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      96.53 ms /   231 tokens (    0.42 ms per token,  2392.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.94 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      62.37 ms /    91 tokens (    0.69 ms per token,  1459.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.32 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      87.16 ms /   185 tokens (    0.47 ms per token,  2122.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.83 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      87.58 ms /   189 tokens (    0.46 ms per token,  2158.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.45 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.87 ms /   198 tokens (    0.46 ms per token,  2178.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.26 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     123.79 ms /   291 tokens (    0.43 ms per token,  2350.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.64 ms /   292 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      86.58 ms /   182 tokens (    0.48 ms per token,  2102.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.10 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      87.31 ms /   186 tokens (    0.47 ms per token,  2130.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.21 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.36 ms /    45 tokens (    1.23 ms per token,   812.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.71 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     119.15 ms /   270 tokens (    0.44 ms per token,  2266.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.38 ms /   271 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      93.93 ms /   218 tokens (    0.43 ms per token,  2320.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.53 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      84.94 ms /   154 tokens (    0.55 ms per token,  1813.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.72 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.12 ms /   237 tokens (    0.41 ms per token,  2415.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     106.32 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      89.55 ms /   193 tokens (    0.46 ms per token,  2155.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.60 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      97.16 ms /   226 tokens (    0.43 ms per token,  2326.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.51 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.97 ms /   117 tokens (    0.57 ms per token,  1747.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.07 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.88 ms /   115 tokens (    0.57 ms per token,  1745.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.61 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      84.72 ms /   172 tokens (    0.49 ms per token,  2030.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.21 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.92 ms /   221 tokens (    0.43 ms per token,  2328.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.98 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      87.32 ms /   188 tokens (    0.46 ms per token,  2152.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.00 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     121.27 ms /   277 tokens (    0.44 ms per token,  2284.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     131.80 ms /   278 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.68 ms /    52 tokens (    1.07 ms per token,   933.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.48 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.01 ms /   240 tokens (    0.41 ms per token,  2448.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     106.33 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      92.53 ms /   200 tokens (    0.46 ms per token,  2161.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.08 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      96.97 ms /   232 tokens (    0.42 ms per token,  2392.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.10 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      95.79 ms /   225 tokens (    0.43 ms per token,  2348.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.80 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      83.87 ms /   165 tokens (    0.51 ms per token,  1967.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.62 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.86 ms /   222 tokens (    0.43 ms per token,  2340.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.93 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      93.26 ms /   206 tokens (    0.45 ms per token,  2208.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.96 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.33 ms /   123 tokens (    0.54 ms per token,  1854.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.20 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      78.16 ms /   138 tokens (    0.57 ms per token,  1765.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.92 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     100.56 ms /   252 tokens (    0.40 ms per token,  2505.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     110.36 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      57.43 ms /    52 tokens (    1.10 ms per token,   905.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.84 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     118.61 ms /   263 tokens (    0.45 ms per token,  2217.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.53 ms /   264 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.29 ms /    95 tokens (    0.67 ms per token,  1501.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.34 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      99.84 ms /   243 tokens (    0.41 ms per token,  2433.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.36 ms /   244 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.32 ms /   196 tokens (    0.46 ms per token,  2170.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.73 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      67.33 ms /   128 tokens (    0.53 ms per token,  1901.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.42 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.00 ms /    67 tokens (    0.94 ms per token,  1063.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.16 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     118.48 ms /   265 tokens (    0.45 ms per token,  2236.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.17 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      53.10 ms /    31 tokens (    1.71 ms per token,   583.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.27 ms /    32 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.15 ms /   213 tokens (    0.44 ms per token,  2262.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.81 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      92.88 ms /   212 tokens (    0.44 ms per token,  2282.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.58 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      82.02 ms /   159 tokens (    0.52 ms per token,  1938.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.07 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.64 ms /   112 tokens (    0.59 ms per token,  1706.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.43 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      86.03 ms /   178 tokens (    0.48 ms per token,  2069.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.86 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.53 ms /   217 tokens (    0.44 ms per token,  2295.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     103.05 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.72 ms /   170 tokens (    0.50 ms per token,  1983.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.20 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.95 ms /   200 tokens (    0.45 ms per token,  2199.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.16 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.70 ms /   231 tokens (    0.43 ms per token,  2340.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.35 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      86.00 ms /   179 tokens (    0.48 ms per token,  2081.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.14 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      80.40 ms /   149 tokens (    0.54 ms per token,  1853.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.33 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      82.09 ms /   156 tokens (    0.53 ms per token,  1900.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.08 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      60.52 ms /    79 tokens (    0.77 ms per token,  1305.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.38 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      99.07 ms /   241 tokens (    0.41 ms per token,  2432.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.31 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      77.25 ms /   132 tokens (    0.59 ms per token,  1708.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.49 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     100.65 ms /   244 tokens (    0.41 ms per token,  2424.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.21 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.54 ms /   175 tokens (    0.49 ms per token,  2045.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.19 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.22 ms /    55 tokens (    1.00 ms per token,   996.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.02 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.23 ms /    41 tokens (    1.35 ms per token,   742.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.51 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      82.95 ms /   162 tokens (    0.51 ms per token,  1953.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.83 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      93.63 ms /   214 tokens (    0.44 ms per token,  2285.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.12 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      60.94 ms /    78 tokens (    0.78 ms per token,  1280.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.66 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.51 ms /   120 tokens (    0.55 ms per token,  1804.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.12 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      68.15 ms /   124 tokens (    0.55 ms per token,  1819.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.22 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     123.86 ms /   280 tokens (    0.44 ms per token,  2260.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     134.71 ms /   281 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.36 ms /   173 tokens (    0.49 ms per token,  2026.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.07 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.16 ms /    74 tokens (    0.83 ms per token,  1209.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.65 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.72 ms /    51 tokens (    1.09 ms per token,   915.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.27 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      59.04 ms /    65 tokens (    0.91 ms per token,  1100.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.22 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      96.03 ms /   218 tokens (    0.44 ms per token,  2270.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.09 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      96.01 ms /   220 tokens (    0.44 ms per token,  2291.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.23 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      79.27 ms /   139 tokens (    0.57 ms per token,  1753.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.96 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      67.32 ms /   125 tokens (    0.54 ms per token,  1856.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.11 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.09 ms /   106 tokens (    0.60 ms per token,  1653.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.47 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.42 ms /   115 tokens (    0.57 ms per token,  1758.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.88 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     126.09 ms /   286 tokens (    0.44 ms per token,  2268.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     137.04 ms /   287 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.87 ms /   111 tokens (    0.60 ms per token,  1659.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.63 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.36 ms /   170 tokens (    0.50 ms per token,  1991.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.95 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.76 ms /   202 tokens (    0.47 ms per token,  2131.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.10 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     100.52 ms /   234 tokens (    0.43 ms per token,  2328.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.37 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      51.91 ms /    13 tokens (    3.99 ms per token,   250.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.71 ms /    14 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      89.31 ms /   184 tokens (    0.49 ms per token,  2060.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.20 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      97.01 ms /   214 tokens (    0.45 ms per token,  2205.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.56 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      88.19 ms /   179 tokens (    0.49 ms per token,  2029.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.74 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      78.43 ms /   130 tokens (    0.60 ms per token,  1657.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.65 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      62.66 ms /    80 tokens (    0.78 ms per token,  1276.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.19 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      88.44 ms /   188 tokens (    0.47 ms per token,  2125.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      95.11 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      54.69 ms /    37 tokens (    1.48 ms per token,   676.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.18 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      67.44 ms /   125 tokens (    0.54 ms per token,  1853.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.60 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      60.68 ms /    73 tokens (    0.83 ms per token,  1203.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.62 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      92.40 ms /   184 tokens (    0.50 ms per token,  1991.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.13 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      79.77 ms /   130 tokens (    0.61 ms per token,  1629.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.54 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      57.04 ms /    59 tokens (    0.97 ms per token,  1034.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.01 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.39 ms /    75 tokens (    0.82 ms per token,  1221.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.96 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      80.89 ms /   135 tokens (    0.60 ms per token,  1669.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.92 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      53.21 ms /    28 tokens (    1.90 ms per token,   526.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.81 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.07 ms /   109 tokens (    0.61 ms per token,  1649.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.62 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      68.71 ms /   117 tokens (    0.59 ms per token,  1702.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.30 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      56.00 ms /    47 tokens (    1.19 ms per token,   839.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.54 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     124.40 ms /   269 tokens (    0.46 ms per token,  2162.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     134.33 ms /   270 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     102.79 ms /   256 tokens (    0.40 ms per token,  2490.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     112.16 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      87.95 ms /   186 tokens (    0.47 ms per token,  2114.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      95.02 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     101.61 ms /   247 tokens (    0.41 ms per token,  2430.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     110.43 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.27 ms /    79 tokens (    0.78 ms per token,  1289.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.82 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     122.62 ms /   269 tokens (    0.46 ms per token,  2193.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     132.51 ms /   270 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.05 ms /   138 tokens (    0.62 ms per token,  1622.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.14 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      60.60 ms /    52 tokens (    1.17 ms per token,   858.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      63.88 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      54.09 ms /    17 tokens (    3.18 ms per token,   314.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.74 ms /    18 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      91.43 ms /   164 tokens (    0.56 ms per token,  1793.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.48 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     108.39 ms /   228 tokens (    0.48 ms per token,  2103.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     116.39 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      91.02 ms /   160 tokens (    0.57 ms per token,  1757.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.27 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      57.52 ms /    33 tokens (    1.74 ms per token,   573.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      59.83 ms /    34 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     104.51 ms /   207 tokens (    0.50 ms per token,  1980.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     112.17 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      68.78 ms /   103 tokens (    0.67 ms per token,  1497.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.99 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.58 ms /   161 tokens (    0.56 ms per token,  1777.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.80 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.66 ms /    79 tokens (    0.82 ms per token,  1221.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.38 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      74.68 ms /   122 tokens (    0.61 ms per token,  1633.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.72 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.60 ms /    62 tokens (    0.95 ms per token,  1058.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      61.71 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     109.09 ms /   241 tokens (    0.45 ms per token,  2209.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.89 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     107.46 ms /   240 tokens (    0.45 ms per token,  2233.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     116.26 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     133.47 ms /   274 tokens (    0.49 ms per token,  2052.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     144.67 ms /   275 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      56.28 ms /    49 tokens (    1.15 ms per token,   870.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      59.10 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      99.71 ms /   214 tokens (    0.47 ms per token,  2146.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.36 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      56.68 ms /    61 tokens (    0.93 ms per token,  1076.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      59.65 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      27.93 ms /     8 tokens (    3.49 ms per token,   286.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      29.21 ms /     9 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     103.36 ms /   218 tokens (    0.47 ms per token,  2109.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     110.86 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.69 ms /    42 tokens (    1.40 ms per token,   715.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.98 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.66 ms /   154 tokens (    0.56 ms per token,  1797.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.72 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.01 ms /   155 tokens (    0.55 ms per token,  1823.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.94 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     138.49 ms /   306 tokens (    0.45 ms per token,  2209.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.49 ms /   307 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.61 ms /   103 tokens (    0.64 ms per token,  1569.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.17 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     168.42 ms /   406 tokens (    0.41 ms per token,  2410.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     190.35 ms /   407 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     175.69 ms /   429 tokens (    0.41 ms per token,  2441.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     194.06 ms /   430 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     172.59 ms /   422 tokens (    0.41 ms per token,  2445.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     190.74 ms /   423 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     173.54 ms /   430 tokens (    0.40 ms per token,  2477.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.52 ms /   431 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     165.36 ms /   427 tokens (    0.39 ms per token,  2582.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     183.82 ms /   428 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     163.88 ms /   420 tokens (    0.39 ms per token,  2562.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     182.35 ms /   421 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     185.98 ms /   432 tokens (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.35 ms /   433 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     182.14 ms /   432 tokens (    0.42 ms per token,  2371.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     202.47 ms /   433 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     107.96 ms /   253 tokens (    0.43 ms per token,  2343.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.95 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      81.29 ms /   129 tokens (    0.63 ms per token,  1586.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.35 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      51.55 ms /     9 tokens (    5.73 ms per token,   174.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.90 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     105.76 ms /   227 tokens (    0.47 ms per token,  2146.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     113.84 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     203.66 ms /   512 tokens (    0.40 ms per token,  2513.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     222.76 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     194.84 ms /   512 tokens (    0.38 ms per token,  2627.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     213.14 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     196.01 ms /   512 tokens (    0.38 ms per token,  2612.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     214.49 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.03 ms /   512 tokens (    0.39 ms per token,  2585.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.87 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     197.60 ms /   512 tokens (    0.39 ms per token,  2591.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.82 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     196.95 ms /   512 tokens (    0.38 ms per token,  2599.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.47 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.25 ms /   512 tokens (    0.39 ms per token,  2582.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.35 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.06 ms /   512 tokens (    0.39 ms per token,  2559.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     220.01 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     199.20 ms /   512 tokens (    0.39 ms per token,  2570.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.20 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     199.06 ms /   512 tokens (    0.39 ms per token,  2572.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.15 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.72 ms /   512 tokens (    0.39 ms per token,  2576.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.35 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     197.50 ms /   512 tokens (    0.39 ms per token,  2592.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.79 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.44 ms /   512 tokens (    0.39 ms per token,  2554.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.51 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.41 ms /   512 tokens (    0.39 ms per token,  2580.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.25 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     197.96 ms /   512 tokens (    0.39 ms per token,  2586.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.99 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     197.38 ms /   512 tokens (    0.39 ms per token,  2593.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.57 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.92 ms /   512 tokens (    0.39 ms per token,  2573.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.68 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.19 ms /   512 tokens (    0.39 ms per token,  2583.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.95 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     203.46 ms /   512 tokens (    0.40 ms per token,  2516.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.55 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.86 ms /   512 tokens (    0.39 ms per token,  2574.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.59 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     184.94 ms /   512 tokens (    0.36 ms per token,  2768.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     204.02 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     203.68 ms /   512 tokens (    0.40 ms per token,  2513.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.17 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.47 ms /   512 tokens (    0.39 ms per token,  2579.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.04 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     193.35 ms /   512 tokens (    0.38 ms per token,  2648.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     212.40 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     187.69 ms /   512 tokens (    0.37 ms per token,  2727.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.05 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     199.80 ms /   512 tokens (    0.39 ms per token,  2562.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.59 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.25 ms /   512 tokens (    0.39 ms per token,  2556.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.28 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.57 ms /   512 tokens (    0.39 ms per token,  2578.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.15 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     203.86 ms /   512 tokens (    0.40 ms per token,  2511.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     225.82 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     199.32 ms /   512 tokens (    0.39 ms per token,  2568.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.07 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.56 ms /   512 tokens (    0.39 ms per token,  2578.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.17 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     203.71 ms /   512 tokens (    0.40 ms per token,  2513.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     221.65 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.90 ms /   512 tokens (    0.39 ms per token,  2574.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     221.26 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     199.66 ms /   512 tokens (    0.39 ms per token,  2564.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.69 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     203.74 ms /   512 tokens (    0.40 ms per token,  2512.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     224.14 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.93 ms /   512 tokens (    0.39 ms per token,  2573.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     220.58 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.58 ms /   512 tokens (    0.39 ms per token,  2552.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.99 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     203.77 ms /   512 tokens (    0.40 ms per token,  2512.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.55 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     199.95 ms /   512 tokens (    0.39 ms per token,  2560.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.06 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     198.96 ms /   512 tokens (    0.39 ms per token,  2573.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.44 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     203.75 ms /   512 tokens (    0.40 ms per token,  2512.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     222.83 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.44 ms /   512 tokens (    0.39 ms per token,  2554.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     221.80 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.43 ms /   512 tokens (    0.39 ms per token,  2554.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.31 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     204.09 ms /   512 tokens (    0.40 ms per token,  2508.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     222.24 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     201.15 ms /   512 tokens (    0.39 ms per token,  2545.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.76 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     199.18 ms /   512 tokens (    0.39 ms per token,  2570.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.96 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     202.44 ms /   512 tokens (    0.40 ms per token,  2529.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     222.04 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.44 ms /   512 tokens (    0.39 ms per token,  2554.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.98 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     190.90 ms /   512 tokens (    0.37 ms per token,  2682.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     209.55 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     203.51 ms /   512 tokens (    0.40 ms per token,  2515.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     220.70 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.47 ms /   512 tokens (    0.39 ms per token,  2553.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     217.66 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.46 ms /   512 tokens (    0.39 ms per token,  2554.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.53 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     204.34 ms /   512 tokens (    0.40 ms per token,  2505.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     224.26 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.53 ms /   512 tokens (    0.39 ms per token,  2553.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     220.01 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.35 ms /   512 tokens (    0.39 ms per token,  2555.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.45 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     203.23 ms /   512 tokens (    0.40 ms per token,  2519.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.07 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.94 ms /   512 tokens (    0.39 ms per token,  2548.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.76 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     200.12 ms /   512 tokens (    0.39 ms per token,  2558.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.27 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     202.94 ms /   512 tokens (    0.40 ms per token,  2522.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     224.44 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     185.18 ms /   430 tokens (    0.43 ms per token,  2322.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     200.69 ms /   431 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     102.02 ms /   202 tokens (    0.51 ms per token,  1979.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.28 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     106.97 ms /   220 tokens (    0.49 ms per token,  2056.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.56 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     100.83 ms /   194 tokens (    0.52 ms per token,  1924.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.22 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.69 ms /    51 tokens (    1.21 ms per token,   826.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.24 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     142.12 ms /   291 tokens (    0.49 ms per token,  2047.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.25 ms /   292 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     103.24 ms /   203 tokens (    0.51 ms per token,  1966.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     111.07 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      99.96 ms /   193 tokens (    0.52 ms per token,  1930.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.15 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.57 ms /    73 tokens (    0.88 ms per token,  1130.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.88 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      56.20 ms /    32 tokens (    1.76 ms per token,   569.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.15 ms /    33 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.87 ms /    81 tokens (    0.81 ms per token,  1229.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.48 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      69.04 ms /   102 tokens (    0.68 ms per token,  1477.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.65 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     108.22 ms /   226 tokens (    0.48 ms per token,  2088.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.80 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.53 ms /    52 tokens (    1.13 ms per token,   888.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      61.42 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     144.44 ms /   300 tokens (    0.48 ms per token,  2077.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.29 ms /   301 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     103.27 ms /   214 tokens (    0.48 ms per token,  2072.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     111.07 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     142.69 ms /   270 tokens (    0.53 ms per token,  1892.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.95 ms /   271 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     105.34 ms /   195 tokens (    0.54 ms per token,  1851.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     112.55 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     113.76 ms /   234 tokens (    0.49 ms per token,  2056.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.38 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      92.46 ms /   161 tokens (    0.57 ms per token,  1741.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.98 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     117.48 ms /   250 tokens (    0.47 ms per token,  2127.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.31 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     182.23 ms /   392 tokens (    0.46 ms per token,  2151.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.61 ms /   393 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     107.03 ms /   231 tokens (    0.46 ms per token,  2158.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.69 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     135.64 ms /   258 tokens (    0.53 ms per token,  1902.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     146.51 ms /   259 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.26 ms /    33 tokens (    1.67 ms per token,   597.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.38 ms /    34 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.74 ms /    80 tokens (    0.82 ms per token,  1216.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.79 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     109.45 ms /   235 tokens (    0.47 ms per token,  2147.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.56 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     105.39 ms /   215 tokens (    0.49 ms per token,  2040.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     113.89 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      69.31 ms /    81 tokens (    0.86 ms per token,  1168.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.53 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      72.81 ms /   127 tokens (    0.57 ms per token,  1744.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.24 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.38 ms /   133 tokens (    0.64 ms per token,  1557.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.90 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.25 ms /   148 tokens (    0.61 ms per token,  1639.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.13 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.02 ms /    81 tokens (    0.80 ms per token,  1245.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.70 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.90 ms /    77 tokens (    0.84 ms per token,  1186.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.40 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      97.97 ms /   182 tokens (    0.54 ms per token,  1857.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.43 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     105.68 ms /   200 tokens (    0.53 ms per token,  1892.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     112.74 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      88.88 ms /   136 tokens (    0.65 ms per token,  1530.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.21 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      54.90 ms /    24 tokens (    2.29 ms per token,   437.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.70 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      74.91 ms /   116 tokens (    0.65 ms per token,  1548.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.03 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      54.18 ms /    18 tokens (    3.01 ms per token,   332.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.83 ms /    19 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     107.91 ms /   213 tokens (    0.51 ms per token,  1973.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     116.11 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.38 ms /    38 tokens (    1.54 ms per token,   650.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.72 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.90 ms /    46 tokens (    1.28 ms per token,   781.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      61.44 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.31 ms /    74 tokens (    0.87 ms per token,  1150.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.73 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     146.50 ms /   293 tokens (    0.50 ms per token,  2000.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.18 ms /   294 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.66 ms /    76 tokens (    0.85 ms per token,  1175.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.28 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      54.45 ms /    23 tokens (    2.37 ms per token,   422.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.20 ms /    24 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.05 ms /    65 tokens (    0.99 ms per token,  1014.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.17 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.16 ms /    27 tokens (    2.04 ms per token,   489.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.97 ms /    28 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      67.34 ms /    88 tokens (    0.77 ms per token,  1306.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.16 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      54.81 ms /    14 tokens (    3.92 ms per token,   255.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.25 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      92.66 ms /   159 tokens (    0.58 ms per token,  1716.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.83 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.28 ms /   183 tokens (    0.54 ms per token,  1862.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.16 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      68.63 ms /    91 tokens (    0.75 ms per token,  1325.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.71 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      60.18 ms /    62 tokens (    0.97 ms per token,  1030.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      63.20 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     115.41 ms /   223 tokens (    0.52 ms per token,  1932.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     124.81 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      69.54 ms /    98 tokens (    0.71 ms per token,  1409.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.95 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     150.46 ms /   276 tokens (    0.55 ms per token,  1834.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.67 ms /   277 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     112.39 ms /   219 tokens (    0.51 ms per token,  1948.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.91 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      97.00 ms /   161 tokens (    0.60 ms per token,  1659.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     103.07 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     109.15 ms /   194 tokens (    0.56 ms per token,  1777.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.24 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.56 ms /    68 tokens (    0.95 ms per token,  1053.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.81 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.78 ms /    26 tokens (    2.15 ms per token,   466.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.82 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     119.19 ms /   242 tokens (    0.49 ms per token,  2030.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     132.07 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.17 ms /    37 tokens (    1.57 ms per token,   636.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.59 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      92.54 ms /   150 tokens (    0.62 ms per token,  1620.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.58 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     117.39 ms /   240 tokens (    0.49 ms per token,  2044.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.25 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      53.69 ms /    14 tokens (    3.83 ms per token,   260.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.33 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.38 ms /   138 tokens (    0.68 ms per token,  1462.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.17 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      59.83 ms /    51 tokens (    1.17 ms per token,   852.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.44 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.44 ms /    65 tokens (    0.99 ms per token,  1008.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.43 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      68.65 ms /    87 tokens (    0.79 ms per token,  1267.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.73 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     151.92 ms /   288 tokens (    0.53 ms per token,  1895.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.20 ms /   289 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      70.59 ms /    99 tokens (    0.71 ms per token,  1402.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.24 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.35 ms /    65 tokens (    0.99 ms per token,  1010.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.56 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      59.74 ms /    60 tokens (    1.00 ms per token,  1004.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.68 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      95.03 ms /   153 tokens (    0.62 ms per token,  1610.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.94 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      71.22 ms /   100 tokens (    0.71 ms per token,  1404.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.68 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      60.04 ms /    45 tokens (    1.33 ms per token,   749.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.48 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     157.77 ms /   302 tokens (    0.52 ms per token,  1914.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     169.28 ms /   303 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     117.16 ms /   232 tokens (    0.51 ms per token,  1980.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.92 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     112.03 ms /   213 tokens (    0.53 ms per token,  1901.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     120.22 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      99.27 ms /   175 tokens (    0.57 ms per token,  1762.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.96 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      70.79 ms /    99 tokens (    0.72 ms per token,  1398.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.32 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      59.51 ms /    45 tokens (    1.32 ms per token,   756.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.32 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.89 ms /    31 tokens (    1.80 ms per token,   554.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.04 ms /    32 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.07 ms /    79 tokens (    0.84 ms per token,  1195.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.65 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.31 ms /    66 tokens (    0.99 ms per token,  1010.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.93 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     121.76 ms /   254 tokens (    0.48 ms per token,  2086.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.89 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     154.98 ms /   259 tokens (    0.60 ms per token,  1671.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.59 ms /   260 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     158.38 ms /   272 tokens (    0.58 ms per token,  1717.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     169.00 ms /   273 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     126.54 ms /   244 tokens (    0.52 ms per token,  1928.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.54 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.39 ms /   151 tokens (    0.63 ms per token,  1599.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.31 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.02 ms /   161 tokens (    0.61 ms per token,  1642.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.33 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      99.04 ms /   174 tokens (    0.57 ms per token,  1756.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     106.24 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      59.07 ms /    46 tokens (    1.28 ms per token,   778.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      61.59 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      92.11 ms /   142 tokens (    0.65 ms per token,  1541.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.52 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     121.91 ms /   250 tokens (    0.49 ms per token,  2050.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.60 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     112.63 ms /   216 tokens (    0.52 ms per token,  1917.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.05 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     101.37 ms /   189 tokens (    0.54 ms per token,  1864.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.46 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      92.27 ms /   143 tokens (    0.65 ms per token,  1549.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.13 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      99.44 ms /   173 tokens (    0.57 ms per token,  1739.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.85 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      59.68 ms /    44 tokens (    1.36 ms per token,   737.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.54 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     113.40 ms /   214 tokens (    0.53 ms per token,  1887.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     121.17 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     127.53 ms /   250 tokens (    0.51 ms per token,  1960.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.40 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.17 ms /    60 tokens (    1.02 ms per token,   980.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.22 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     122.16 ms /   221 tokens (    0.55 ms per token,  1809.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.62 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      72.02 ms /   102 tokens (    0.71 ms per token,  1416.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.61 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      73.45 ms /    98 tokens (    0.75 ms per token,  1334.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.74 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     119.18 ms /   207 tokens (    0.58 ms per token,  1736.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.59 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     115.26 ms /   195 tokens (    0.59 ms per token,  1691.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     124.06 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     118.19 ms /   215 tokens (    0.55 ms per token,  1819.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     126.40 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     165.43 ms /   298 tokens (    0.56 ms per token,  1801.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     178.85 ms /   299 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      60.10 ms /    46 tokens (    1.31 ms per token,   765.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      63.12 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      70.09 ms /    84 tokens (    0.83 ms per token,  1198.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.41 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      70.27 ms /    81 tokens (    0.87 ms per token,  1152.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.02 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     161.34 ms /   278 tokens (    0.58 ms per token,  1723.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     171.48 ms /   279 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.47 ms /    40 tokens (    1.46 ms per token,   684.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.95 ms /    41 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      76.64 ms /   118 tokens (    0.65 ms per token,  1539.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.04 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.85 ms /    26 tokens (    2.26 ms per token,   441.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.95 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     158.97 ms /   269 tokens (    0.59 ms per token,  1692.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     168.76 ms /   270 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      73.67 ms /   109 tokens (    0.68 ms per token,  1479.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.12 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     102.60 ms /   161 tokens (    0.64 ms per token,  1569.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.11 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      53.57 ms /    11 tokens (    4.87 ms per token,   205.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.93 ms /    12 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      54.09 ms /     9 tokens (    6.01 ms per token,   166.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      55.36 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      71.40 ms /    80 tokens (    0.89 ms per token,  1120.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.33 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     123.20 ms /   210 tokens (    0.59 ms per token,  1704.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     132.08 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     111.47 ms /   169 tokens (    0.66 ms per token,  1516.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.48 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     183.42 ms /   274 tokens (    0.67 ms per token,  1493.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     193.17 ms /   275 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     103.10 ms /   132 tokens (    0.78 ms per token,  1280.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.25 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     112.13 ms /   155 tokens (    0.72 ms per token,  1382.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.68 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     106.00 ms /   131 tokens (    0.81 ms per token,  1235.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     111.43 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     133.59 ms /   200 tokens (    0.67 ms per token,  1497.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.07 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     117.67 ms /   188 tokens (    0.63 ms per token,  1597.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     124.68 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     103.37 ms /   131 tokens (    0.79 ms per token,  1267.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.65 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     113.89 ms /   148 tokens (    0.77 ms per token,  1299.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.69 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     137.31 ms /   221 tokens (    0.62 ms per token,  1609.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     146.16 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      76.27 ms /   103 tokens (    0.74 ms per token,  1350.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.95 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     112.26 ms /   147 tokens (    0.76 ms per token,  1309.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.40 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      62.62 ms /    41 tokens (    1.53 ms per token,   654.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.93 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     117.51 ms /   172 tokens (    0.68 ms per token,  1463.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     123.81 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.46 ms /    52 tokens (    1.22 ms per token,   819.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.08 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.67 ms /    56 tokens (    1.10 ms per token,   908.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.45 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      85.72 ms /   128 tokens (    0.67 ms per token,  1493.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.55 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.09 ms /    44 tokens (    1.43 ms per token,   697.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.60 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      33.94 ms /     5 tokens (    6.79 ms per token,   147.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.00 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      79.84 ms /    99 tokens (    0.81 ms per token,  1239.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.52 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     123.94 ms /   186 tokens (    0.67 ms per token,  1500.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.84 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      70.05 ms /    65 tokens (    1.08 ms per token,   927.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.15 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      62.69 ms /    41 tokens (    1.53 ms per token,   653.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.35 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      84.35 ms /   128 tokens (    0.66 ms per token,  1517.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.51 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     119.63 ms /   172 tokens (    0.70 ms per token,  1437.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.94 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      76.22 ms /    93 tokens (    0.82 ms per token,  1220.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.34 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     133.99 ms /   207 tokens (    0.65 ms per token,  1544.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.49 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     127.96 ms /   206 tokens (    0.62 ms per token,  1609.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.78 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      72.78 ms /    85 tokens (    0.86 ms per token,  1167.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.93 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     148.99 ms /   251 tokens (    0.59 ms per token,  1684.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.60 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      79.47 ms /   120 tokens (    0.66 ms per token,  1510.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.39 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     129.40 ms /   195 tokens (    0.66 ms per token,  1506.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     137.85 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      69.88 ms /    72 tokens (    0.97 ms per token,  1030.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.17 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      81.99 ms /   113 tokens (    0.73 ms per token,  1378.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.87 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     140.81 ms /   230 tokens (    0.61 ms per token,  1633.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.16 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     172.94 ms /   261 tokens (    0.66 ms per token,  1509.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     182.77 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      60.93 ms /    60 tokens (    1.02 ms per token,   984.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.15 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      77.17 ms /    91 tokens (    0.85 ms per token,  1179.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.16 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     130.87 ms /   193 tokens (    0.68 ms per token,  1474.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     139.32 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      71.87 ms /    85 tokens (    0.85 ms per token,  1182.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.59 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      57.90 ms /    28 tokens (    2.07 ms per token,   483.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      59.67 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.28 ms /    47 tokens (    1.35 ms per token,   742.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.02 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     205.47 ms /   340 tokens (    0.60 ms per token,  1654.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.85 ms /   341 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     176.42 ms /   268 tokens (    0.66 ms per token,  1519.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     186.09 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      75.79 ms /   105 tokens (    0.72 ms per token,  1385.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.24 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     148.87 ms /   254 tokens (    0.59 ms per token,  1706.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.20 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      56.65 ms /    24 tokens (    2.36 ms per token,   423.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.64 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     116.74 ms /   173 tokens (    0.67 ms per token,  1481.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     123.07 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      79.84 ms /   120 tokens (    0.67 ms per token,  1503.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.76 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     185.05 ms /   276 tokens (    0.67 ms per token,  1491.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     195.67 ms /   277 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      77.39 ms /   108 tokens (    0.72 ms per token,  1395.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.77 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     104.78 ms /   141 tokens (    0.74 ms per token,  1345.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     114.33 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     133.47 ms /   208 tokens (    0.64 ms per token,  1558.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.30 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      54.68 ms /    13 tokens (    4.21 ms per token,   237.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.18 ms /    14 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     118.95 ms /   173 tokens (    0.69 ms per token,  1454.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.60 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.74 ms /    55 tokens (    1.12 ms per token,   890.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.98 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     143.58 ms /   236 tokens (    0.61 ms per token,  1643.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.84 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     143.15 ms /   250 tokens (    0.57 ms per token,  1746.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.51 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      76.67 ms /   104 tokens (    0.74 ms per token,  1356.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.40 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      62.65 ms /    41 tokens (    1.53 ms per token,   654.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.36 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.77 ms /    37 tokens (    1.67 ms per token,   598.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.03 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      75.69 ms /    88 tokens (    0.86 ms per token,  1162.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.51 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      62.69 ms /    56 tokens (    1.12 ms per token,   893.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.42 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     135.50 ms /   207 tokens (    0.65 ms per token,  1527.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     144.49 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     109.16 ms /   159 tokens (    0.69 ms per token,  1456.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.98 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.25 ms /    44 tokens (    1.46 ms per token,   684.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.15 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      69.08 ms /    50 tokens (    1.38 ms per token,   723.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.27 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     149.41 ms /   175 tokens (    0.85 ms per token,  1171.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.69 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.46 ms /    51 tokens (    1.30 ms per token,   767.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.68 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     136.51 ms /   157 tokens (    0.87 ms per token,  1150.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.05 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     156.52 ms /   200 tokens (    0.78 ms per token,  1277.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.74 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      71.61 ms /    78 tokens (    0.92 ms per token,  1089.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.67 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      70.84 ms /    72 tokens (    0.98 ms per token,  1016.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.47 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.59 ms /    58 tokens (    1.06 ms per token,   941.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.25 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      77.55 ms /   110 tokens (    0.70 ms per token,  1418.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.40 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      71.81 ms /    85 tokens (    0.84 ms per token,  1183.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.08 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     107.13 ms /   146 tokens (    0.73 ms per token,  1362.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     113.97 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      23.34 ms /     3 tokens (    7.78 ms per token,   128.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      24.53 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.74 ms /    40 tokens (    1.54 ms per token,   647.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.37 ms /    41 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     111.38 ms /   163 tokens (    0.68 ms per token,  1463.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.72 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     130.39 ms /   228 tokens (    0.57 ms per token,  1748.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     139.73 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      76.15 ms /   122 tokens (    0.62 ms per token,  1602.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.20 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     111.21 ms /   212 tokens (    0.52 ms per token,  1906.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.48 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     161.78 ms /    45 tokens (    3.60 ms per token,   278.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.34 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     271.18 ms /    79 tokens (    3.43 ms per token,   291.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     275.67 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     249.04 ms /   115 tokens (    2.17 ms per token,   461.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     255.30 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     226.50 ms /   249 tokens (    0.91 ms per token,  1099.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     236.57 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      83.76 ms /   113 tokens (    0.74 ms per token,  1349.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.48 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     130.34 ms /   219 tokens (    0.60 ms per token,  1680.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     139.17 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      70.23 ms /    79 tokens (    0.89 ms per token,  1124.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      73.75 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.95 ms /    55 tokens (    1.13 ms per token,   887.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.78 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     104.80 ms /   139 tokens (    0.75 ms per token,  1326.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     110.54 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      69.24 ms /    76 tokens (    0.91 ms per token,  1097.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.70 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      57.97 ms /    19 tokens (    3.05 ms per token,   327.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      59.53 ms /    20 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      97.20 ms /    89 tokens (    1.09 ms per token,   915.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.26 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     196.03 ms /   250 tokens (    0.78 ms per token,  1275.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.49 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.46 ms /    39 tokens (    1.65 ms per token,   604.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.00 ms /    40 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     182.72 ms /   235 tokens (    0.78 ms per token,  1286.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.97 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     233.29 ms /   285 tokens (    0.82 ms per token,  1221.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     245.52 ms /   286 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     115.75 ms /   157 tokens (    0.74 ms per token,  1356.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     123.01 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     118.86 ms /   185 tokens (    0.64 ms per token,  1556.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.60 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      75.03 ms /    89 tokens (    0.84 ms per token,  1186.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.14 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     140.54 ms /   230 tokens (    0.61 ms per token,  1636.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.06 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      30.52 ms /     6 tokens (    5.09 ms per token,   196.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      31.86 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      87.21 ms /   116 tokens (    0.75 ms per token,  1330.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.06 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     134.93 ms /   210 tokens (    0.64 ms per token,  1556.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     144.58 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      70.93 ms /    67 tokens (    1.06 ms per token,   944.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.73 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      72.99 ms /    78 tokens (    0.94 ms per token,  1068.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.95 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.17 ms /    57 tokens (    1.11 ms per token,   902.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.33 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      77.35 ms /    91 tokens (    0.85 ms per token,  1176.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.33 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.12 ms /    25 tokens (    2.32 ms per token,   430.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.31 ms /    26 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     109.25 ms /   139 tokens (    0.79 ms per token,  1272.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.75 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      54.77 ms /     9 tokens (    6.09 ms per token,   164.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.03 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      62.56 ms /    56 tokens (    1.12 ms per token,   895.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.43 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     119.06 ms /   166 tokens (    0.72 ms per token,  1394.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.66 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.01 ms /   112 tokens (    0.88 ms per token,  1142.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.61 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      95.60 ms /    81 tokens (    1.18 ms per token,   847.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.44 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      55.30 ms /     7 tokens (    7.90 ms per token,   126.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      56.56 ms /     8 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      83.70 ms /    45 tokens (    1.86 ms per token,   537.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.23 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     152.74 ms /   129 tokens (    1.18 ms per token,   844.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     158.83 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     152.60 ms /   156 tokens (    0.98 ms per token,  1022.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     159.35 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.86 ms /    88 tokens (    1.08 ms per token,   927.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.13 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     202.33 ms /   250 tokens (    0.81 ms per token,  1235.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.97 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      84.39 ms /    76 tokens (    1.11 ms per token,   900.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.06 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.82 ms /    84 tokens (    1.18 ms per token,   850.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.63 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.24 ms /    83 tokens (    1.18 ms per token,   844.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.13 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     196.25 ms /   247 tokens (    0.79 ms per token,  1258.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.01 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     183.50 ms /   247 tokens (    0.74 ms per token,  1346.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     192.95 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     148.95 ms /   180 tokens (    0.83 ms per token,  1208.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.27 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.92 ms /    96 tokens (    1.03 ms per token,   970.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     103.48 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     189.67 ms /   231 tokens (    0.82 ms per token,  1217.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     198.67 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     238.85 ms /   282 tokens (    0.85 ms per token,  1180.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.21 ms /   283 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      67.56 ms /    64 tokens (    1.06 ms per token,   947.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.68 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      69.07 ms /    26 tokens (    2.66 ms per token,   376.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.90 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     195.94 ms /   239 tokens (    0.82 ms per token,  1219.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.19 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     133.79 ms /   136 tokens (    0.98 ms per token,  1016.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     139.33 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     159.47 ms /   174 tokens (    0.92 ms per token,  1091.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.22 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     145.63 ms /   137 tokens (    1.06 ms per token,   940.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.55 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.31 ms /    27 tokens (    2.38 ms per token,   419.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.62 ms /    28 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.79 ms /    74 tokens (    1.28 ms per token,   780.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.72 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      69.17 ms /    22 tokens (    3.14 ms per token,   318.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.33 ms /    23 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      98.90 ms /    72 tokens (    1.37 ms per token,   727.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.72 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      68.76 ms /    24 tokens (    2.86 ms per token,   349.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.02 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      77.35 ms /    52 tokens (    1.49 ms per token,   672.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.33 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     178.90 ms /   194 tokens (    0.92 ms per token,  1084.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.05 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      87.91 ms /    89 tokens (    0.99 ms per token,  1012.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.72 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      99.68 ms /    87 tokens (    1.15 ms per token,   872.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.36 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     144.50 ms /   132 tokens (    1.09 ms per token,   913.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.49 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     158.55 ms /   168 tokens (    0.94 ms per token,  1059.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     165.97 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     151.83 ms /   165 tokens (    0.92 ms per token,  1086.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     158.88 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      62.10 ms /    13 tokens (    4.78 ms per token,   209.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.00 ms /    14 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     196.82 ms /   241 tokens (    0.82 ms per token,  1224.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.89 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.82 ms /    59 tokens (    1.13 ms per token,   882.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.45 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      31.96 ms /     3 tokens (   10.65 ms per token,    93.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.06 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      96.85 ms /    75 tokens (    1.29 ms per token,   774.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.56 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     282.63 ms /   351 tokens (    0.81 ms per token,  1241.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     297.45 ms /   352 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     122.87 ms /   133 tokens (    0.92 ms per token,  1082.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     128.57 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      71.75 ms /    37 tokens (    1.94 ms per token,   515.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.39 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     109.46 ms /   105 tokens (    1.04 ms per token,   959.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     114.25 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.70 ms /    82 tokens (    1.15 ms per token,   865.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.72 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     149.69 ms /   139 tokens (    1.08 ms per token,   928.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.78 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     110.08 ms /   124 tokens (    0.89 ms per token,  1126.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.68 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      96.91 ms /    92 tokens (    1.05 ms per token,   949.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     101.91 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      72.63 ms /    52 tokens (    1.40 ms per token,   715.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.90 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     108.52 ms /   100 tokens (    1.09 ms per token,   921.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     113.00 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.74 ms /     9 tokens (    7.30 ms per token,   136.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.34 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     112.28 ms /   111 tokens (    1.01 ms per token,   988.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.36 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      96.28 ms /    78 tokens (    1.23 ms per token,   810.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.08 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     148.97 ms /   137 tokens (    1.09 ms per token,   919.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     154.50 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     243.49 ms /   268 tokens (    0.91 ms per token,  1100.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.33 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     127.15 ms /   136 tokens (    0.93 ms per token,  1069.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.34 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     103.17 ms /   104 tokens (    0.99 ms per token,  1008.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.78 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     177.55 ms /   206 tokens (    0.86 ms per token,  1160.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     186.12 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     168.43 ms /   199 tokens (    0.85 ms per token,  1181.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     175.67 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.78 ms /    33 tokens (    1.93 ms per token,   517.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.85 ms /    34 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.94 ms /    13 tokens (    5.00 ms per token,   200.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.41 ms /    14 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     245.94 ms /   261 tokens (    0.94 ms per token,  1061.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     256.79 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      97.93 ms /   125 tokens (    0.78 ms per token,  1276.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.94 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     182.74 ms /   225 tokens (    0.81 ms per token,  1231.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.40 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     229.65 ms /   265 tokens (    0.87 ms per token,  1153.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     239.56 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      87.70 ms /    96 tokens (    0.91 ms per token,  1094.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.09 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     189.12 ms /   230 tokens (    0.82 ms per token,  1216.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     197.92 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     186.31 ms /   255 tokens (    0.73 ms per token,  1368.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     195.67 ms /   256 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     167.63 ms /   217 tokens (    0.77 ms per token,  1294.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     175.97 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     103.20 ms /   124 tokens (    0.83 ms per token,  1201.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.59 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     203.94 ms /   256 tokens (    0.80 ms per token,  1255.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     213.61 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     224.91 ms /   260 tokens (    0.87 ms per token,  1156.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     235.99 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      88.86 ms /   105 tokens (    0.85 ms per token,  1181.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.76 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     157.87 ms /   172 tokens (    0.92 ms per token,  1089.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     164.46 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     237.16 ms /   258 tokens (    0.92 ms per token,  1087.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     246.77 ms /   259 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      95.14 ms /   114 tokens (    0.83 ms per token,  1198.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.17 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     113.22 ms /   128 tokens (    0.88 ms per token,  1130.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.23 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.54 ms /    15 tokens (    4.10 ms per token,   243.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      63.26 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      70.79 ms /    29 tokens (    2.44 ms per token,   409.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.60 ms /    30 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     268.29 ms /   299 tokens (    0.90 ms per token,  1114.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     279.61 ms /   300 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     260.66 ms /   346 tokens (    0.75 ms per token,  1327.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     275.56 ms /   347 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     229.90 ms /   283 tokens (    0.81 ms per token,  1230.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     240.08 ms /   284 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.99 ms /    62 tokens (    1.08 ms per token,   925.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.06 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     186.92 ms /   217 tokens (    0.86 ms per token,  1160.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     194.69 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      93.97 ms /    95 tokens (    0.99 ms per token,  1010.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      98.18 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     247.25 ms /   269 tokens (    0.92 ms per token,  1087.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     258.45 ms /   270 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      80.82 ms /    74 tokens (    1.09 ms per token,   915.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.76 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     144.13 ms /   130 tokens (    1.11 ms per token,   901.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.79 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      87.77 ms /    68 tokens (    1.29 ms per token,   774.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.38 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     111.92 ms /   120 tokens (    0.93 ms per token,  1072.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     117.25 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     154.84 ms /   159 tokens (    0.97 ms per token,  1026.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     161.75 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     170.32 ms /   198 tokens (    0.86 ms per token,  1162.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     179.86 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     183.54 ms /   249 tokens (    0.74 ms per token,  1356.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     193.62 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     162.50 ms /   199 tokens (    0.82 ms per token,  1224.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.55 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.52 ms /    45 tokens (    1.48 ms per token,   676.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.36 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      68.26 ms /    24 tokens (    2.84 ms per token,   351.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.18 ms /    25 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     158.85 ms /   161 tokens (    0.99 ms per token,  1013.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     169.13 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     172.62 ms /   217 tokens (    0.80 ms per token,  1257.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.15 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     178.93 ms /   249 tokens (    0.72 ms per token,  1391.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.76 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      68.91 ms /    63 tokens (    1.09 ms per token,   914.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.11 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     267.27 ms /   309 tokens (    0.86 ms per token,  1156.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     280.84 ms /   310 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.33 ms /    38 tokens (    1.67 ms per token,   600.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.78 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     246.43 ms /   275 tokens (    0.90 ms per token,  1115.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     256.14 ms /   276 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     182.91 ms /   256 tokens (    0.71 ms per token,  1399.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     193.91 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      96.97 ms /   121 tokens (    0.80 ms per token,  1247.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.43 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     173.72 ms /   197 tokens (    0.88 ms per token,  1133.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.94 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     144.58 ms /   155 tokens (    0.93 ms per token,  1072.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.71 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     193.55 ms /   250 tokens (    0.77 ms per token,  1291.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     202.33 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     228.06 ms /   268 tokens (    0.85 ms per token,  1175.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     238.29 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     223.59 ms /   260 tokens (    0.86 ms per token,  1162.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     234.17 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      81.31 ms /    72 tokens (    1.13 ms per token,   885.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.75 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     103.32 ms /   100 tokens (    1.03 ms per token,   967.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.88 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.35 ms /    16 tokens (    4.15 ms per token,   241.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.03 ms /    17 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      82.96 ms /    62 tokens (    1.34 ms per token,   747.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.14 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     169.46 ms /   188 tokens (    0.90 ms per token,  1109.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     176.56 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     102.79 ms /   116 tokens (    0.89 ms per token,  1128.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     108.34 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     109.41 ms /   123 tokens (    0.89 ms per token,  1124.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     114.64 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.56 ms /    12 tokens (    5.30 ms per token,   188.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.25 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     172.19 ms /   190 tokens (    0.91 ms per token,  1103.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     179.81 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      95.26 ms /   101 tokens (    0.94 ms per token,  1060.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.84 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     106.48 ms /   114 tokens (    0.93 ms per token,  1070.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     111.36 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.54 ms /    14 tokens (    4.75 ms per token,   210.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.99 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      99.57 ms /    70 tokens (    1.42 ms per token,   703.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     103.23 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      75.86 ms /    44 tokens (    1.72 ms per token,   580.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.25 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      76.00 ms /    47 tokens (    1.62 ms per token,   618.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.84 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     100.10 ms /    79 tokens (    1.27 ms per token,   789.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     103.75 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     100.64 ms /    90 tokens (    1.12 ms per token,   894.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.08 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      77.39 ms /    57 tokens (    1.36 ms per token,   736.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.50 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      75.17 ms /    38 tokens (    1.98 ms per token,   505.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.44 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      72.82 ms /    26 tokens (    2.80 ms per token,   357.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.81 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     106.63 ms /    89 tokens (    1.20 ms per token,   834.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     110.86 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     189.55 ms /   226 tokens (    0.84 ms per token,  1192.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.09 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     147.25 ms /   175 tokens (    0.84 ms per token,  1188.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     154.34 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     139.52 ms /   141 tokens (    0.99 ms per token,  1010.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.28 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     150.41 ms /   143 tokens (    1.05 ms per token,   950.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.09 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     147.14 ms /   151 tokens (    0.97 ms per token,  1026.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.25 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     184.71 ms /   229 tokens (    0.81 ms per token,  1239.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     195.05 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.61 ms /    38 tokens (    1.67 ms per token,   597.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      66.35 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     146.40 ms /   146 tokens (    1.00 ms per token,   997.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.92 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     242.36 ms /   268 tokens (    0.90 ms per token,  1105.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.04 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.47 ms /    54 tokens (    1.23 ms per token,   812.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.63 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     100.30 ms /    90 tokens (    1.11 ms per token,   897.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     104.41 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     109.40 ms /   111 tokens (    0.99 ms per token,  1014.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     114.67 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      91.55 ms /    71 tokens (    1.29 ms per token,   775.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      95.46 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     104.95 ms /   105 tokens (    1.00 ms per token,  1000.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.80 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     104.74 ms /    99 tokens (    1.06 ms per token,   945.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.71 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     164.13 ms /   178 tokens (    0.92 ms per token,  1084.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     171.81 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      69.55 ms /    35 tokens (    1.99 ms per token,   503.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.78 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     149.99 ms /   129 tokens (    1.16 ms per token,   860.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.46 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      94.96 ms /    84 tokens (    1.13 ms per token,   884.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.53 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     189.20 ms /   233 tokens (    0.81 ms per token,  1231.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.42 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     167.85 ms /   214 tokens (    0.78 ms per token,  1274.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     177.65 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      84.70 ms /    79 tokens (    1.07 ms per token,   932.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.13 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      35.25 ms /     4 tokens (    8.81 ms per token,   113.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.72 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     116.19 ms /   128 tokens (    0.91 ms per token,  1101.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     123.04 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      74.25 ms /    61 tokens (    1.22 ms per token,   821.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.79 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     108.42 ms /   102 tokens (    1.06 ms per token,   940.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     113.85 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     181.54 ms /   221 tokens (    0.82 ms per token,  1217.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     192.11 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      86.11 ms /    96 tokens (    0.90 ms per token,  1114.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.99 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     236.37 ms /   258 tokens (    0.92 ms per token,  1091.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     247.79 ms /   259 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      59.88 ms /    28 tokens (    2.14 ms per token,   467.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.29 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     172.57 ms /   201 tokens (    0.86 ms per token,  1164.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     180.90 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     185.14 ms /   247 tokens (    0.75 ms per token,  1334.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     194.19 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.47 ms /    34 tokens (    1.87 ms per token,   535.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.67 ms /    35 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     177.51 ms /   187 tokens (    0.95 ms per token,  1053.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     184.65 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     166.81 ms /   122 tokens (    1.37 ms per token,   731.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     172.50 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     246.00 ms /   155 tokens (    1.59 ms per token,   630.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.23 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     283.37 ms /   220 tokens (    1.29 ms per token,   776.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     292.22 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     131.88 ms /    73 tokens (    1.81 ms per token,   553.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.19 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     379.37 ms /   263 tokens (    1.44 ms per token,   693.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     391.36 ms /   264 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      75.05 ms /    28 tokens (    2.68 ms per token,   373.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.10 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     384.54 ms /   261 tokens (    1.47 ms per token,   678.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     394.79 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      75.94 ms /    26 tokens (    2.92 ms per token,   342.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.15 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     262.21 ms /   242 tokens (    1.08 ms per token,   922.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     272.14 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     223.71 ms /   258 tokens (    0.87 ms per token,  1153.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     234.94 ms /   259 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      77.53 ms /    68 tokens (    1.14 ms per token,   877.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.79 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     181.39 ms /   213 tokens (    0.85 ms per token,  1174.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     190.81 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.19 ms /    91 tokens (    0.99 ms per token,  1009.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.25 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      74.59 ms /    54 tokens (    1.38 ms per token,   723.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.43 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     190.68 ms /   209 tokens (    0.91 ms per token,  1096.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.63 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     151.17 ms /   178 tokens (    0.85 ms per token,  1177.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     158.74 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     181.00 ms /   224 tokens (    0.81 ms per token,  1237.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     189.52 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     167.37 ms /   209 tokens (    0.80 ms per token,  1248.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     175.48 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     173.15 ms /   214 tokens (    0.81 ms per token,  1235.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.86 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     170.83 ms /   214 tokens (    0.80 ms per token,  1252.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     180.44 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      87.16 ms /    80 tokens (    1.09 ms per token,   917.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.66 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      69.56 ms /    28 tokens (    2.48 ms per token,   402.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.82 ms /    29 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      68.27 ms /    11 tokens (    6.21 ms per token,   161.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.85 ms /    12 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     175.07 ms /   192 tokens (    0.91 ms per token,  1096.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     185.33 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.84 ms /    88 tokens (    1.03 ms per token,   968.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      95.67 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     101.75 ms /   104 tokens (    0.98 ms per token,  1022.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     107.29 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     171.49 ms /   205 tokens (    0.84 ms per token,  1195.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     180.82 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      95.34 ms /   103 tokens (    0.93 ms per token,  1080.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.65 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     242.41 ms /   277 tokens (    0.88 ms per token,  1142.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     255.31 ms /   278 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.79 ms /    53 tokens (    1.22 ms per token,   817.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.31 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      70.11 ms /    37 tokens (    1.89 ms per token,   527.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.55 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      73.89 ms /    35 tokens (    2.11 ms per token,   473.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.35 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     185.46 ms /   202 tokens (    0.92 ms per token,  1089.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     194.45 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      92.61 ms /   104 tokens (    0.89 ms per token,  1123.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      99.14 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     241.54 ms /   268 tokens (    0.90 ms per token,  1109.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     254.43 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     179.30 ms /   254 tokens (    0.71 ms per token,  1416.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     190.01 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      56.82 ms /    12 tokens (    4.74 ms per token,   211.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.37 ms /    13 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     193.77 ms /   207 tokens (    0.94 ms per token,  1068.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     202.67 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     257.56 ms /   217 tokens (    1.19 ms per token,   842.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     266.87 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     140.80 ms /   108 tokens (    1.30 ms per token,   767.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     146.07 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     194.09 ms /   178 tokens (    1.09 ms per token,   917.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     202.08 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      76.64 ms /    37 tokens (    2.07 ms per token,   482.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.41 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      70.63 ms /    14 tokens (    5.04 ms per token,   198.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.22 ms /    15 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     173.94 ms /   193 tokens (    0.90 ms per token,  1109.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.91 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      82.84 ms /    71 tokens (    1.17 ms per token,   857.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.68 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      70.92 ms /    44 tokens (    1.61 ms per token,   620.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.11 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     168.02 ms /   177 tokens (    0.95 ms per token,  1053.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     176.02 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     309.03 ms /   276 tokens (    1.12 ms per token,   893.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     321.63 ms /   277 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     211.01 ms /   218 tokens (    0.97 ms per token,  1033.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     220.83 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      80.94 ms /    48 tokens (    1.69 ms per token,   593.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      83.97 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     237.05 ms /   206 tokens (    1.15 ms per token,   869.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     245.42 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     299.38 ms /   265 tokens (    1.13 ms per token,   885.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     311.11 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     210.39 ms /   210 tokens (    1.00 ms per token,   998.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.40 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     304.91 ms /   271 tokens (    1.13 ms per token,   888.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     316.10 ms /   272 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     216.28 ms /   232 tokens (    0.93 ms per token,  1072.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     226.33 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     303.40 ms /   283 tokens (    1.07 ms per token,   932.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     315.98 ms /   284 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     179.68 ms /   174 tokens (    1.03 ms per token,   968.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     186.65 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     332.49 ms /   315 tokens (    1.06 ms per token,   947.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     344.17 ms /   316 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      74.10 ms /    52 tokens (    1.43 ms per token,   701.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      77.11 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     215.83 ms /   168 tokens (    1.28 ms per token,   778.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     225.88 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     234.07 ms /   245 tokens (    0.96 ms per token,  1046.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     244.99 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      76.01 ms /    46 tokens (    1.65 ms per token,   605.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      78.75 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      89.99 ms /    23 tokens (    3.91 ms per token,   255.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      92.09 ms /    24 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     154.76 ms /   126 tokens (    1.23 ms per token,   814.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.74 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      83.15 ms /    26 tokens (    3.20 ms per token,   312.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.58 ms /    27 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     145.70 ms /   108 tokens (    1.35 ms per token,   741.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.80 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     238.40 ms /   225 tokens (    1.06 ms per token,   943.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     247.81 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     202.36 ms /   196 tokens (    1.03 ms per token,   968.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     210.33 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     184.84 ms /   152 tokens (    1.22 ms per token,   822.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.34 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     114.48 ms /    76 tokens (    1.51 ms per token,   663.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     118.62 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     308.44 ms /   262 tokens (    1.18 ms per token,   849.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     319.54 ms /   263 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     218.40 ms /   237 tokens (    0.92 ms per token,  1085.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     227.89 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     109.97 ms /   123 tokens (    0.89 ms per token,  1118.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.22 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.65 ms /    38 tokens (    1.75 ms per token,   570.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.17 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.24 ms /    22 tokens (    2.87 ms per token,   347.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.96 ms /    23 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      89.07 ms /    85 tokens (    1.05 ms per token,   954.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.41 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      96.25 ms /   100 tokens (    0.96 ms per token,  1038.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.84 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     218.91 ms /   240 tokens (    0.91 ms per token,  1096.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     228.05 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     286.08 ms /   224 tokens (    1.28 ms per token,   782.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     296.19 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     288.46 ms /   208 tokens (    1.39 ms per token,   721.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     296.69 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     269.17 ms /   190 tokens (    1.42 ms per token,   705.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     277.53 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     285.44 ms /   210 tokens (    1.36 ms per token,   735.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     293.80 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     249.23 ms /   170 tokens (    1.47 ms per token,   682.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     256.34 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     282.94 ms /   194 tokens (    1.46 ms per token,   685.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     291.21 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     295.12 ms /   226 tokens (    1.31 ms per token,   765.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     305.44 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     182.81 ms /   226 tokens (    0.81 ms per token,  1236.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     192.28 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     179.03 ms /   218 tokens (    0.82 ms per token,  1217.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     187.43 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     187.89 ms /   243 tokens (    0.77 ms per token,  1293.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     197.65 ms /   244 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     176.29 ms /   230 tokens (    0.77 ms per token,  1304.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     187.12 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     187.64 ms /   245 tokens (    0.77 ms per token,  1305.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     197.91 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     184.17 ms /   251 tokens (    0.73 ms per token,  1362.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     194.73 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     183.58 ms /   231 tokens (    0.79 ms per token,  1258.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     193.31 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     179.58 ms /   227 tokens (    0.79 ms per token,  1264.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     189.45 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     190.21 ms /   251 tokens (    0.76 ms per token,  1319.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     200.36 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     187.13 ms /   247 tokens (    0.76 ms per token,  1319.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     196.96 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     173.46 ms /   201 tokens (    0.86 ms per token,  1158.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     182.16 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     181.71 ms /   213 tokens (    0.85 ms per token,  1172.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     190.02 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     185.21 ms /   239 tokens (    0.77 ms per token,  1290.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     195.74 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     190.49 ms /   237 tokens (    0.80 ms per token,  1244.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.68 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     307.74 ms /   254 tokens (    1.21 ms per token,   825.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     318.39 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     396.73 ms /   291 tokens (    1.36 ms per token,   733.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     408.39 ms /   292 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     369.47 ms /   268 tokens (    1.38 ms per token,   725.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     379.87 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     286.28 ms /   239 tokens (    1.20 ms per token,   834.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     296.11 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     214.78 ms /   230 tokens (    0.93 ms per token,  1070.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     224.20 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      81.39 ms /    65 tokens (    1.25 ms per token,   798.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.89 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      41.28 ms /     5 tokens (    8.26 ms per token,   121.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.47 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      74.72 ms /    17 tokens (    4.40 ms per token,   227.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.60 ms /    18 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     190.64 ms /   202 tokens (    0.94 ms per token,  1059.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.40 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     155.37 ms /   170 tokens (    0.91 ms per token,  1094.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     166.19 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     148.86 ms /   143 tokens (    1.04 ms per token,   960.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     154.73 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     173.33 ms /   186 tokens (    0.93 ms per token,  1073.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.99 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      89.34 ms /    68 tokens (    1.31 ms per token,   761.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      93.19 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     113.99 ms /   116 tokens (    0.98 ms per token,  1017.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     119.19 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     402.23 ms /   512 tokens (    0.79 ms per token,  1272.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     423.73 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     377.22 ms /   512 tokens (    0.74 ms per token,  1357.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     398.79 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     347.91 ms /   512 tokens (    0.68 ms per token,  1471.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     372.75 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     312.52 ms /   512 tokens (    0.61 ms per token,  1638.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     331.92 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     388.64 ms /   512 tokens (    0.76 ms per token,  1317.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     410.82 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     315.37 ms /   512 tokens (    0.62 ms per token,  1623.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     334.96 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     318.78 ms /   512 tokens (    0.62 ms per token,  1606.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     337.50 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     413.22 ms /   512 tokens (    0.81 ms per token,  1239.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     434.70 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     408.66 ms /   512 tokens (    0.80 ms per token,  1252.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     430.06 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     389.10 ms /   512 tokens (    0.76 ms per token,  1315.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     409.23 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     408.12 ms /   512 tokens (    0.80 ms per token,  1254.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     429.51 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     304.51 ms /   512 tokens (    0.59 ms per token,  1681.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     326.24 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     333.65 ms /   512 tokens (    0.65 ms per token,  1534.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     355.39 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     309.90 ms /   512 tokens (    0.61 ms per token,  1652.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     331.78 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     331.34 ms /   512 tokens (    0.65 ms per token,  1545.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     351.38 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     464.53 ms /   512 tokens (    0.91 ms per token,  1102.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     483.81 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     460.01 ms /   512 tokens (    0.90 ms per token,  1113.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     479.34 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     312.35 ms /   512 tokens (    0.61 ms per token,  1639.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     333.86 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     267.85 ms /   512 tokens (    0.52 ms per token,  1911.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     289.17 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     339.98 ms /   512 tokens (    0.66 ms per token,  1505.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     361.32 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     344.51 ms /   512 tokens (    0.67 ms per token,  1486.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     364.38 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     342.76 ms /   512 tokens (    0.67 ms per token,  1493.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     361.98 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     341.66 ms /   512 tokens (    0.67 ms per token,  1498.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     364.80 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     352.70 ms /   512 tokens (    0.69 ms per token,  1451.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     372.14 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     344.71 ms /   512 tokens (    0.67 ms per token,  1485.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     364.64 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     347.22 ms /   512 tokens (    0.68 ms per token,  1474.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     367.04 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     344.64 ms /   512 tokens (    0.67 ms per token,  1485.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     367.90 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     277.53 ms /   512 tokens (    0.54 ms per token,  1844.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     299.34 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     361.32 ms /   512 tokens (    0.71 ms per token,  1417.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     380.31 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     363.93 ms /   512 tokens (    0.71 ms per token,  1406.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     383.14 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     358.50 ms /   512 tokens (    0.70 ms per token,  1428.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     380.04 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     290.25 ms /   512 tokens (    0.57 ms per token,  1764.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     310.06 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     357.17 ms /   512 tokens (    0.70 ms per token,  1433.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     377.23 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     358.85 ms /   512 tokens (    0.70 ms per token,  1426.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     378.01 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     289.83 ms /   512 tokens (    0.57 ms per token,  1766.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     309.15 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     347.87 ms /   512 tokens (    0.68 ms per token,  1471.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     368.42 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     351.29 ms /   512 tokens (    0.69 ms per token,  1457.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     370.98 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     292.73 ms /   512 tokens (    0.57 ms per token,  1749.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     311.92 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     385.95 ms /   512 tokens (    0.75 ms per token,  1326.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     405.19 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     398.35 ms /   512 tokens (    0.78 ms per token,  1285.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     417.58 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     386.34 ms /   512 tokens (    0.75 ms per token,  1325.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     408.08 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     378.47 ms /   512 tokens (    0.74 ms per token,  1352.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     399.86 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     391.22 ms /   512 tokens (    0.76 ms per token,  1308.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     410.96 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     293.23 ms /   512 tokens (    0.57 ms per token,  1746.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     317.99 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     295.27 ms /   512 tokens (    0.58 ms per token,  1734.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     314.59 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     294.28 ms /   512 tokens (    0.57 ms per token,  1739.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     313.68 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     616.82 ms /   512 tokens (    1.20 ms per token,   830.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     636.40 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     271.88 ms /   512 tokens (    0.53 ms per token,  1883.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     290.56 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     273.61 ms /   512 tokens (    0.53 ms per token,  1871.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     295.77 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     260.55 ms /   512 tokens (    0.51 ms per token,  1965.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     279.24 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     317.21 ms /   512 tokens (    0.62 ms per token,  1614.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     336.62 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     324.21 ms /   512 tokens (    0.63 ms per token,  1579.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     343.74 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     321.64 ms /   512 tokens (    0.63 ms per token,  1591.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     342.01 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     317.43 ms /   512 tokens (    0.62 ms per token,  1612.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     339.14 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     321.76 ms /   512 tokens (    0.63 ms per token,  1591.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     340.39 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     323.41 ms /   512 tokens (    0.63 ms per token,  1583.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     343.00 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     265.43 ms /   512 tokens (    0.52 ms per token,  1928.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     285.07 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     310.28 ms /   512 tokens (    0.61 ms per token,  1650.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     332.56 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     302.85 ms /   512 tokens (    0.59 ms per token,  1690.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     322.49 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     114.58 ms /   155 tokens (    0.74 ms per token,  1352.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     120.89 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      47.72 ms /     8 tokens (    5.96 ms per token,   167.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.15 ms /     9 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     132.24 ms /   143 tokens (    0.92 ms per token,  1081.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.69 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     199.39 ms /   259 tokens (    0.77 ms per token,  1298.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     210.78 ms /   260 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     333.81 ms /   432 tokens (    0.77 ms per token,  1294.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     354.34 ms /   433 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     163.42 ms /   192 tokens (    0.85 ms per token,  1174.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     171.76 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     206.50 ms /   223 tokens (    0.93 ms per token,  1079.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.24 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     157.88 ms /   138 tokens (    1.14 ms per token,   874.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.47 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     136.61 ms /   121 tokens (    1.13 ms per token,   885.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.20 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     180.07 ms /   140 tokens (    1.29 ms per token,   777.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     187.18 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     197.87 ms /   188 tokens (    1.05 ms per token,   950.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     206.17 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     116.66 ms /   111 tokens (    1.05 ms per token,   951.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     123.87 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     213.07 ms /   212 tokens (    1.01 ms per token,   994.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     221.70 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     154.23 ms /   212 tokens (    0.73 ms per token,  1374.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     162.16 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     147.67 ms /   215 tokens (    0.69 ms per token,  1455.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.65 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     154.03 ms /   235 tokens (    0.66 ms per token,  1525.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.15 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     156.86 ms /   251 tokens (    0.62 ms per token,  1600.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     167.19 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     143.10 ms /   211 tokens (    0.68 ms per token,  1474.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.02 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      63.04 ms /    38 tokens (    1.66 ms per token,   602.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.40 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      78.79 ms /    74 tokens (    1.06 ms per token,   939.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      82.23 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     128.02 ms /   148 tokens (    0.86 ms per token,  1156.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.85 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     162.27 ms /   246 tokens (    0.66 ms per token,  1515.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     172.10 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      83.70 ms /   116 tokens (    0.72 ms per token,  1385.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.76 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.59 ms /    43 tokens (    1.53 ms per token,   655.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.18 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      95.72 ms /   127 tokens (    0.75 ms per token,  1326.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     100.83 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     205.68 ms /   267 tokens (    0.77 ms per token,  1298.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.17 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     148.82 ms /   228 tokens (    0.65 ms per token,  1532.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     157.30 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      64.60 ms /    53 tokens (    1.22 ms per token,   820.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      67.36 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      83.42 ms /    78 tokens (    1.07 ms per token,   935.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      86.73 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     155.80 ms /   210 tokens (    0.74 ms per token,  1347.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     163.50 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     175.19 ms /   179 tokens (    0.98 ms per token,  1021.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     182.97 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     109.55 ms /    96 tokens (    1.14 ms per token,   876.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     114.44 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     215.77 ms /   223 tokens (    0.97 ms per token,  1033.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     224.36 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     262.21 ms /   266 tokens (    0.99 ms per token,  1014.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     272.64 ms /   267 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     187.98 ms /   222 tokens (    0.85 ms per token,  1180.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     195.81 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     169.07 ms /   175 tokens (    0.97 ms per token,  1035.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     175.80 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     216.33 ms /   249 tokens (    0.87 ms per token,  1151.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     226.29 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     129.20 ms /   166 tokens (    0.78 ms per token,  1284.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     135.73 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     122.94 ms /   158 tokens (    0.78 ms per token,  1285.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     129.25 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     119.28 ms /   141 tokens (    0.85 ms per token,  1182.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     124.88 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     143.71 ms /   199 tokens (    0.72 ms per token,  1384.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.16 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     140.95 ms /   209 tokens (    0.67 ms per token,  1482.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.58 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     135.46 ms /   195 tokens (    0.69 ms per token,  1439.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     143.55 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      82.28 ms /   103 tokens (    0.80 ms per token,  1251.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      87.15 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     144.67 ms /   204 tokens (    0.71 ms per token,  1410.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.85 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     127.40 ms /   185 tokens (    0.69 ms per token,  1452.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     136.76 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     126.20 ms /   167 tokens (    0.76 ms per token,  1323.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     133.51 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     203.17 ms /   262 tokens (    0.78 ms per token,  1289.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     215.18 ms /   263 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     219.16 ms /   266 tokens (    0.82 ms per token,  1213.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     229.79 ms /   267 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     135.18 ms /   164 tokens (    0.82 ms per token,  1213.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     142.32 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     103.73 ms /   122 tokens (    0.85 ms per token,  1176.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     109.53 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     243.03 ms /   304 tokens (    0.80 ms per token,  1250.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     255.82 ms /   305 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     355.66 ms /   512 tokens (    0.69 ms per token,  1439.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     383.84 ms /   513 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     231.27 ms /   397 tokens (    0.58 ms per token,  1716.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.66 ms /   398 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     181.71 ms /   286 tokens (    0.64 ms per token,  1573.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     195.88 ms /   287 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      82.91 ms /   102 tokens (    0.81 ms per token,  1230.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.38 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     219.37 ms /   271 tokens (    0.81 ms per token,  1235.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     231.45 ms /   272 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      56.68 ms /    21 tokens (    2.70 ms per token,   370.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.74 ms /    22 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      66.75 ms /    55 tokens (    1.21 ms per token,   823.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.84 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      61.87 ms /    10 tokens (    6.19 ms per token,   161.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      63.32 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      69.45 ms /    36 tokens (    1.93 ms per token,   518.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      72.12 ms /    37 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     169.38 ms /   204 tokens (    0.83 ms per token,  1204.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     178.38 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      77.84 ms /    72 tokens (    1.08 ms per token,   924.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.58 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     179.70 ms /   250 tokens (    0.72 ms per token,  1391.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.06 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     151.03 ms /   208 tokens (    0.73 ms per token,  1377.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     160.13 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     172.16 ms /   247 tokens (    0.70 ms per token,  1434.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.83 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     170.64 ms /   253 tokens (    0.67 ms per token,  1482.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.69 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      89.92 ms /   111 tokens (    0.81 ms per token,  1234.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.88 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     178.51 ms /   247 tokens (    0.72 ms per token,  1383.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.59 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      80.12 ms /    86 tokens (    0.93 ms per token,  1073.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      84.38 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     172.00 ms /   225 tokens (    0.76 ms per token,  1308.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     181.12 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     161.91 ms /   224 tokens (    0.72 ms per token,  1383.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     170.88 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      81.41 ms /    81 tokens (    1.01 ms per token,   994.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      85.61 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     148.41 ms /   182 tokens (    0.82 ms per token,  1226.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.71 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     144.25 ms /   173 tokens (    0.83 ms per token,  1199.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     151.33 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     163.02 ms /   196 tokens (    0.83 ms per token,  1202.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     171.28 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     132.11 ms /   156 tokens (    0.85 ms per token,  1180.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     138.47 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     161.08 ms /   206 tokens (    0.78 ms per token,  1278.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     169.70 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     119.12 ms /   129 tokens (    0.92 ms per token,  1082.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     125.23 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     146.84 ms /   166 tokens (    0.88 ms per token,  1130.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     153.89 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      86.90 ms /    90 tokens (    0.97 ms per token,  1035.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.43 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     167.55 ms /   211 tokens (    0.79 ms per token,  1259.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     176.11 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.69 ms /    54 tokens (    1.22 ms per token,   821.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.82 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     179.09 ms /   239 tokens (    0.75 ms per token,  1334.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.10 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     168.76 ms /   245 tokens (    0.69 ms per token,  1451.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     178.89 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      60.55 ms /    29 tokens (    2.09 ms per token,   478.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.81 ms /    30 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     139.90 ms /   153 tokens (    0.91 ms per token,  1093.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     145.92 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      68.84 ms /    48 tokens (    1.43 ms per token,   697.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      71.57 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     180.03 ms /   235 tokens (    0.77 ms per token,  1305.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.58 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      65.66 ms /    43 tokens (    1.53 ms per token,   654.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.40 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.54 ms /    86 tokens (    1.05 ms per token,   949.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.62 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      90.49 ms /    78 tokens (    1.16 ms per token,   861.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      94.49 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      88.37 ms /    68 tokens (    1.30 ms per token,   769.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.78 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      97.57 ms /    98 tokens (    1.00 ms per token,  1004.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.98 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      39.37 ms /     5 tokens (    7.87 ms per token,   127.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.56 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      93.35 ms /    74 tokens (    1.26 ms per token,   792.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.12 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      71.15 ms /    52 tokens (    1.37 ms per token,   730.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      74.07 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      73.00 ms /    45 tokens (    1.62 ms per token,   616.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      75.82 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     144.23 ms /   149 tokens (    0.97 ms per token,  1033.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     150.75 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =     148.44 ms /   171 tokens (    0.87 ms per token,  1151.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     155.19 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =      74.78 ms\n",
      "llama_perf_context_print: prompt eval time =      58.71 ms /    11 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.02 ms /    12 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Embedding generation for phi-2.Q6_K] 165.17s\n",
      "‚úî Saved embeddings to /workspaces/VectorVet/embeddings/phi-2.Q6_K_20news_chunks.npy\n"
     ]
    }
   ],
   "source": [
    "# Define paths  \n",
    "MODEL_DIR = PROJECT_ROOT / \"models\"  \n",
    "EMB_DIR = PROJECT_ROOT / \"embeddings\"  \n",
    "EMB_DIR.mkdir(exist_ok=True, parents=True)  \n",
    "  \n",
    "# List of models to embed with  \n",
    "MODELS = [  \n",
    "    \"Phi-3-mini-4k-instruct-q4.gguf\",  \n",
    "    \"Llama-3.2-1B-Instruct.Q6_K.gguf\",  \n",
    "    \"Llama-3.1-8b-instruct-q6_k.gguf\",  \n",
    "    \"phi-2.Q6_K.gguf\",  \n",
    "]  \n",
    "  \n",
    "# Generate embeddings  \n",
    "for fname in MODELS:  \n",
    "    model_path = MODEL_DIR / fname  \n",
    "    model_name = model_path.stem  \n",
    "    out_file = EMB_DIR / f\"{model_name}_20news_chunks.npy\"  \n",
    "  \n",
    "    if out_file.exists():  \n",
    "        print(f\"‚úî {out_file.name} already exists ‚Äì skipping\")  \n",
    "        continue  \n",
    "  \n",
    "    print(f\"‚Üí Embedding with {model_name} ‚Ä¶\")  \n",
    "    llm = Llama(  \n",
    "        model_path=str(model_path),  \n",
    "        n_gpu_layers=-1,  \n",
    "        embedding=True,  \n",
    "    )  \n",
    "  \n",
    "    embs = np.zeros((len(chunk_texts), llm.n_embd()), dtype=np.float32)  \n",
    "  \n",
    "    with timer(f\"Embedding generation for {model_name}\"):  \n",
    "        for i, txt in enumerate(tqdm(chunk_texts, desc=f\"Embedding ({model_name})\")):  \n",
    "            emb = llm.embed(txt)  \n",
    "            emb = np.array(emb)  \n",
    "  \n",
    "            if emb.ndim > 1:  \n",
    "                emb = emb.mean(axis=0)  # Average if needed  \n",
    "  \n",
    "            emb = emb.flatten()  \n",
    "  \n",
    "            if emb.shape[0] != llm.n_embd():  \n",
    "                print(f\"Warning: Skipping text {i} due to embedding size mismatch: {emb.shape}\")  \n",
    "                continue  \n",
    "  \n",
    "            embs[i] = emb  \n",
    "  \n",
    "    np.save(out_file, embs)  \n",
    "    print(f\"‚úî Saved embeddings to {out_file}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "  \n",
    "## üìä Compute Metrics and Summarize Results  \n",
    "  \n",
    "Now let's load the embeddings we've saved, compute intrinsic embedding metrics, and summarize results into a tidy dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÇÔ∏è Embedding sets detected: ['Llama-3.1-8b-instruct-q6_k', 'Llama-3.2-1B-Instruct.Q6_K', 'phi-2.Q6_K', 'Phi-3-mini-4k-instruct-q4']\n",
      "\n",
      "üìê Running metrics for: Llama-3.1-8b-instruct-q6_k\n",
      "Calculating Isotropy...\n",
      "Calculating Hubness...\n",
      "Calculating Clustering Quality...\n",
      "Calculating Pairwise Cosine Similarity...\n",
      "[Metrics computation for Llama-3.1-8b-instruct-q6_k] 1.04s\n",
      "\n",
      "üìê Running metrics for: Llama-3.2-1B-Instruct.Q6_K\n",
      "Calculating Isotropy...\n",
      "Calculating Hubness...\n",
      "Calculating Clustering Quality...\n",
      "Calculating Pairwise Cosine Similarity...\n",
      "[Metrics computation for Llama-3.2-1B-Instruct.Q6_K] 0.64s\n",
      "\n",
      "üìê Running metrics for: phi-2.Q6_K\n",
      "Calculating Isotropy...\n",
      "Calculating Hubness...\n",
      "Calculating Clustering Quality...\n",
      "Calculating Pairwise Cosine Similarity...\n",
      "[Metrics computation for phi-2.Q6_K] 0.57s\n",
      "\n",
      "üìê Running metrics for: Phi-3-mini-4k-instruct-q4\n",
      "Calculating Isotropy...\n",
      "Calculating Hubness...\n",
      "Calculating Clustering Quality...\n",
      "Calculating Pairwise Cosine Similarity...\n",
      "[Metrics computation for Phi-3-mini-4k-instruct-q4] 0.62s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_11287\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_11287_level0_col0\" class=\"col_heading level0 col0\" >IsoScore</th>\n",
       "      <th id=\"T_11287_level0_col1\" class=\"col_heading level0 col1\" >skewness</th>\n",
       "      <th id=\"T_11287_level0_col2\" class=\"col_heading level0 col2\" >robin_hood</th>\n",
       "      <th id=\"T_11287_level0_col3\" class=\"col_heading level0 col3\" >antihub_rate</th>\n",
       "      <th id=\"T_11287_level0_col4\" class=\"col_heading level0 col4\" >silhouette</th>\n",
       "      <th id=\"T_11287_level0_col5\" class=\"col_heading level0 col5\" >davies_bouldin</th>\n",
       "      <th id=\"T_11287_level0_col6\" class=\"col_heading level0 col6\" >cos_mean</th>\n",
       "      <th id=\"T_11287_level0_col7\" class=\"col_heading level0 col7\" >cos_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_11287_level0_row0\" class=\"row_heading level0 row0\" >Llama-3.1-8b-instruct-q6_k</th>\n",
       "      <td id=\"T_11287_row0_col0\" class=\"data row0 col0\" >0.003</td>\n",
       "      <td id=\"T_11287_row0_col1\" class=\"data row0 col1\" >1.741</td>\n",
       "      <td id=\"T_11287_row0_col2\" class=\"data row0 col2\" >0.272</td>\n",
       "      <td id=\"T_11287_row0_col3\" class=\"data row0 col3\" >0.000</td>\n",
       "      <td id=\"T_11287_row0_col4\" class=\"data row0 col4\" >0.177</td>\n",
       "      <td id=\"T_11287_row0_col5\" class=\"data row0 col5\" >2.752</td>\n",
       "      <td id=\"T_11287_row0_col6\" class=\"data row0 col6\" >0.449</td>\n",
       "      <td id=\"T_11287_row0_col7\" class=\"data row0 col7\" >0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11287_level0_row1\" class=\"row_heading level0 row1\" >Llama-3.2-1B-Instruct.Q6_K</th>\n",
       "      <td id=\"T_11287_row1_col0\" class=\"data row1 col0\" >0.001</td>\n",
       "      <td id=\"T_11287_row1_col1\" class=\"data row1 col1\" >2.651</td>\n",
       "      <td id=\"T_11287_row1_col2\" class=\"data row1 col2\" >0.325</td>\n",
       "      <td id=\"T_11287_row1_col3\" class=\"data row1 col3\" >0.000</td>\n",
       "      <td id=\"T_11287_row1_col4\" class=\"data row1 col4\" >0.141</td>\n",
       "      <td id=\"T_11287_row1_col5\" class=\"data row1 col5\" >2.658</td>\n",
       "      <td id=\"T_11287_row1_col6\" class=\"data row1 col6\" >0.653</td>\n",
       "      <td id=\"T_11287_row1_col7\" class=\"data row1 col7\" >0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11287_level0_row2\" class=\"row_heading level0 row2\" >Phi-3-mini-4k-instruct-q4</th>\n",
       "      <td id=\"T_11287_row2_col0\" class=\"data row2 col0\" >0.001</td>\n",
       "      <td id=\"T_11287_row2_col1\" class=\"data row2 col1\" >3.406</td>\n",
       "      <td id=\"T_11287_row2_col2\" class=\"data row2 col2\" >0.358</td>\n",
       "      <td id=\"T_11287_row2_col3\" class=\"data row2 col3\" >0.000</td>\n",
       "      <td id=\"T_11287_row2_col4\" class=\"data row2 col4\" >0.086</td>\n",
       "      <td id=\"T_11287_row2_col5\" class=\"data row2 col5\" >2.869</td>\n",
       "      <td id=\"T_11287_row2_col6\" class=\"data row2 col6\" >0.731</td>\n",
       "      <td id=\"T_11287_row2_col7\" class=\"data row2 col7\" >0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_11287_level0_row3\" class=\"row_heading level0 row3\" >phi-2.Q6_K</th>\n",
       "      <td id=\"T_11287_row3_col0\" class=\"data row3 col0\" >0.001</td>\n",
       "      <td id=\"T_11287_row3_col1\" class=\"data row3 col1\" >2.291</td>\n",
       "      <td id=\"T_11287_row3_col2\" class=\"data row3 col2\" >0.323</td>\n",
       "      <td id=\"T_11287_row3_col3\" class=\"data row3 col3\" >0.000</td>\n",
       "      <td id=\"T_11287_row3_col4\" class=\"data row3 col4\" >0.118</td>\n",
       "      <td id=\"T_11287_row3_col5\" class=\"data row3 col5\" >2.546</td>\n",
       "      <td id=\"T_11287_row3_col6\" class=\"data row3 col6\" >0.635</td>\n",
       "      <td id=\"T_11287_row3_col7\" class=\"data row3 col7\" >0.213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5121a3a7a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find saved embeddings  \n",
    "files = {  \n",
    "    p.stem.split(\"_20news_chunks\")[0]: str(p)  \n",
    "    for p in EMB_DIR.glob(\"*_20news_chunks.npy\")  \n",
    "}  \n",
    "  \n",
    "print(\"üóÇÔ∏è Embedding sets detected:\", list(files.keys()))  \n",
    "  \n",
    "# Load embeddings  \n",
    "embs = load_multiple_embeddings(files)  \n",
    "  \n",
    "# Compute all metrics  \n",
    "results = {}  \n",
    "for name, mat in embs.items():  \n",
    "    print(f\"\\nüìê Running metrics for: {name}\")  \n",
    "    with timer(f\"Metrics computation for {name}\"):  \n",
    "        results[name] = run_all_metrics(mat)  \n",
    "  \n",
    "# Summarize results into DataFrame  \n",
    "summary_df = summarize_to_dataframe(results)  \n",
    "  \n",
    "# Display summarized metrics nicely  \n",
    "summary_df.style.format(precision=3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "  \n",
    "## ‚úÖ Final Results  \n",
    "  \n",
    "The resulting table summarizes the embedding quality across all models, making it easy to compare and interpret metrics like isotropy, hubness, clustering quality, and pairwise cosine similarity.  \n",
    "  \n",
    "üéâ **You're all set!**  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
