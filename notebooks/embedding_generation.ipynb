{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìì Embedding Generation\n",
    "\n",
    "This notebook handles **data loading, chunking, embedding generation, and saving embeddings**.  \n",
    "  \n",
    "## üîß Setup and Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "from pathlib import Path  \n",
    "  \n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from tqdm.auto import tqdm  \n",
    "  \n",
    "from sklearn.datasets import fetch_20newsgroups  \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  \n",
    "from llama_cpp import Llama  \n",
    "  \n",
    "# Path setup  \n",
    "PROJECT_ROOT = Path.cwd().parent  \n",
    "sys.path.append(str(PROJECT_ROOT))  \n",
    "  \n",
    "from vectorvet.core.utils import timer  \n",
    "  \n",
    "# Create directories  \n",
    "MODEL_DIR = PROJECT_ROOT / \"models\"  \n",
    "EMB_DIR = PROJECT_ROOT / \"embeddings\"  \n",
    "EMB_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÉÔ∏è Load and Chunk Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data  \n",
    "news = fetch_20newsgroups(subset=\"train\", remove=(\"headers\", \"footers\", \"quotes\"))  \n",
    "texts = [t for t in news.data if t.strip()]  \n",
    "  \n",
    "# Split into chunks  \n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=50)  \n",
    "  \n",
    "chunked_data = []  \n",
    "for idx, text in enumerate(tqdm(texts, desc=\"Chunking texts\")):  \n",
    "    chunks = splitter.split_text(text)  \n",
    "    for chunk_idx, chunk in enumerate(chunks):  \n",
    "        chunked_data.append({  \n",
    "            \"original_index\": idx,  \n",
    "            \"chunk_index\": chunk_idx,  \n",
    "            \"chunk\": chunk  \n",
    "        })  \n",
    "  \n",
    "chunked_df = pd.DataFrame(chunked_data)  \n",
    "chunk_texts = chunked_df[\"chunk\"].tolist()  \n",
    "print(f\"‚úÖ Total chunks created: {len(chunk_texts)}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Generate and Save Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of embedding models  \n",
    "MODELS = [  \n",
    "    \"Phi-3-mini-4k-instruct-q4.gguf\",  \n",
    "    \"Llama-3.2-1B-Instruct.Q6_K.gguf\",  \n",
    "    \"Llama-3.1-8b-instruct-q6_k.gguf\",  \n",
    "    \"phi-2.Q6_K.gguf\",  \n",
    "]  \n",
    "  \n",
    "# Verify models exist  \n",
    "for fname in MODELS:  \n",
    "    model_path = MODEL_DIR / fname  \n",
    "    if not model_path.exists():  \n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")  \n",
    "  \n",
    "# Generate embeddings  \n",
    "for fname in MODELS:  \n",
    "    model_path = MODEL_DIR / fname  \n",
    "    model_name = model_path.stem  \n",
    "    out_file = EMB_DIR / f\"{model_name}_20news_chunks.npy\"  \n",
    "  \n",
    "    if out_file.exists():  \n",
    "        print(f\"‚úî {out_file.name} already exists ‚Äì skipping\")  \n",
    "        continue  \n",
    "  \n",
    "    print(f\"‚Üí Embedding with {model_name} ‚Ä¶\")  \n",
    "    llm = Llama(  \n",
    "        model_path=str(model_path),  \n",
    "        n_gpu_layers=-1,  \n",
    "        embedding=True,  \n",
    "    )  \n",
    "  \n",
    "    embs = np.zeros((len(chunk_texts), llm.n_embd()), dtype=np.float32)  \n",
    "  \n",
    "    with timer(f\"Embedding generation for {model_name}\"):  \n",
    "        for i, txt in enumerate(tqdm(chunk_texts, desc=f\"Embedding ({model_name})\")):  \n",
    "            emb = llm.embed(txt)  \n",
    "            emb = np.array(emb)  \n",
    "  \n",
    "            if emb.ndim > 1:  \n",
    "                emb = emb.mean(axis=0)  \n",
    "  \n",
    "            emb = emb.flatten()  \n",
    "  \n",
    "            if emb.shape[0] != llm.n_embd():  \n",
    "                print(f\"‚ö†Ô∏è Warning: Skipping text {i} due to embedding size mismatch: {emb.shape}\")  \n",
    "                continue  \n",
    "  \n",
    "            embs[i] = emb  \n",
    "  \n",
    "    np.save(out_file, embs)  \n",
    "    print(f\"‚úî Saved embeddings to {out_file}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
